<!DOCTYPE html> 
<html lang="en" xml:lang="en" > 
<head> <title>2nd Order Elliptic PDE</title> 
<meta  charset="UTF-8"" /> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" /> 
<link rel="stylesheet" type="text/css" href="2nd_Order_Elliptic_PDE.css" /> 
<meta name="src" content="2nd_Order_Elliptic_PDE.tex" /> 
<script>window.MathJax = { tex: { tags: "ams", inlineMath: [ ["\\\(","\\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true, processEnvironments: true, packages: ['base', 'color', 'ams', 'newcommand'] }, loader: { load: ['[tex]/color', '[tex]/ams', '[tex]/newcommand'] } }; </script> 
 <script type="text/javascript" async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>  
</head><body 
>
  <p style="display: none;">\( \newcommand{\cO}{\mathcal{O}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\GG}{\mathbb{G}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\LL}{\mathbb{L}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\SP}{\mathbb{S}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FF}{\mathbb{F}}
\renewcommand{\AA}{\mathbb{A}}
\newcommand{\sF}{\mathscr{F}}
\newcommand{\sC}{\mathscr{C}}
\newcommand{\ts}{\textsuperscript}
\newcommand{\mf}{\mathfrak}
\newcommand{\cc}{\mf{c}}
\newcommand{\mg}{\mf{g}}
\newcommand{\ma}{\mf{a}}
\newcommand{\mh}{\mf{h}}
\newcommand{\mn}{\mf{n}}
\newcommand{\mc}{\mf{c}}
\newcommand{\ul}{\underline}
\newcommand{\mz}{\mf{z}}
\newcommand{\me}{\mf{e}}
\newcommand{\mff}{\mf{f}}
\newcommand{\mm}{\mf{m}}
\newcommand{\mt}{\mf{t}}
\newcommand{\pp}{\mf{p}}
\newcommand{\qq}{\mf{q}}
\newcommand{\gl}{\mf{gl}}
\newcommand{\msl}{\mf{sl}}
\newcommand{\so}{\mf{so}}
\newcommand{\mfu}{\mf{u}}
\newcommand{\su}{\mf{su}}
\newcommand{\msp}{\mf{sp}}
\renewcommand{\aa}{\mf{a}}
\newcommand{\bb}{\mf{b}}
\newcommand{\sR}{\mathscr{R}}
\newcommand{\lb}{\langle}
\newcommand{\rb}{\rangle}
\newcommand{\ff}{\mf{f}}
\newcommand{\ee}{\epsilon}

\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\ceil}[1]{\lceil #1 \rceil}

\newcommand{\pushout}{\arrow[ul, phantom, "\ulcorner", very near start]}
\newcommand{\pullback}{\arrow[dr, phantom, "\lrcorner", very near start]}

\newcommand{\simp}[1]{#1^{\Delta^{op}}}

\newcommand{\arrowtcupp}[2]{\arrow[bend left=50, ""{name=U, below,inner sep=1}]{#1}\arrow[Rightarrow,from=U,to=MU,"#2"]}
\newcommand{\arrowtclow}[2]{\arrow[bend right=50, ""{name=L,inner sep=1}]{#1}\arrow[Rightarrow,from=LM,to=L]{}[]{#2}} % if you want to change some parameter of the label.
\newcommand{\arrowtcmid}[2]{\arrow[""{name=MU,inner sep=1},""{name=LM,below,inner sep=1}]{#1}[pos=.1]{#2}}
\newcommand{\dummy}{\textcolor{white}{\bullet}}


%for adjunction
\newcommand{\adjunction}[4]{
	#1\hspace{2pt}\colon #2	\leftrightharpoons #3 \hspace{2pt}\colon #4
}


%Math operators
\newcommand{\Set}{\mathop{\rm Set}\nolimits}
\newcommand{\Ind}{\mathop{\rm Ind}\nolimits}
\newcommand{\Sind}{\mathop{\rm Sind}\nolimits}
\newcommand{\Ext}{\mathop{\rm Ext}\nolimits}
\newcommand{\sd}{\mathop{\rm sd}\nolimits}
\newcommand{\Ex}{\mathop{\rm Ex}\nolimits}
\newcommand{\Out}{\mathop{\rm Out}\nolimits}
\newcommand{\Cyl}{\mathop{\rm Cyl}\nolimits}
\newcommand{\Path}{\mathop{\rm Path}\nolimits}
\newcommand{\Ch}{\mathop{\rm Ch}\nolimits}
\newcommand{\SSet}{\mathop{\rm \Set^{\Delta^{op}}}\nolimits}
\newcommand{\Sq}{\mathop{\rm Sq}\nolimits}
\newcommand{\Free}{\mathop{\rm Free}\nolimits}
\newcommand{\Maps}{\mathop{\rm Maps}\nolimits}
\newcommand{\LMaps}{\mathop{\rm LMaps}\nolimits}
\newcommand{\RMaps}{\mathop{\rm RMaps}\nolimits}
\newcommand{\MU}{\mathop{\rm MU}\nolimits}
\newcommand{\MSU}{\mathop{\rm MSU}\nolimits}
\newcommand{\MSp}{\mathop{\rm MSp}\nolimits}
\newcommand{\MSO}{\mathop{\rm MSO}\nolimits}
\newcommand{\MO}{\mathop{\rm MO}\nolimits}
\newcommand{\BU}{\mathop{\rm BU}\nolimits}
\newcommand{\BSU}{\mathop{\rm BSU}\nolimits}
\newcommand{\BSp}{\mathop{\rm BSp}\nolimits}
\newcommand{\BSO}{\mathop{\rm BSO}\nolimits}
\newcommand{\BO}{\mathop{\rm BO}\nolimits}
\newcommand{\Tor}{\mathop{\rm Tor}\nolimits}
\newcommand{\Cotor}{\mathop{\rm Cotor}\nolimits}
\newcommand{\imag}{\mathop{\rm Im}\nolimits}
\newcommand{\real}{\mathop{\rm Re}\nolimits}
\newcommand{\Cat}{\mathop{\rm Cat}\nolimits}
\newcommand{\Fld}{\mathop{\rm Fld}\nolimits}
\newcommand{\Frac}{\mathop{\rm Frac}\nolimits}
\newcommand{\Dom}{\mathop{\rm Dom}\nolimits}
\newcommand{\Hotc}{\mathop{\rm Hotc}\nolimits}
\newcommand{\Top}{\mathop{\rm Top}\nolimits}
\newcommand{\Ring}{\mathop{\rm Ring}\nolimits}
\newcommand{\CRing}{\mathop{\rm CRing}\nolimits}
\newcommand{\CGHaus}{\mathop{\rm CGHaus}\nolimits}
\newcommand{\Alg}{\mathop{\rm Alg}\nolimits}
\newcommand{\Bool}{\mathop{\rm Bool}\nolimits}
\newcommand{\hTop}{\mathop{\rm hTop}\nolimits}
\newcommand{\Nat}{\mathop{\rm Nat}\nolimits}
\newcommand{\Rel}{\mathop{\rm Rel}\nolimits}
\newcommand{\Mod}{\mathop{\rm Mod}\nolimits}
\newcommand{\Space}{\mathop{\rm Space}\nolimits}
\newcommand{\Vect}{\mathop{\rm Vect}\nolimits}
\newcommand{\FinVect}{\mathop{\rm FinVect}\nolimits}
\newcommand{\Matr}{\mathop{\rm Matr}\nolimits}
\newcommand{\Ab}{\mathop{\rm Ab}\nolimits}
\newcommand{\Gr}{\mathop{\rm Gr}\nolimits}
\newcommand{\Grp}{\mathop{\rm Grp}\nolimits}
\newcommand{\Hol}{\mathop{\rm Hol}\nolimits}
\newcommand{\Grpd}{\mathop{\rm Grpd}\nolimits}
\newcommand{\Mon}{\mathop{\rm Mon}\nolimits}
\newcommand{\FinSet}{\mathop{\rm FinSet}\nolimits}
\newcommand{\Sch}{\mathop{\rm Sch}\nolimits}
\newcommand{\AffSch}{\mathop{\rm AffSch}\nolimits}
\newcommand{\Idem}{\mathop{\rm Idem}\nolimits}
\newcommand{\SIdem}{\mathop{\rm SIdem}\nolimits}
\newcommand{\Aut}{\mathop{\rm Aut}\nolimits}
\newcommand{\Ord}{\mathop{\rm Ord}\nolimits}
\newcommand{\coker}{\mathop{\rm coker}\nolimits}
\newcommand{\ch}{\mathop{\rm char}\nolimits}%characteristic
\newcommand{\Sym}{\mathop{\rm Sym}\nolimits}
\newcommand{\adj}{\mathop{\rm adj}\nolimits}
\newcommand{\dil}{\mathop{\rm dil}\nolimits}
\newcommand{\Cl}{\mathop{\rm Cl}\nolimits}
\newcommand{\Diff}{\mathop{\rm Diff}\nolimits}
\newcommand{\End}{\mathop{\rm End}\nolimits}
\newcommand{\Hom}{\mathop{\rm Hom}\nolimits}% preferred
\newcommand{\Gal}{\mathop{\rm Gal}\nolimits}
\newcommand{\Pos}{\mathop{\rm Pos}\nolimits}
\newcommand{\Ad}{\mathop{\rm Ad}\nolimits}
\newcommand{\GL}{\mathop{\rm GL}\nolimits}
\newcommand{\SL}{\mathop{\rm SL}\nolimits}
\newcommand{\vol}{\mathop{\rm vol}\nolimits}
\newcommand{\reg}{\mathop{\rm reg}\nolimits}
\newcommand{\Or}{\mathop{\rm O}\nolimits}
\newcommand{\U}{\mathop{\rm U}\nolimits}
\newcommand{\SOr}{\mathop{\rm SO}\nolimits}
\newcommand{\SU}{\mathop{\rm SU}\nolimits}
\newcommand{\Spin}{\mathop{\rm Spin}\nolimits}
\newcommand{\Sp}{\mathop{\rm Sp}\nolimits}
\newcommand{\Int}{\mathop{\rm Int}\nolimits}
\newcommand{\im}{\mathop{\rm im}\nolimits}
\newcommand{\dom}{\mathop{\rm dom}\nolimits}
\newcommand{\di}{\mathop{\rm div}\nolimits}
\newcommand{\cod}{\mathop{\rm cod}\nolimits}
\newcommand{\colim}{\mathop{\rm colim}\nolimits}
\newcommand{\ad}{\mathop{\rm ad}\nolimits}
\newcommand{\PSL}{\mathop{\rm PSL}\nolimits}
\newcommand{\PGL}{\mathop{\rm PGL}\nolimits}
\newcommand{\sep}{\mathop{\rm sep}\nolimits}
\newcommand{\MCG}{\mathop{\rm MCG}\nolimits}
\newcommand{\oMCG}{\mathop{\rm MCG^+}\nolimits}
\newcommand{\Spec}{\mathop{\rm Spec}\nolimits}
\newcommand{\rank}{\mathop{\rm rank}\nolimits}
\newcommand{\diverg}{\mathop{\rm div}\nolimits}%Divergence
\newcommand{\disc}{\mathop{\rm disc}\nolimits}
\newcommand{\sign}{\mathop{\rm sign}\nolimits}
\newcommand{\Arf}{\mathop{\rm Arf}\nolimits}
\newcommand{\Pic}{\mathop{\rm Pic}\nolimits}
\newcommand{\Tr}{\mathop{\rm Tr}\nolimits}
\newcommand{\res}{\mathop{\rm res}\nolimits}
\newcommand{\Proj}{\mathop{\rm Proj}\nolimits}
\newcommand{\mult}{\mathop{\rm mult}\nolimits}
\newcommand{\N}{\mathop{\rm N}\nolimits}
\newcommand{\lk}{\mathop{\rm lk}\nolimits}
\newcommand{\Pf}{\mathop{\rm Pf}\nolimits}
\newcommand{\sgn}{\mathop{\rm sgn}\nolimits}
\newcommand{\grad}{\mathop{\rm grad}\nolimits}
\newcommand{\lcm}{\mathop{\rm lcm}\nolimits}
\newcommand{\Ric}{\mathop{\rm Ric}\nolimits}
\newcommand{\Hess}{\mathop{\rm Hess}\nolimits}
\newcommand{\sn}{\mathop{\rm sn}\nolimits}
\newcommand{\cut}{\mathop{\rm cut}\nolimits}
\newcommand{\tr}{\mathop{\rm tr}\nolimits}
\newcommand{\codim}{\mathop{\rm codim}\nolimits}
\newcommand{\ind}{\mathop{\rm index}\nolimits}
\newcommand{\rad}{\mathop{\rm rad}\nolimits}
\newcommand{\Rep}{\mathop{\rm Rep}\nolimits}
\newcommand{\Lie}{\mathop{\rm Lie}\nolimits}
\newcommand{\Der}{\mathop{\rm Der}\nolimits}
\newcommand{\hgt}{\mathop{\rm ht}\nolimits}
\newcommand{\Ider}{\mathop{\rm Ider}\nolimits}
\newcommand{\id}{\mathop{\rm id}\nolimits} \)</p>
  <div class="maketitle">
  <h2 class="titleHead">
2ND ORDER ELLIPTIC PDE
  </h2>
  <div class="authors"><span class="author" >
<span 
class="cmr-10">ISHAN LEVY</span>
  </span></div>
<div class="submaketitle">
  <div class="date" >
<!--l. 8--><p class="indent" >  <span 
class="cmti-12">Date</span>:&#x00A0;1/7/2019.</p></div></div></div>
  <h3 class="sectionHead"><span class="titlemark">1. </span> <a 
 id="x1-10001"></a>Introduction</h3>
<!--l. 10--><p class="noindent" >Here we will consider 2nd order linear elliptic PDE, which are PDE that behave similarly
to the standard Laplacian \(\Delta \) in Euclidean space. They can be interpreted as generalizing
what the Laplacian does: solutions are equilibria of the &#xFB02;ow of some quantity such as a
chemical. The extra generality comes from the fact that now other factors such as the
geometry of the ambient space, transport with in the space, and creation/depletion of the
quantity are considered. The Laplacian itself makes sense for a Riemannian manifold,
in which case it is the divergence of the di&#xFB00;erential of a function. The kinds
of spaces that much the discussion here easily extends to are those with &#xFB01;nite
volume, although for simplicity we will always work with a bounded open subset
\(U \subset \RR ^n\).
</p><!--l. 12--><p class="indent" >  An elliptic 2nd order operator is a partial di&#xFB00;erential operator of the form
&#x0028;Einstein notation is used throughout&#x0029; \(Lu = -(a_{ij}u_{x_i}){x_j} + b_i u_{x_i} + c u\), where \(a_{ij},b_i,c\) are functions, and \((a_{ij})\) is positive
de&#xFB01;nite at each point. We will usually want \(L\) to be uniformly elliptic, meaning that \(a_{ij}\)
is uniformly positive de&#xFB01;nite, or satis&#xFB01;es \(a_{ij}\xi _i \xi _j \geq C|\xi |^2\) on \(U\) for some \(C&gt;0\). We will also assume
\(a_{ij} = a_{ji}\).
</p>
  <h3 class="sectionHead"><span class="titlemark">2. </span> <a 
 id="x1-20002"></a>Existence and uniqueness</h3>
<!--l. 16--><p class="noindent" >In this section we will assume \(a_{ij},b_i,c \in L^\infty (U)\).
                                                                                  

                                                                                  
</p><!--l. 18--><p class="indent" >  It can be hard in general to &#xFB01;nd explicit solutions to \(Lu = f\) &#x0028;one can try to &#xFB01;nd Green&#x2019;s
functions for example&#x0029;, but using some functional analysis it is possible to show weak
solutions exist and are sometimes unique. Namely, we will recast solving the PDE \(Lu = f\), \(u = 0\)
on \(\partial U\) as follows: If \(Lu = f\), then for any test function \(v \in C^\infty _0(U)\), we can integrate by parts to get
\[ B[u,v]:= \int _U a_{ij}u_{x_i}v_{x_j} + b_iu_{x_i}v + cuv = \int _U Luv = \int _U fv = \langle f,v\rangle \]
</p><!--l. 21--><p class="indent" >  Note that \(B[u,v]\) de&#xFB01;ned above is a bilinear form that makes sense for \(u,v \in H_0^1(U)\).
</p>
  <div class="newtheorem">
<!--l. 23--><p class="noindent" ><span class="head">
<a 
 id="x1-2001r1"></a>
<span 
class="cmbx-12">De&#xFB01;nition 2.1.</span>  </span><span 
class="cmti-12">A weak solution of</span> \(Lu=f,f \in H^{-1}(U)\)<span 
class="cmti-12">,</span> \(u \in H^1_0(U)\) <span 
class="cmti-12">is an element</span> \(u\) <span 
class="cmti-12">such that for all</span> \(v\)<span 
class="cmti-12">,</span> \(B[u,v] = \langle f,v\rangle \)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 27--><p class="indent" >  Note that this formulation of the problem is more symmetric in \(u\) and v. Namely, if we
similarly de&#xFB01;ne a weak solution for the bilinear form \(B^*[u,v] = B[v,u]\), and the \(b_i\) are \(C^1(\overline{U})\), then \(u\) will be a weak
solution of \(L^*u = f\), where \(L^*\) is the adjoint elliptic operator \(L^*u = -(a_{ij}u_{x_j})_{x_i} - b_ju_{x_i} + (c-b_{i,x_i})u\).
</p><!--l. 29--><p class="indent" >  The &#xFB01;rst tool from functional analysis that will give solutions is the Lax-Milgram
Theorem, which can be viewed as an asymmetric generalization of the Riesz representation
theorem.
</p>
  <div class="newtheorem">
<!--l. 31--><p class="noindent" ><span class="head">
<a 
 id="x1-2002r2"></a>
<span 
class="cmbx-12">Theorem 2.2 </span>&#x0028;Lax-Milgram&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Let</span>  \(B\)  <span 
class="cmti-12">be  a  bilinear  form  on  a  Hilbert  space</span>  \(H\)  <span 
class="cmti-12">that</span>
<span 
class="cmti-12">satis&#xFB01;es</span> \(B[u,v] \leq C\Vert u \Vert \Vert v\Vert \)<span 
class="cmti-12">,</span> \(B[u,u] \geq c\Vert u \Vert ^2\)<span 
class="cmti-12">. Then</span> \(u \to B[u,-]\) <span 
class="cmti-12">de&#xFB01;nes an isomorphism of</span> \(H\) <span 
class="cmti-12">and</span> \(H^*\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 35--><p class="indent" >  Unfortunately, our \(B\) will not always satisfy exactly the conditions of the above theorem.
But if we de&#xFB01;ne \(B_\mu [u,v] = B[u,v] + \mu \langle u,v \rangle \), then for su&#xFB03;ciently large \(\mu \), \(B_\mu [u,v]\) will satisfy the Lax-Milgram theorem. Note
uniform ellipticity is needed to get \(B_\mu [u,u] \geq c\Vert u \Vert ^2\). A solution for \(B_\mu \) will be a weak solution for
\(L+\mu I\).
</p>
  <div class="newtheorem">
<!--l. 37--><p class="noindent" ><span class="head">
                                                                                  

                                                                                  
<a 
 id="x1-2003r3"></a>
<span 
class="cmbx-12">Theorem 2.3.</span>  </span><span 
class="cmti-12">There is a</span> \(\gamma \geq 0\) <span 
class="cmti-12">such that for each</span> \(\mu \geq \gamma \)<span 
class="cmti-12">, and each</span> \(f \in H^{-1}(U)\)<span 
class="cmti-12">, there is a unique weak</span>
<span 
class="cmti-12">solution of</span> \(L_\mu = L + \mu u = f\) <span 
class="cmti-12">in</span> \(H^1_0(U)\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 41--><p class="indent" >  In the case that \(b_i \equiv 0, c \geq 0\), then \(\gamma \) is 0, so there is a unique solution.
</p><!--l. 43--><p class="indent" >  To an extent we can &#xFB01;x the addition of the \(\mu \) using the Fredholm theory for compact
operators. For su&#xFB03;ciently large \(\mu \), \(L_\mu \) is an isomorphism, so we can consider \(L_\mu ^{-1}\) as a
map from \(L^2(U) \to L^2(U)\). As we have passed through the inclusion \(H_0^1(U) \to L^2(U)\), which is compact by the
Rellich-Kondrachov compactness theorem, \(L_\mu ^{-1}\) is compact. Finally note that if \(f \in L^2(U)\), \(u\) is a weak
solution of \(Lu = f\) i&#xFB00; \(L_\mu (u) = \mu u + f\) i&#xFB00; \(u - \mu L_\mu ^{-1}(u) = f\). But \(K := \mu L_\mu ^{-1}\) is compact, so the Fredholm alternative gives the following
theorem:
</p>
  <div class="newtheorem">
<!--l. 46--><p class="noindent" ><span class="head">
<a 
 id="x1-2004r4"></a>
<span 
class="cmbx-12">Theorem 2.4.</span>  </span><span 
class="cmti-12">Either there is a unique weak solution to</span> \(Lu = f\) <span 
class="cmti-12">on</span> \(U\)<span 
class="cmti-12">,</span> \(u = 0\) <span 
class="cmti-12">on</span> \(\partial U\) <span 
class="cmti-12">for each</span> \(f \in L^2(U)\)<span 
class="cmti-12">, or</span>
<span 
class="cmti-12">there is a &#xFB01;nite and nonzero dimensional space of weak solutions to the homogeneous</span>
<span 
class="cmti-12">problem</span> \(Lu = 0\) <span 
class="cmti-12">on</span> \(U\)<span 
class="cmti-12">,</span> \(u = 0\) <span 
class="cmti-12">on</span> \(\partial U\)<span 
class="cmti-12">. Moreover in the second case, the dimension of solutions to the</span>
<span 
class="cmti-12">homogeneous problem is the same as the dimension of solutions to the homogeneous</span>
<span 
class="cmti-12">problem of the adjoint operator</span> \(L^*\)<span 
class="cmti-12">. There is a solution to</span> \(Lu = f\) <span 
class="cmti-12">i&#xFB00;</span> \(f\) <span 
class="cmti-12">is orthogonal to all weak</span>
<span 
class="cmti-12">solutions to</span> \(L^*v= 0\) <span 
class="cmti-12">on</span> \(U\)<span 
class="cmti-12">,</span> \(v = 0\) <span 
class="cmti-12">on</span> \(\partial U\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 50--><p class="indent" >  Moreover, note that an eigenvector of \(K\) with eigenvalue \(\frac \mu{\mu +\lambda }\) is an eigenvector of \(L\) with
eigenvalue \(\lambda \). Thus the general knowledge of the spectrum of compact operators
gives:
</p>
  <div class="newtheorem">
<!--l. 52--><p class="noindent" ><span class="head">
<a 
 id="x1-2005r5"></a>
<span 
class="cmbx-12">Theorem 2.5.</span>  </span><span 
class="cmti-12">There is a set</span> \(\{\lambda _i\}\)<span 
class="cmti-12">, that is either &#xFB01;nite, or an increasing sequence, such</span>
                                                                                  

                                                                                  
<span 
class="cmti-12">that</span> \(Lu = \lambda u + f\)<span 
class="cmti-12">,</span> \(f \in L^2(U)\) <span 
class="cmti-12">has a unique weak solution i&#xFB00;</span> \(\lambda \) <span 
class="cmti-12">is not one of the</span> \(\lambda _i\)<span 
class="cmti-12">, and if</span> \(\{\lambda _i\}\) <span 
class="cmti-12">is in&#xFB01;nite, the</span> \(\lambda _i\) <span 
class="cmti-12">tend</span>
<span 
class="cmti-12">to in&#xFB01;nity.</span>
</p>
  </div>
  <h3 class="sectionHead"><span class="titlemark">3. </span> <a 
 id="x1-30003"></a>Regularity</h3>
<!--l. 57--><p class="noindent" >Now that we can know weak solutions exist, we can ask how regular they are. For
motivation, suppose \(u \in H^2_0(U)\) is a weak solution to \(-\Delta u = f\), and by approximation and integrating by parts
twice, we can obtain the identity \(\int _U f^2 = \int _U \Delta u^2 = \int _U u_{x_ix_i}u_{x_jx_j} = \int _U u_{x_ix_j}u_{x_jx_i} = \int _U |D^2u|^2\), so in particular we see that the \(H^2\) norm of u can be
bounded by a constant times the sum of the \(L^2\) norms of \(u\) and \(f\). This tells use that if \(f \in L^2(U), u \in H^1(U)\), we
might still expect \(u\) to be in \(H^2(U)\) and have similar estimates on its norm. Moreover, since \(-\Delta D^\alpha u = D^\alpha \) for
each multi-index \(\alpha \) &#x0028;this can be interpreted in the sense of distributions&#x0029;, we can expect \(u \in H^{m+2}(U)\) if
\(f \in H^{m}(U)\).
</p><!--l. 59--><p class="indent" >  The way to show this is to put uniform norm bounds on the di&#xFB00;erence quotients \(D^h_kDu\) for
small \(h\), as then the di&#xFB00;erence quotients will have a subsequence weakly converging to a
weak second derivative. Working with di&#xFB00;erence quotients in general involves
having some room to take the di&#xFB00;erence quotient, so we must &#xFB01;rst restrict to the
interior of \(U\). The following theorem is local so we can only require that \(L\) be elliptic
rather than uniformly elliptic and it is possible to remove the restriction that \(U\) is
bounded.
</p>
  <div class="newtheorem">
<!--l. 61--><p class="noindent" ><span class="head">
<a 
 id="x1-3001r1"></a>
<span 
class="cmbx-12">Theorem 3.1.</span>  </span> <span 
class="cmti-12">Suppose</span> \(a_{ij} \in C^1(U), b_i,c \in L^\infty _{loc}(U),f \in L^2(U)\)<span 
class="cmti-12">, and suppose</span> \(u \in H^1(U)\) <span 
class="cmti-12">is a weak solution of</span> \(Lu=f\)<span 
class="cmti-12">. Then</span> \(u \in H^2_{loc}(U)\) <span 
class="cmti-12">and for each</span>
<span 
class="cmti-12">open</span> \(V\) <span 
class="cmti-12">with</span> \(\overline{V} \subset U\)<span 
class="cmti-12">, there is a constant only depending on</span> \(V,U,L\) <span 
class="cmti-12">such that</span> \(\Vert u \Vert _{H^2(V)} \leq C(\Vert u \Vert _{L^2(U)} + \Vert f \Vert _{L^2(U)})\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 65--><p class="indent" >  In particular, note \(Lu = f\) in \(L^2(U)\) if we view \(L\) as a map \(H^2(U) \to L^2(U)\). By inducting, we can obtain the following
result:
</p>
  <div class="newtheorem">
<!--l. 66--><p class="noindent" ><span class="head">
<a 
 id="x1-3002r2"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">Theorem 3.2 </span>&#x0028;Local regularity&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Suppose</span> \(a_{ij},b_i,c \in C^{m+1}(U), f \in H^m(U)\)<span 
class="cmti-12">, and suppose</span> \(u \in H^1(U)\) <span 
class="cmti-12">is a weak solution of</span> \(Lu=f\)<span 
class="cmti-12">.</span>
<span 
class="cmti-12">Then</span> \(u \in H^{m+2}_{loc}(U)\) <span 
class="cmti-12">and for each open</span> \(V\) <span 
class="cmti-12">with</span> \(\overline{V} \subset U\)<span 
class="cmti-12">, there is a constant only depending on</span> \(V,U,L,m\) <span 
class="cmti-12">such that</span> \(\Vert u \Vert _{H^{m+2}(V)} \leq C(\Vert u \Vert _{L^2(U)} + \Vert f \Vert _{H^{m}(U)})\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 70--><p class="indent" >  From the Sobolev inequalities, it follows that if \(a_{ij},b_i,c,f\) are smooth, then the weak solution \(u\) is
too.
</p><!--l. 72--><p class="indent" >  Finally, we can ask whether in the above theorem \(u \in H^{m+2}(U)\). We can achieve this if we add
assumptions about the behavior of \(u\) at the boundary and assumptions about the regularity
of the boundary. We can for example assume \(u\) vanishes on the boundary and \(\partial U\) is
\(C^{m+2}\). The way to prove this is to prove Theorem <a 
href="#x1-3001r1">3.1<!--tex4ht:ref: regularity --></a> in the local model \(B(0,1)\cap \RR ^n_{x_n\geq 0}\). We can
still use di&#xFB00;erence quotients in all directions except the \(x_n\) direction to get similar
bounds. For the \(x_n\) direction, since the PDE \(Lu = f\) is uniformly elliptic, we also have \(a_{nn}u_{x_n x_n} = Lu-f+a_{nn} u_{x_n x_n}\), and
the right hand side is not dependent on \(u_{x_nx_n}\), and \(a_{nn} \geq \ee &gt;0\) for some \(\ee \) so we can bound \(u_{x_nx_n}\) in
terms of the other second derivatives. If the boundary is \(C^{m+2}\), we can locally do a
change of variables that preserves the uniform ellipticity of the PDE and use
compactness to reduce to this model case. Inducting as before we get the following
result:
</p>
  <div class="newtheorem">
<!--l. 75--><p class="noindent" ><span class="head">
<a 
 id="x1-3003r3"></a>
<span 
class="cmbx-12">Theorem 3.3 </span>&#x0028;Global regularity&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Suppose</span> \(a_{ij},b_i,c \in C^{m+1}(\overline{U}), f \in H^m(U)\)<span 
class="cmti-12">,</span> \(\partial U\) <span 
class="cmti-12">is</span> \(C^{m+2}\)<span 
class="cmti-12">, and suppose</span> \(u \in H^1_0(U)\) <span 
class="cmti-12">is a weak solution</span>
<span 
class="cmti-12">of</span> \(Lu=f\)<span 
class="cmti-12">. Then</span> \(u \in H^{m+2}(U)\) <span 
class="cmti-12">and there is a constant only depending on</span> \(U,L,m\) <span 
class="cmti-12">such that</span> \(\Vert u \Vert _{H^{m+2}(U)} \leq C(\Vert u \Vert _{L^2(U)} + \Vert f \Vert _{H^{m}(U)})\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 79--><p class="indent" >  If \(a_{ij},f,b_i,c\) are in \(C^\infty (\bar U)\) and \(\partial U\) is \(C^\infty \), then the above result and the Sobolev inequalities give that
\(u \in C^\infty (\overline U)\).
</p>
  <h3 class="sectionHead"><span class="titlemark">4. </span> <a 
 id="x1-40004"></a>Maximum principles</h3>
<!--l. 83--><p class="noindent" >Like \(\Delta \), general elliptic operators \(L\) satisfy maximum principles. In this section we will assume
\(u \in C^2(U)\cap C(\overline{U})\). If \(c \equiv 0\), then at an interior maximum of \(u\), we have \(Lu = -a_{ij}u_{x_ix_j}\). We can use the ellipticity condition to see
that since the Hessian is negative de&#xFB01;nite and \(a_{ij}\) diagonalizable, \(Lu \geq 0\). Thus if \(u\) is a strict
                                                                                  

                                                                                  
subsolution of \(L\), meaning \(Lu &lt; 0\), maxima must occur at the boundary. We can remove the strict
assumption if \(u\) is uniformly elliptic by using a sequence of subsolutions of \(u\) converging to \(u\),
giving the following:
</p>
  <div class="newtheorem">
<!--l. 85--><p class="noindent" ><span class="head">
<a 
 id="x1-4001r1"></a>
<span 
class="cmbx-12">Theorem 4.1.</span>  </span><span 
class="cmti-12">If</span> \(c \equiv 0,Lu \leq 0\)<span 
class="cmti-12">, then</span> \(\max _{\bar U}u \leq \max _{\partial U}u\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 89--><p class="indent" >  If \(c \geq 0\), and \(u\) is a subsolution, we can apply the above theorem on the open set where \(u &gt; 0\) to
obtain:
</p>
  <div class="newtheorem">
<!--l. 91--><p class="noindent" ><span class="head">
<a 
 id="x1-4002r2"></a>
<span 
class="cmbx-12">Theorem 4.2.</span>  </span><span 
class="cmti-12">If</span> \(c \geq 0,Lu\leq 0\)<span 
class="cmti-12">, then either</span> \(u \leq 0\) <span 
class="cmti-12">or</span> \(\max _{\bar U}u \leq \max _{\partial U}u\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 95--><p class="indent" >  A stronger maximal principle states that if the maximum is obtained on the interior,
then \(u\) is constant.
</p><!--l. 97--><p class="indent" >  It follows from Hopf&#x2019;s lemma, which is a technical analytic computation.
</p>
  <div class="newtheorem">
<!--l. 98--><p class="noindent" ><span class="head">
<a 
 id="x1-4003r3"></a>
<span 
class="cmbx-12">Lemma 4.3 </span>&#x0028;Hopf&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Assume</span> \(u \in C^2(U) \cap C^1(\bar (U))\) <span 
class="cmti-12">and</span> \(c \equiv 0\)<span 
class="cmti-12">, and</span> \(u\) <span 
class="cmti-12">is a subsolution to</span> \(L\)<span 
class="cmti-12">. If there is a point</span>
\(x_0 \in \partial U\) <span 
class="cmti-12">that satis&#xFB01;es</span> \(u(x_0) &gt; u(x)\) <span 
class="cmti-12">for all</span> \(x \in U\)<span 
class="cmti-12">, and such that</span> \(u\) <span 
class="cmti-12">satis&#xFB01;es the interior ball condition, namely</span>
<span 
class="cmti-12">there is a ball</span> \(B\) <span 
class="cmti-12">in</span> \(U\) <span 
class="cmti-12">with</span> \(x_0\) <span 
class="cmti-12">on the boundary, then</span> \(\frac{\partial u}{\partial \nu }(x_0) &gt;0\)<span 
class="cmti-12">, where</span> \(\nu \) <span 
class="cmti-12">is the outer normal to</span> \(B\) <span 
class="cmti-12">at</span> \(x_0\)<span 
class="cmti-12">.</span>
<span 
class="cmti-12">If</span> \(c,u(x_0)\geq 0\)<span 
class="cmti-12">, the same conclusion holds.</span>
</p>
  </div>
                                                                                  

                                                                                  
<!--l. 102--><p class="indent" >  By applying Hopf&#x2019;s lemma to a point \(x\) on the interior of \(U\) that maximizes \(u\), but in one
direction is surrounded by points that don&#x2019;t maximize \(U\), we get that \(\frac{\partial u}{\partial \nu }(x) &gt;0\), by choosing a ball
containing non-maximizing points of \(u\) with \(x\) on the boundary. This contradicts the fact
that \(Du(x) = 0\), so we get
</p>
  <div class="newtheorem">
<!--l. 104--><p class="noindent" ><span class="head">
<a 
 id="x1-4004r4"></a>
<span 
class="cmbx-12">Theorem 4.4.</span>  </span><span 
class="cmti-12">If</span> \(u \in C^2(U) \cap C(\bar U)\)<span 
class="cmti-12">, U connected,</span> \(c \equiv 0\) <span 
class="cmti-12">and</span> \(u\) <span 
class="cmti-12">is a subsolution of</span> \(L\) <span 
class="cmti-12">that attains a maximum</span>
<span 
class="cmti-12">on its interior, then</span> \(u\) <span 
class="cmti-12">is constant.</span>
</p>
  </div>
<!--l. 107--><p class="indent" >  The version for \(c\geq 0\) is:
</p>
  <div class="newtheorem">
<!--l. 109--><p class="noindent" ><span class="head">
<a 
 id="x1-4005r5"></a>
<span 
class="cmbx-12">Theorem 4.5.</span>  </span><span 
class="cmti-12">If</span> \(u \in C^2(U) \cap C(\bar U)\)<span 
class="cmti-12">,</span> \(U\) <span 
class="cmti-12">connected,</span> \(c \geq 0\) <span 
class="cmti-12">and</span> \(u\) <span 
class="cmti-12">is a subsolution of</span> \(L\) <span 
class="cmti-12">that attains a nonnegative</span>
<span 
class="cmti-12">maximum on its interior, then</span> \(u\) <span 
class="cmti-12">is constant.</span>
</p>
  </div>
<!--l. 112--><p class="indent" >  Finally just as for harmonic functions, if \(Lu=0\), then nearby points of \(u\) are comparable.
</p>
  <div class="newtheorem">
<!--l. 114--><p class="noindent" ><span class="head">
<a 
 id="x1-4006r6"></a>
<span 
class="cmbx-12">Theorem 4.6 </span>&#x0028;Harnack&#x2019;s inequality&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">If</span> \(Lu=0, u \in C^2(U)\)<span 
class="cmti-12">, then for any connected</span> \(V\) <span 
class="cmti-12">with</span> \(\bar V \subset U\) <span 
class="cmti-12">we have</span> \(\sup _Vu\leq C\inf _Vu\)
<span 
class="cmti-12">where</span> \(C\) <span 
class="cmti-12">depends on</span> \(L,V\)<span 
class="cmti-12">.</span>
</p>
  </div>
                                                                                  

                                                                                  
  <h3 class="sectionHead"><span class="titlemark">5. </span> <a 
 id="x1-50005"></a>Eigenvalues and Eigenfunctions</h3>
<!--l. 120--><p class="noindent" >Suppose \(L\) is of the form \(Lu = -(a_{ij}u_{x_i})_{x_j}\). Then from earlier we have that \(L\) is an isomorphism \(H^1_0(U) \to H^{-1}(U)\). Moreover as
from earlier we have \(L^{-1}: L^2(U) \to L^2(U)\) is a compact operator, and since \(L\) is self adjoint, \(L^{-1}\) is too. Moreover, \(\langle L^{-1}(u),u\rangle = B[L^{-1}(u),L^{-1}(u)]\geq 0\).
Thus the spectral theory of symmetric compact operators gives the following
theorem:
</p>
  <div class="newtheorem">
<!--l. 122--><p class="noindent" ><span class="head">
<a 
 id="x1-5001r1"></a>
<span 
class="cmbx-12">Theorem 5.1.</span>  </span><span 
class="cmti-12">Suppose</span> \(L\) <span 
class="cmti-12">is of the form above. Then the eigenvalues of</span> \(L\) <span 
class="cmti-12">are real,</span>
<span 
class="cmti-12">positive and tending to in&#xFB01;nity. Eigenvectors form an orthonormal basis, and the</span>
<span 
class="cmti-12">eigenspaces are &#xFB01;nite dimensional.</span>
</p>
  </div>
<!--l. 126--><p class="indent" >  By regularity, the eigenvectors are all smooth functions if the coe&#xFB03;cients of \(L\) are smooth,
which we will assume.
</p><!--l. 128--><p class="indent" >  The &#xFB01;rst &#x0028;principle&#x0029; eigenvalue \(\lambda _1\) is very special. If \(w_k\) are eigenvalues that are an
orthonormal basis of \(L^2\), then since \(B\) satis&#xFB01;es the Lax-Milgram Theorem and is symmetric, \(w_k\) is
also an orthonormal basis of the inner product given by \(B\). Let \(s(u) = \frac{B[u,u]}{\langle u,u\rangle }\). Then one &#xFB01;nds that \(s(u) \geq \lambda _1\) with
equality holding i&#xFB00; \(u\) is in the \(\lambda _1\) eigenspace. This condition for being in the eigenspace can
then show that \(\max (u,0), \min (u,0)\) are in the eigenspace if \(u\) is. By the strong maximal principle, \(u^+,u^-\) are strictly
positive/negative or \(0\). In particular, \(u\) must have been either identically \(0\), or never \(0\). All
together we have:
</p>
  <div class="newtheorem">
<!--l. 130--><p class="noindent" ><span class="head">
<a 
 id="x1-5002r2"></a>
<span 
class="cmbx-12">Theorem 5.2.</span>  </span>\(\lambda _1 = \inf _{u\neq 0} s(u)\)<span 
class="cmti-12">,  the  eigenspace  of</span>  \(\lambda _1\)  <span 
class="cmti-12">is</span>  \(1\)<span 
class="cmti-12">-dimensional  and  spanned  by  a  positive</span>
<span 
class="cmti-12">function.</span>
</p>
  </div>
<!--l. 133--><p class="indent" >  For a non-symmetric elliptic operator, we cannot apply the spectral theory of
symmetric compact operators, but nevertheless we can obtain the following similar
result:
                                                                                  

                                                                                  
</p>
  <div class="newtheorem">
<!--l. 135--><p class="noindent" ><span class="head">
<a 
 id="x1-5003r3"></a>
<span 
class="cmbx-12">Theorem 5.3.</span>  </span><span 
class="cmti-12">There is an eigenvalue</span> \(\lambda _1 \in \RR \) <span 
class="cmti-12">such that any complex eigenvalue satis&#xFB01;es</span> \(\real (\lambda ) \geq \lambda _1\)<span 
class="cmti-12">,</span>
<span 
class="cmti-12">and moreover the eigenspace of</span> \(\lambda _1\) <span 
class="cmti-12">is</span> \(1\)<span 
class="cmti-12">-dimensional and spanned by a positive function.</span>
</p>
  </div>
  <h3 class="sectionHead"><span class="titlemark">6. </span> <a 
 id="x1-60006"></a>Exercises</h3>
<!--l. 140--><p class="noindent" >From now on all coe&#xFB03;cients are smooth and \(U\) is bounded, has smooth boundary, and
operators \(L\) are uniformly elliptic.
</p>
  <div class="newtheorem">
<!--l. 142--><p class="noindent" ><span class="head">
<a 
 id="x1-6001r1"></a>
<span 
class="cmbx-12">Exercise 6.0.1 </span>&#x0028;2&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">A function</span> \(u \in H^2_0(U)\) <span 
class="cmti-12">is a weak solution of</span> \(\Delta ^2u=f,u=\frac{\partial u}{\partial \nu } = 0\) <span 
class="cmti-12">i&#xFB00;</span> \(\int _U \Delta u \Delta v = \int _U fv\) <span 
class="cmti-12">for any</span> \(v \in H^2_0(U)\)<span 
class="cmti-12">. Show that for</span> \(f \in L^2(U)\)<span 
class="cmti-12">,</span>
<span 
class="cmti-12">there is a unique weak solution of</span> \(\Delta ^2u = f\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 146--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>We  will  show  that  the  bilinear  form  \(B[u,v] = \int _U\Delta u \Delta v\)  satis&#xFB01;es  the  conditions  of  the
Lax-Milgram theorem. That theorem will then immediately imply the result.
</p><!--l. 148--><p class="indent" >  Indeed, \(B\) is bilinear, \(|B[u,v]| \leq \Vert \Delta u \Vert _{L^2(U)} \Vert \Delta v \Vert _{L^2(U)} \leq \Vert D^2u \Vert _{L^2(U)} \Vert D^2 v \Vert _{L^2(U)} \leq \Vert D^2u \Vert _{H^2(U)} \Vert D^2 v \Vert _{H^2(U)}\). For the other estimate, note that for any \(u \in H^2_0(U)\), we have \(\Vert u_{x_ix_i}u_{x_jx_j} \Vert _{L^1(U)} = \Vert u_{x_ix_j}u_{x_jx_i}\Vert _{L^1(U)}\). This
is proven by approximating \(u\) by compactly supported smooth functions, for which
it  follows  by  integrating  by  parts  twice.  Thus  we  can  bound  the  mixed  partial
derivatives of \(u\) with \(\int _U (\Delta u)^2\), so we have \(B[u,u] \geq C\int _U |D^2u|^2\). By applying Poincare&#x2019;s inequality twice, we then
have \(C\int _U|D^2u|^2\geq C'\Vert u \Vert _{H^2(U)}^2\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
                                                                                  

                                                                                  
  </div>
  <div class="newtheorem">
<!--l. 152--><p class="noindent" ><span class="head">
<a 
 id="x1-6002r2"></a>
<span 
class="cmbx-12">Exercise 6.0.2 </span>&#x0028;4&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Let</span> \(u \in H^1(\RR ^n)\) <span 
class="cmti-12">be a weak compactly supported solution of</span> \(-\Delta u + c(u) = f\)<span 
class="cmti-12">, where</span> \(f \in L^2(\RR ^n)\)<span 
class="cmti-12">, c a</span>
<span 
class="cmti-12">non-decreasing smooth function with</span> \(c(0) = 0\)<span 
class="cmti-12">. Prove</span> \(u \in H^2(\RR ^n)\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 156--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>As \(u\) is a weak solution, for each \(v \in H^1(\RR ^n)\) we have \(\int Du\cdot Dv = \int fv-c(u)v\). Set \(v = -D^{-h}D_k^h(u)\), \(h\) small. Then the left hand
side is \(-\int Du DD_k^{-h}D_k^{h}(u) = \int |DD^h_k(u)|^2\). Note that \(\int v^2 = \int (-D^{-h}_kD^h_ku)^2 \leq C \int |D^h_kDu|^2\) for small \(h\), where \(C\) doesn&#x2019;t depend on \(h\) as \(u\) is compactly supported.
Thus by Cauchy inequality with \(\ee \) the right hand side is \( \leq \frac 1 2 \int |D^h_kDu|^2 + C'\int |f-c(u)|^2\). Thus \(\int |D^h_kDu|^2 \leq 2C'\int |f-c(u)|^2\), and the right hand
side doesn&#x2019;t depend on \(h\), so \(u\) has weak second derivatives in \(L^2(\RR ^n)\), and \(u \in H^2(\RR ^n)\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 160--><p class="noindent" ><span class="head">
<a 
 id="x1-6003r3"></a>
<span 
class="cmbx-12">Exercise 6.0.3 </span>&#x0028;7&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Assume</span> \(U\) <span 
class="cmti-12">is connected. Use</span> \((a)\) <span 
class="cmti-12">energy methods and</span> \((b)\) <span 
class="cmti-12">the maximum</span>
<span 
class="cmti-12">principle to show that the only smooth solutions to</span> \(-\Delta u = 0\) <span 
class="cmti-12">on</span> \(U\)<span 
class="cmti-12">,</span> \(\frac{\partial u}{\partial \nu } = 0\) <span 
class="cmti-12">on</span> \(\partial U\) <span 
class="cmti-12">are constant.</span>
</p>
  <div class="proof">
<!--l. 164--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Here is a proof using energy methods. Integrating by parts gives \(0 = \int _U u\Delta u = \int _U |Du|^2\) so \(Du = 0\), and \(u\) is
constant.
</p><!--l. 166--><p class="indent" >  Here  is  a  proof  using  the  maximal  principle.  If  \(u\)  is  not  constant,  it  attains  a
maximum on the boundary. But by Hopf&#x2019;s Lemma, \(\frac{\partial u}{\partial \nu }\) is positive at that maximum,
contradicting the boundary condition. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
                                                                                  

                                                                                  
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 170--><p class="noindent" ><span class="head">
<a 
 id="x1-6004r4"></a>
<span 
class="cmbx-12">Exercise 6.0.4 </span>&#x0028;8&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Let</span> \(u \in H^1(U)\) <span 
class="cmti-12">be a bounded weak solution of</span> \(Lu = -\sum (a^{ij}u_{x_i})_{x_j} = 0\)<span 
class="cmti-12">. Then show that if</span> \(\phi \) <span 
class="cmti-12">is a</span>
<span 
class="cmti-12">convex smooth function, then</span> \(\phi (u)\) <span 
class="cmti-12">is a weak subsolution, meaning</span> \(B[\phi (u),v] \leq 0\) <span 
class="cmti-12">for all nonnegative</span>
\(v\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 172--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>By regularity, \(u\) is smooth and solves the PDE. Now observe that \(L\phi (u) = -\phi ''(u)(a_{ij}u_{x_i}u_{x_j}) \leq 0\) as \(a_{ij}\) is positive
de&#xFB01;nite, and \(\phi ''\) is positive. Thus integrating by parts gives \(B[\phi (u),v] = \int _U L\phi (u)v \leq 0\) as \(v \geq 0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
   
</body> 
</html>
                                                                                  

                                                                                  
                                                                                  


