<!DOCTYPE html> 
<html lang="en" xml:lang="en" > 
<head> <title>Lie Algebras</title> 
<meta  charset="UTF-8"" /> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" /> 
<link rel="stylesheet" type="text/css" href="Lie_Algebras.css" /> 
<meta name="src" content="Lie_Algebras.tex" /> 
<script>window.MathJax = { tex: { tags: "ams", inlineMath: [ ["\\\(","\\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true, processEnvironments: true, packages: ['base', 'color', 'ams', 'newcommand'] }, loader: { load: ['[tex]/color', '[tex]/ams', '[tex]/newcommand'] } }; </script> 
 <script type="text/javascript" async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>  
</head><body 
>
  <p style="display: none;">\( \newcommand{\cO}{\mathcal{O}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\GG}{\mathbb{G}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\LL}{\mathbb{L}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\SP}{\mathbb{S}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FF}{\mathbb{F}}
\renewcommand{\AA}{\mathbb{A}}
\newcommand{\sF}{\mathscr{F}}
\newcommand{\sC}{\mathscr{C}}
\newcommand{\ts}{\textsuperscript}
\newcommand{\mf}{\mathfrak}
\newcommand{\cc}{\mf{c}}
\newcommand{\mg}{\mf{g}}
\newcommand{\ma}{\mf{a}}
\newcommand{\mh}{\mf{h}}
\newcommand{\mn}{\mf{n}}
\newcommand{\mc}{\mf{c}}
\newcommand{\ul}{\underline}
\newcommand{\mz}{\mf{z}}
\newcommand{\me}{\mf{e}}
\newcommand{\mff}{\mf{f}}
\newcommand{\mm}{\mf{m}}
\newcommand{\mt}{\mf{t}}
\newcommand{\pp}{\mf{p}}
\newcommand{\qq}{\mf{q}}
\newcommand{\gl}{\mf{gl}}
\newcommand{\msl}{\mf{sl}}
\newcommand{\so}{\mf{so}}
\newcommand{\mfu}{\mf{u}}
\newcommand{\su}{\mf{su}}
\newcommand{\msp}{\mf{sp}}
\renewcommand{\aa}{\mf{a}}
\newcommand{\bb}{\mf{b}}
\newcommand{\sR}{\mathscr{R}}
\newcommand{\lb}{\langle}
\newcommand{\rb}{\rangle}
\newcommand{\ff}{\mf{f}}
\newcommand{\ee}{\epsilon}

\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\ceil}[1]{\lceil #1 \rceil}

\newcommand{\pushout}{\arrow[ul, phantom, "\ulcorner", very near start]}
\newcommand{\pullback}{\arrow[dr, phantom, "\lrcorner", very near start]}

\newcommand{\simp}[1]{#1^{\Delta^{op}}}

\newcommand{\arrowtcupp}[2]{\arrow[bend left=50, ""{name=U, below,inner sep=1}]{#1}\arrow[Rightarrow,from=U,to=MU,"#2"]}
\newcommand{\arrowtclow}[2]{\arrow[bend right=50, ""{name=L,inner sep=1}]{#1}\arrow[Rightarrow,from=LM,to=L]{}[]{#2}} % if you want to change some parameter of the label.
\newcommand{\arrowtcmid}[2]{\arrow[""{name=MU,inner sep=1},""{name=LM,below,inner sep=1}]{#1}[pos=.1]{#2}}
\newcommand{\dummy}{\textcolor{white}{\bullet}}


%for adjunction
\newcommand{\adjunction}[4]{
	#1\hspace{2pt}\colon #2	\leftrightharpoons #3 \hspace{2pt}\colon #4
}


%Math operators
\newcommand{\Set}{\mathop{\rm Set}\nolimits}
\newcommand{\Ind}{\mathop{\rm Ind}\nolimits}
\newcommand{\Sind}{\mathop{\rm Sind}\nolimits}
\newcommand{\Ext}{\mathop{\rm Ext}\nolimits}
\newcommand{\sd}{\mathop{\rm sd}\nolimits}
\newcommand{\Ex}{\mathop{\rm Ex}\nolimits}
\newcommand{\Out}{\mathop{\rm Out}\nolimits}
\newcommand{\Cyl}{\mathop{\rm Cyl}\nolimits}
\newcommand{\Path}{\mathop{\rm Path}\nolimits}
\newcommand{\Ch}{\mathop{\rm Ch}\nolimits}
\newcommand{\SSet}{\mathop{\rm \Set^{\Delta^{op}}}\nolimits}
\newcommand{\Sq}{\mathop{\rm Sq}\nolimits}
\newcommand{\Free}{\mathop{\rm Free}\nolimits}
\newcommand{\Maps}{\mathop{\rm Maps}\nolimits}
\newcommand{\LMaps}{\mathop{\rm LMaps}\nolimits}
\newcommand{\RMaps}{\mathop{\rm RMaps}\nolimits}
\newcommand{\MU}{\mathop{\rm MU}\nolimits}
\newcommand{\MSU}{\mathop{\rm MSU}\nolimits}
\newcommand{\MSp}{\mathop{\rm MSp}\nolimits}
\newcommand{\MSO}{\mathop{\rm MSO}\nolimits}
\newcommand{\MO}{\mathop{\rm MO}\nolimits}
\newcommand{\BU}{\mathop{\rm BU}\nolimits}
\newcommand{\BSU}{\mathop{\rm BSU}\nolimits}
\newcommand{\BSp}{\mathop{\rm BSp}\nolimits}
\newcommand{\BSO}{\mathop{\rm BSO}\nolimits}
\newcommand{\BO}{\mathop{\rm BO}\nolimits}
\newcommand{\Tor}{\mathop{\rm Tor}\nolimits}
\newcommand{\Cotor}{\mathop{\rm Cotor}\nolimits}
\newcommand{\imag}{\mathop{\rm Im}\nolimits}
\newcommand{\real}{\mathop{\rm Re}\nolimits}
\newcommand{\Cat}{\mathop{\rm Cat}\nolimits}
\newcommand{\Fld}{\mathop{\rm Fld}\nolimits}
\newcommand{\Frac}{\mathop{\rm Frac}\nolimits}
\newcommand{\Dom}{\mathop{\rm Dom}\nolimits}
\newcommand{\Hotc}{\mathop{\rm Hotc}\nolimits}
\newcommand{\Top}{\mathop{\rm Top}\nolimits}
\newcommand{\Ring}{\mathop{\rm Ring}\nolimits}
\newcommand{\CRing}{\mathop{\rm CRing}\nolimits}
\newcommand{\CGHaus}{\mathop{\rm CGHaus}\nolimits}
\newcommand{\Alg}{\mathop{\rm Alg}\nolimits}
\newcommand{\Bool}{\mathop{\rm Bool}\nolimits}
\newcommand{\hTop}{\mathop{\rm hTop}\nolimits}
\newcommand{\Nat}{\mathop{\rm Nat}\nolimits}
\newcommand{\Rel}{\mathop{\rm Rel}\nolimits}
\newcommand{\Mod}{\mathop{\rm Mod}\nolimits}
\newcommand{\Space}{\mathop{\rm Space}\nolimits}
\newcommand{\Vect}{\mathop{\rm Vect}\nolimits}
\newcommand{\FinVect}{\mathop{\rm FinVect}\nolimits}
\newcommand{\Matr}{\mathop{\rm Matr}\nolimits}
\newcommand{\Ab}{\mathop{\rm Ab}\nolimits}
\newcommand{\Gr}{\mathop{\rm Gr}\nolimits}
\newcommand{\Grp}{\mathop{\rm Grp}\nolimits}
\newcommand{\Hol}{\mathop{\rm Hol}\nolimits}
\newcommand{\Grpd}{\mathop{\rm Grpd}\nolimits}
\newcommand{\Mon}{\mathop{\rm Mon}\nolimits}
\newcommand{\FinSet}{\mathop{\rm FinSet}\nolimits}
\newcommand{\Sch}{\mathop{\rm Sch}\nolimits}
\newcommand{\AffSch}{\mathop{\rm AffSch}\nolimits}
\newcommand{\Idem}{\mathop{\rm Idem}\nolimits}
\newcommand{\SIdem}{\mathop{\rm SIdem}\nolimits}
\newcommand{\Aut}{\mathop{\rm Aut}\nolimits}
\newcommand{\Ord}{\mathop{\rm Ord}\nolimits}
\newcommand{\coker}{\mathop{\rm coker}\nolimits}
\newcommand{\ch}{\mathop{\rm char}\nolimits}%characteristic
\newcommand{\Sym}{\mathop{\rm Sym}\nolimits}
\newcommand{\adj}{\mathop{\rm adj}\nolimits}
\newcommand{\dil}{\mathop{\rm dil}\nolimits}
\newcommand{\Cl}{\mathop{\rm Cl}\nolimits}
\newcommand{\Diff}{\mathop{\rm Diff}\nolimits}
\newcommand{\End}{\mathop{\rm End}\nolimits}
\newcommand{\Hom}{\mathop{\rm Hom}\nolimits}% preferred
\newcommand{\Gal}{\mathop{\rm Gal}\nolimits}
\newcommand{\Pos}{\mathop{\rm Pos}\nolimits}
\newcommand{\Ad}{\mathop{\rm Ad}\nolimits}
\newcommand{\GL}{\mathop{\rm GL}\nolimits}
\newcommand{\SL}{\mathop{\rm SL}\nolimits}
\newcommand{\vol}{\mathop{\rm vol}\nolimits}
\newcommand{\reg}{\mathop{\rm reg}\nolimits}
\newcommand{\Or}{\mathop{\rm O}\nolimits}
\newcommand{\U}{\mathop{\rm U}\nolimits}
\newcommand{\SOr}{\mathop{\rm SO}\nolimits}
\newcommand{\SU}{\mathop{\rm SU}\nolimits}
\newcommand{\Spin}{\mathop{\rm Spin}\nolimits}
\newcommand{\Sp}{\mathop{\rm Sp}\nolimits}
\newcommand{\Int}{\mathop{\rm Int}\nolimits}
\newcommand{\im}{\mathop{\rm im}\nolimits}
\newcommand{\dom}{\mathop{\rm dom}\nolimits}
\newcommand{\di}{\mathop{\rm div}\nolimits}
\newcommand{\cod}{\mathop{\rm cod}\nolimits}
\newcommand{\colim}{\mathop{\rm colim}\nolimits}
\newcommand{\ad}{\mathop{\rm ad}\nolimits}
\newcommand{\PSL}{\mathop{\rm PSL}\nolimits}
\newcommand{\PGL}{\mathop{\rm PGL}\nolimits}
\newcommand{\sep}{\mathop{\rm sep}\nolimits}
\newcommand{\MCG}{\mathop{\rm MCG}\nolimits}
\newcommand{\oMCG}{\mathop{\rm MCG^+}\nolimits}
\newcommand{\Spec}{\mathop{\rm Spec}\nolimits}
\newcommand{\rank}{\mathop{\rm rank}\nolimits}
\newcommand{\diverg}{\mathop{\rm div}\nolimits}%Divergence
\newcommand{\disc}{\mathop{\rm disc}\nolimits}
\newcommand{\sign}{\mathop{\rm sign}\nolimits}
\newcommand{\Arf}{\mathop{\rm Arf}\nolimits}
\newcommand{\Pic}{\mathop{\rm Pic}\nolimits}
\newcommand{\Tr}{\mathop{\rm Tr}\nolimits}
\newcommand{\res}{\mathop{\rm res}\nolimits}
\newcommand{\Proj}{\mathop{\rm Proj}\nolimits}
\newcommand{\mult}{\mathop{\rm mult}\nolimits}
\newcommand{\N}{\mathop{\rm N}\nolimits}
\newcommand{\lk}{\mathop{\rm lk}\nolimits}
\newcommand{\Pf}{\mathop{\rm Pf}\nolimits}
\newcommand{\sgn}{\mathop{\rm sgn}\nolimits}
\newcommand{\grad}{\mathop{\rm grad}\nolimits}
\newcommand{\lcm}{\mathop{\rm lcm}\nolimits}
\newcommand{\Ric}{\mathop{\rm Ric}\nolimits}
\newcommand{\Hess}{\mathop{\rm Hess}\nolimits}
\newcommand{\sn}{\mathop{\rm sn}\nolimits}
\newcommand{\cut}{\mathop{\rm cut}\nolimits}
\newcommand{\tr}{\mathop{\rm tr}\nolimits}
\newcommand{\codim}{\mathop{\rm codim}\nolimits}
\newcommand{\ind}{\mathop{\rm index}\nolimits}
\newcommand{\rad}{\mathop{\rm rad}\nolimits}
\newcommand{\Rep}{\mathop{\rm Rep}\nolimits}
\newcommand{\Lie}{\mathop{\rm Lie}\nolimits}
\newcommand{\Der}{\mathop{\rm Der}\nolimits}
\newcommand{\hgt}{\mathop{\rm ht}\nolimits}
\newcommand{\Ider}{\mathop{\rm Ider}\nolimits}
\newcommand{\id}{\mathop{\rm id}\nolimits} \)</p>
  <div class="maketitle">
  <h2 class="titleHead">
LIE ALGEBRAS
  </h2>
  <div class="authors"><span class="author" >
<span 
class="cmr-10">ISHAN LEVY</span>
  </span></div>
<div class="submaketitle">
</div>
  </div>
  <h3 class="sectionHead"><a 
 id="x1-1000"></a>Contents</h3>
  <div class="tableofcontents"><span class="sectionToc" ><a 
href="#x1-1000" id="QQ2-1-1">Contents</a></span><br /><span class="sectionToc" >&#x00A0;1.&#x00A0;&#x00A0;<a 
href="#x1-20001" id="QQ2-1-2">Nilpotent and Solvable Lie Algebras</a></span><br /><span class="sectionToc" >&#x00A0;2.&#x00A0;&#x00A0;<a 
href="#x1-30002" id="QQ2-1-3">Semisimple
Lie   Algebras</a></span><br /><span class="sectionToc" >&#x00A0;3.&#x00A0;&#x00A0;<a 
href="#x1-40003" id="QQ2-1-4">Poincar&#x00E9;   Birkho&#xFB00;   Witt</a></span><br /><span class="sectionToc" >&#x00A0;4.&#x00A0;&#x00A0;<a 
href="#x1-50004" id="QQ2-1-5">\(\mathfrak{sl}_2k\)</a></span><br /><span class="sectionToc" >&#x00A0;5.&#x00A0;&#x00A0;<a 
href="#x1-60005" id="QQ2-1-6">Root
Systems</a></span><br /><span class="sectionToc" >&#x00A0;6.&#x00A0;&#x00A0;<a 
href="#x1-70006" id="QQ2-1-7">Classi&#xFB01;cation</a></span><br /><span class="sectionToc" >&#x00A0;7.&#x00A0;&#x00A0;<a 
href="#x1-80007" id="QQ2-1-8">Homological Methods</a></span><br /><span class="sectionToc" >&#x00A0;8.&#x00A0;&#x00A0;<a 
href="#x1-90008" id="QQ2-1-9">To add</a></span><br />
  </div>All Lie algebras are &#xFB01;nite dimensional over a &#xFB01;eld \(k\).
  <h3 class="sectionHead"><span class="titlemark">1. </span> <a 
 id="x1-20001"></a>Nilpotent and Solvable Lie Algebras</h3>
  <div class="newtheorem">
<!--l. 13--><p class="noindent" ><span class="head">
<a 
 id="x1-2001r1"></a>
<span 
class="cmbx-12">Lemma 1.1.</span>  </span><span 
class="cmti-12">Every solvable Lie algebra contains an ideal of codimension</span> \(1\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 16--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Since it is solvable, it has a proper abelian quotient, which has a quotient of
                                                                                  

                                                                                  
dimension \(1\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 20--><p class="noindent" ><span class="head">
<a 
 id="x1-2002r2"></a>
<span 
class="cmbx-12">Lemma 1.2.</span>  </span><span 
class="cmti-12">If</span> \(A\) <span 
class="cmti-12">is nilpotent on a vector space</span> \(V\)<span 
class="cmti-12">, it has a nontrivial kernel, and</span> \(\ad A\) <span 
class="cmti-12">is</span>
<span 
class="cmti-12">nilpotent in</span> \(\gl _V\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 23--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>The &#xFB01;rst claim is clear, and the second follows since \(\ad A = L_A-R_A\), which are commuting
nilpotent operators on \(\gl _V\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 27--><p class="noindent" ><span class="head">
<a 
 id="x1-2003r3"></a>
<span 
class="cmbx-12">Theorem 1.3 </span>&#x0028;Engel&#x2019;s Theorem&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">If</span> \(V\) <span 
class="cmti-12">is a representation of a Lie algebra</span> \(\mg \) <span 
class="cmti-12">by nilpotent</span>
<span 
class="cmti-12">matricies, then there is a</span> \(v\) <span 
class="cmti-12">such that</span> \(\mg v=0\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 30--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Let \(\mh \) be a codimension \(1\) ideal. By induction, there is a nontrivial subspace such
that \(\mh \) acts trivially. Since \(\mh \) contains \([\mg ,\mg ]\), \(\ker \mh \) is an invariant subspace since \(hgv= [h,g]v + ghv = 0\) if \(h \in \mh , g \in \mg , v \in \ker \mh \). Any \(a \notin h\) has an
element it kills \(v \in \ker \mh \) since it acts nilpotently. Since \(ka + \mh = \mg \), we see \(\mg v = 0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
                                                                                  

                                                                                  
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 34--><p class="noindent" ><span class="head">
<a 
 id="x1-2004r4"></a>
<span 
class="cmbx-12">Corollary 1.4.</span>  </span><span 
class="cmti-12">After a change of basis, a subalgebra of</span> \(\gl _n\) <span 
class="cmti-12">consisting of nilpotent matricies</span>
<span 
class="cmti-12">is an algebra of strictly upper triangular matricies.</span>
</p>
  <div class="proof">
<!--l. 37--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Apply Engel&#x2019;s theorem to inductivly construct a &#xFB02;ag such that the action
decreases &#xFB01;ltration. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 41--><p class="noindent" ><span class="head">
<a 
 id="x1-2005r5"></a>
<span 
class="cmbx-12">Corollary 1.5.</span>  </span><span 
class="cmti-12">A Lie algebra is nilpotent i&#xFB00; for every</span> \(a \in \mg \)<span 
class="cmti-12">,</span> \(\ad a\) <span 
class="cmti-12">is nilpotent.</span>
</p>
  <div class="proof">
<!--l. 44--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Since the lower central series eventually vanishes, \(\ad a\) is nilpotent for a nilpotent
Lie algebra. Conversely, by Engel&#x2019;s theorem, if \(\ad a\) is nilpotent, then \(\mg /Z(\mg )\) is nilpotent, so \(\mg \) is
too. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
                                                                                  

                                                                                  
  </div>
<!--l. 48--><p class="noindent" >We can classify \(2\)-step nilpotent Lie algebras \(\mg \). They are completely determined by
the bracket \(\mg /Z(\mg ) \to Z(\mg )\). This is an alternating form, and is nondegenerate because \(Z(\mg )\) is the
center.
</p>
  <div class="newtheorem">
<!--l. 50--><p class="noindent" ><span class="head">
<a 
 id="x1-2006r6"></a>
<span 
class="cmbx-12">Proposition 1.6.</span>  </span><span 
class="cmti-12">2-step nilpotent Lie algebras correspond to vector spaces</span> \(V,W\) <span 
class="cmti-12">with a</span>
<span 
class="cmti-12">nondegenerate alternating pairing</span> \(V \otimes V \to W\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 54--><p class="indent" >  The idea in Engel&#x2019;s Theorem can be upgraded to nonzero weights when the
characteristic is su&#xFB03;ciently large.
</p>
  <div class="newtheorem">
<!--l. 55--><p class="noindent" ><span class="head">
<a 
 id="x1-2007r7"></a>
<span 
class="cmbx-12">Lemma 1.7 </span>&#x0028;Lie&#x2019;s Lemma&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">If</span> \(\mh \subset \mg \) <span 
class="cmti-12">is an ideal,</span> \(V^{\mh }_{\lambda }\) <span 
class="cmti-12">a weight space of</span> \(\mh \) <span 
class="cmti-12">in a f.d representation</span>
\(V\) <span 
class="cmti-12">of</span> \(\mg \)<span 
class="cmti-12">, with</span> \(\ch k &gt; V\)<span 
class="cmti-12">, then it is</span> \(\mg \)<span 
class="cmti-12">-invariant.</span>
</p>
  <div class="proof">
<!--l. 59--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>For \(v \in V^{mh}_{\lambda }, g \in \mg , h \in \mh \) we need to show that \(hgv = \lambda (h)gv\). But it is \([h,g]v + ghv = [h,g] v + \lambda (h)gv\), so it is equivalent to show \([h,g]v=0\).
</p><!--l. 61--><p class="indent" >  De&#xFB01;ne \(W_m\) as the span of \(g^iv\) for \(i \leq m\). By induction, we can see that \(W_m\) is \(\mh \)-invariant and \(hW_m/W_{m-1} = \lambda (h)W_m/W_{m-1}\), since
\(hg^iv = \sum g^j[h,g]g^{i-1-j}v + g^ihv\).
</p><!--l. 63--><p class="indent" >  For su&#xFB03;ciently large \(m\), \(W_m\) stabilizes, so is \(g\)-invariant. Then \(\tr ([g,h]) = 0\), but it is upper triangular
with eigenvalue \(\lambda ([g,h])\). By our assumption on characteristic, we are done. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
                                                                                  

                                                                                  
<!--l. 67--><p class="indent" >  Now we can copy the proof of Engel&#x2019;s theorem to get a result about solvable Lie
algebras.
</p>
  <div class="newtheorem">
<!--l. 69--><p class="noindent" ><span class="head">
<a 
 id="x1-2008r8"></a>
<span 
class="cmbx-12">Theorem 1.8 </span>&#x0028;Lie&#x2019;s Theorem&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">If</span> \(V\) <span 
class="cmti-12">is a &#xFB01;nite dimensional representation over</span> \(\mg \)<span 
class="cmti-12">, a solvable</span>
<span 
class="cmti-12">Lie algebra, and</span> \(\ch k&gt; \dim V\) <span 
class="cmti-12">and</span> \(k\) <span 
class="cmti-12">is algebraically closed, then there is a nonzero weight</span>
<span 
class="cmti-12">space.</span>
</p>
  <div class="proof">
<!--l. 72--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>By induction, a codimension \(1\) ideal of \(\mg \) has a nonzero weight space \(W\). By Lie&#x2019;s
lemma, it is an invariant subspace. Any \(a \notin h\) has an eigenvector \(v\) in \(W\) since \(k\) is algebraically
closed. Since \(ka + \mh = \mg \), we see \(\mg \) acts by scalars on \(v\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 76--><p class="noindent" ><span class="head">
<a 
 id="x1-2009r9"></a>
<span 
class="cmbx-12">Corollary 1.9.</span>  </span><span 
class="cmti-12">After a change of basis, a solvable subalgebra of</span> \(\gl _n\) <span 
class="cmti-12">over an algebraically</span>
<span 
class="cmti-12">closed &#xFB01;eld</span> \(k, \ch k&gt;n\) <span 
class="cmti-12">is an algebra of upper triangular matricies.</span>
</p>
  <div class="proof">
<!--l. 79--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Apply  Lie&#x2019;s  theorem  to  inductivly  construct  a  &#xFB02;ag  such  that  the  action
preserves &#xFB01;ltration. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
                                                                                  

                                                                                  
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 83--><p class="noindent" ><span class="head">
<a 
 id="x1-2010r10"></a>
<span 
class="cmbx-12">Corollary 1.10.</span>  </span><span 
class="cmti-12">If</span> \(\ch k&gt;\dim \mg /Z(\mg )\) <span 
class="cmti-12">and</span> \(\mg \) <span 
class="cmti-12">is solvable,</span> \([\mg ,\mg ]\) <span 
class="cmti-12">is nilpotent.</span>
</p>
  <div class="proof">
<!--l. 86--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>By extending scalars, we can assume \(k\) is algebraically closed. Then \(\ad \mg \) acts by
upper triangular matricies by Lie&#x2019;s theorem, so \(\ad [\mg ,\mg ]\) acts by strictly upper triangular
matricies, so by Engel&#x2019;s theorem, we are done. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 90--><p class="indent" >  Now we will study generalized weight space decompositions.
</p><!--l. 92--><p class="indent" >  Let \(k\) be algebraically closed. Via the Jordan decomposition any operator \(A\) on a &#xFB01;nite
dimensional vector space \(V\) decomposes as \(A_s + A_n\) where \(A_s\) is semisimple, \(A_n\) is nilpotent, and they
commute.
</p>
  <div class="newtheorem">
<!--l. 93--><p class="noindent" ><span class="head">
<a 
 id="x1-2011r11"></a>
<span 
class="cmbx-12">Lemma 1.11.</span>  </span><span 
class="cmti-12">If</span> \(A,B\) <span 
class="cmti-12">commute, they preserve eachother&#x2019;s generalized eigenspaces, and their</span>
<span 
class="cmti-12">Jordan decompositions commute with eachother.</span>
</p>
  <div class="proof">
<!--l. 96--><p class="indent" >  <span class="head">
                                                                                  

                                                                                  
<span 
class="cmti-12">Proof.</span> </span>For the &#xFB01;rst statement, the support of the \(k[A,B]\)-module \(V\) is a &#xFB01;nite set of points
so it splits as a sum of modules supported at a point, which corresponds to &#xFB01;nding
simultaneous generalized eigenspaces of \(A,B\). The semi-simple parts act diagonally on
each component of the sum, so \(A,A_s\) commute with \(B,B_s\), so we are done. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 100--><p class="noindent" ><span class="head">
<a 
 id="x1-2012r12"></a>
<span 
class="cmbx-12">Lemma 1.12.</span>  </span><span 
class="cmti-12">The Jordan decomposition is the unique decomposition into a commuting</span>
<span 
class="cmti-12">semisimple and nilpotent endomorphism.</span>
</p>
  <div class="proof">
<!--l. 103--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Suppose \(A = A_s+A_n = A'_s+A'_n\), where the former is the usual decomposition. Then since \(A'_s\) commutes
with \(A\), it commutes with \(A_s\), and hence \(A_n\). Since \(A'_n = A-A'_s\), it also commutes with everything else.
Then \(A_s-A'_s=A_n-A'_n\) is a semisimple and nilpotent so it is \(0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 107--><p class="noindent" ><span class="head">
<a 
 id="x1-2013r13"></a>
<span 
class="cmbx-12">Corollary 1.13.</span>  </span><span 
class="cmti-12">In</span> \(\gl _V\)<span 
class="cmti-12">, if</span> \(x = x_s + x_n\) <span 
class="cmti-12">is a Jordan decomposition, then</span> \(\ad (x) = \ad (x_s) + \ad (x_n)\) <span 
class="cmti-12">is the Jordan decomposition.</span>
</p>
  <div class="proof">
<!--l. 110--><p class="indent" >  <span class="head">
                                                                                  

                                                                                  
<span 
class="cmti-12">Proof.</span> </span>Observe that \(\ad (x_s)\) is semisimple and \(\ad _n\) is nilpotent and use the characterization. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 114--><p class="indent" >  We would like a theory of generalized eigenspaces that works for representations of
nilpotent Lie algebra, rather than just for endomorphisms.
</p>
  <div class="newtheorem">
<!--l. 115--><p class="noindent" ><span class="head">
<a 
 id="x1-2014r14"></a>
<span 
class="cmbx-12">Lemma 1.14.</span>  </span><span 
class="cmti-12">In an associative unital algebra</span> \(U\) <span 
class="cmti-12">over</span> \(k\)<span 
class="cmti-12">, if</span> \(a,b \in U\) <span 
class="cmti-12">and</span> \(\lambda ,\alpha \in k\)<span 
class="cmti-12">, then </span>\[(a-\alpha -\lambda )^{N}b = \sum _0^N{N \choose j} (\ad a-\alpha )^jb(a-\lambda )^{N-j}\]
</p>
  <div class="proof">
<!--l. 119--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\(L_a-\alpha -\lambda = (\ad a- \alpha ) + (R_a-\lambda )\) where \(L,R\) denote right and left multiplication. Since these summands commute,
the lemma follows from the binomial theorem. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 123--><p class="indent" >  To avoid writing a more precise assumption, from now on assume \(\ch k = 0\) and \(k\) is algebraically
closed. Some statements will hold without the algebraically closed assumption via
extension of scalars.
</p>
  <div class="newtheorem">
<!--l. 124--><p class="noindent" ><span class="head">
<a 
 id="x1-2015r15"></a>
<span 
class="cmbx-12">Theorem 1.15.</span>  </span> <span 
class="cmti-12">Let</span> \(\mh \) <span 
class="cmti-12">be a nilpotent subalgebra of</span> \(\mg \) <span 
class="cmti-12">and</span> \(V\) <span 
class="cmti-12">be a f.d representation of</span> \(\mg \)<span 
class="cmti-12">.</span>
<span 
class="cmti-12">Then</span> \(V\) <span 
class="cmti-12">decompose into generalized weight spaces</span> \(V_{\lambda }^{\mh }\) <span 
class="cmti-12">and</span> \(\mg _{\alpha }^{\mh }V_{\lambda }^{\mh } \subset V_{\lambda +\alpha }^{\mh }\)<span 
class="cmti-12">.</span>
</p>
                                                                                  

                                                                                  
  <div class="proof">
<!--l. 128--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>The very last statement is obtained by having both sides of the equation in
the previous lemma act on \(v\in V\), with \(U\) the universal enveloping algebra \(U(\mg )\), \(a \in \mh ,b \in \mg \).
</p><!--l. 130--><p class="indent" >  To obtain the decomposition, &#xFB01;rst note that for a \(1\)-dimensional Lie algebra it is
just the generalized eigenspace decomposition. If there is some \(a \in \mh \) with more than one
eigenvalue, &#xFB01;rst note that \(\mh = \mh _0^a\) because \(a\) acts nilpotently. Then by the last statement of
the theorem, \(\mh \) preserves the generalized eigenspaces of \(a\), so by induction on \(\dim V\) we are
done.
</p><!--l. 132--><p class="indent" >  In the case that everything has one eigenvalue, Lie&#x2019;s theorem shows that \(\mh \) acts by
upper triangular matricies where the diagonals are constant, so it is a weight space.
<span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 136--><p class="indent" >  For a Cartan subalgebra, we drop the superscript \(\mh \) in the notation.
</p>
  <h3 class="sectionHead"><span class="titlemark">2. </span> <a 
 id="x1-30002"></a>Semisimple Lie Algebras</h3>
<!--l. 140--><p class="noindent" >Given a representation \(V\) of a Lie Algebra \(\mg \), the <span 
class="cmbx-12">trace form </span>is \((a,b)_V = \tr _V ab\). One easily checks it is
symmetric \((a,b) = (b,a)\) and invariant \(([a,b],c) = (a,[b,c])\). The trace form on the adjoint representation is called the
<span 
class="cmbx-12">Killing form</span>, denoted \(\kappa \).
</p>
  <div class="newtheorem">
<!--l. 142--><p class="noindent" ><span class="head">
<a 
 id="x1-3001r1"></a>
<span 
class="cmbx-12">Lemma 2.1.</span>  </span><span 
class="cmti-12">If</span> \(\ma \) <span 
class="cmti-12">is an ideal of</span> \(\mg \)<span 
class="cmti-12">, then</span> \(\kappa _{\mg }|_{\ma } =\kappa _{\ma }\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 145--><p class="indent" >  <span class="head">
                                                                                  

                                                                                  
<span 
class="cmti-12">Proof.</span> </span>\(\ad b\ad a, a\in \ma \) has image in \(\ma \), so its trace is equal to its trace on \(\ma \). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 149--><p class="indent" >  Weights are related to roots by rational multiples on certain parts of the Cartan
subalgebra.
</p>
  <div class="newtheorem">
<!--l. 150--><p class="noindent" ><span class="head">
<a 
 id="x1-3002r2"></a>
<span 
class="cmbx-12">Lemma 2.2 </span>&#x0028;Cartan&#x2019;s Lemma&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Let</span> \(e \in \mg _a, f \in \mg _{-a}, [e,f]=h\)<span 
class="cmti-12">, and suppose that</span> \(V_{\lambda } \neq 0\)<span 
class="cmti-12">. Then</span> \(\lambda (h) = r \alpha (h)\)<span 
class="cmti-12">, where</span> \(r \in \QQ \) <span 
class="cmti-12">doesn&#x2019;t depend on</span>
\(h\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 153--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Consider \(W=\oplus _n V_{\lambda +n\alpha }\), upon which \(e,f,h\) act. \(h\)&#x2019;s trace is \(0\) on this as it is a commutator. The
trace is \(\sum _n (\lambda +n\alpha )(h)\dim V_{\lambda +n\alpha }=0\), giving the relation. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 157--><p class="noindent" ><span class="head">
<a 
 id="x1-3003r3"></a>
<span 
class="cmbx-12">Theorem 2.3 </span>&#x0028;Cartan&#x2019;s Criterion&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">For a subalgebra of</span> \(\gl _V\)<span 
class="cmti-12">, the following are equivalent:</span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\((\mg ,[\mg ,\mg ])_V= 0\)
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(([\mg ,\mg ],[\mg ,\mg ])_V = 0\)
                                                                                  

                                                                                  
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\mg \) <span 
class="cmti-12">is solvable.</span></dd></dl>
  <div class="proof">
<!--l. 165--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\((1)\implies (2)\) is clear. \((3) \implies (1)\) follows from Lie&#x2019;s theorem, since the product of two elements of
that form is strictly uppertriangular.
</p><!--l. 167--><p class="indent" >  \((2) \implies (3)\): If not, then there is a point in the derived series giving a subalgebra \(\mg '\) such that \([\mg ',\mg ']= \mg '\).
If \(\mh \) is its Cartan subalgebra, then \(\mh = \sum _i [\mg '_{\alpha },\mg '_{-\alpha }]\). Choose an \(h = [e,f]\), and observe \(0 = (h,h)_V = \tr h^2 = \sum _{\lambda } \lambda (h)^2 \dim V_{\lambda }\). By the previous lemma,
this is a nonnegative rational multiple of \(\alpha (h)\), so we must have \(\lambda (h)=0\) and \(V = V_0\). But then everything
acts nilpotently, so by Engel&#x2019;s theorem \(\mg '\) is nilpotent, a contradiction. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 171--><p class="noindent" ><span class="head">
<a 
 id="x1-3007r4"></a>
<span 
class="cmbx-12">Corollary 2.4.</span>  </span>\(\mg \) <span 
class="cmti-12">is solvable i&#xFB00;</span> \(\kappa (\mg ,[\mg ,\mg ]) =0\)<span 
class="cmti-12">.</span>
</p>
  </div>
  <div class="newtheorem">
<!--l. 175--><p class="noindent" ><span class="head">
<a 
 id="x1-3008r5"></a>
<span 
class="cmbx-12">De&#xFB01;nition 2.5.</span>  </span><span 
class="cmti-12">The radical of</span> \(\mg \)<span 
class="cmti-12">,</span> \(\rad (\mg )\) <span 
class="cmti-12">is the largest solvable ideal.</span>
</p>
  </div>
  <div class="newtheorem">
<!--l. 179--><p class="noindent" ><span class="head">
<a 
 id="x1-3009r6"></a>
<span 
class="cmbx-12">De&#xFB01;nition 2.6.</span>  </span>\(\mg \) <span 
class="cmti-12">is semisimple if</span> \(\rad (\mg ) = 0\)<span 
class="cmti-12">.</span>
                                                                                  

                                                                                  
</p>
  </div>
<!--l. 183--><p class="indent" >  Equivalently, there are no nontrivial abelian ideals. Note that a simple Lie algebra is
clearly semisimple.
</p>
  <div class="newtheorem">
<!--l. 185--><p class="noindent" ><span class="head">
<a 
 id="x1-3010r7"></a>
<span 
class="cmbx-12">Corollary 2.7.</span>  </span><span 
class="cmti-12">If</span> \(\mg \) <span 
class="cmti-12">is semisimple the trace form of any or every faithful representation</span> \(V\) <span 
class="cmti-12">is</span>
<span 
class="cmti-12">nondegenerate.</span>
</p>
  <div class="proof">
<!--l. 188--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>By Cartan&#x2019;s criterion, the nullspace of \((a,b)_V\) is a solvable ideal, so is \(0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 192--><p class="noindent" ><span class="head">
<a 
 id="x1-3011r8"></a>
<span 
class="cmbx-12">Corollary 2.8.</span>  </span>\(\mg \) <span 
class="cmti-12">is semisimple i&#xFB00; its Killing form is nondegenerate.</span>
</p>
  <div class="proof">
<!--l. 195--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>If \(\mg \) is not semisimple, it has a nontrivial abelian ideal, which is in the kernel
of \(\kappa \). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
                                                                                  

                                                                                  
  </div>
  <div class="newtheorem">
<!--l. 199--><p class="noindent" ><span class="head">
<a 
 id="x1-3012r9"></a>
<span 
class="cmbx-12">Proposition 2.9.</span>  </span><span 
class="cmti-12">The Killing form of a semisimple Lie algebra</span> \(\mg \) <span 
class="cmti-12">is nondegenerate when</span>
<span 
class="cmti-12">restricted to any ideal</span> \(\ma \)<span 
class="cmti-12">. A Lie algebra splits as a sum of simple Lie algebras.</span>
</p>
  <div class="proof">
<!--l. 202--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\(\ma \cap \ma ^{\perp }\) is a solvable ideal by Cartan&#x2019;s criterion, so is \(0\). Thus \(\mg = \ma \oplus \ma ^{\perp }\) as a Lie algebra. Iterating
gives the last assertion. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 206--><p class="noindent" ><span class="head">
<a 
 id="x1-3013r1"></a>
<span 
class="cmbx-12">Example 2.9.1.</span>  </span>\(\gl _n\) is \(k I \oplus \msl _n\) where \(\msl _n\) is semisimple.
</p>
  <div class="proof">
<!--l. 209--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Let \(E_{ij}\) be the matrix \((E_{ij})_{kl} = \delta _{ik}\delta _{jl}\). We can compute \(\ad (E_{ij})E_{kl} = E_{il}\delta _{jk} -E_{kj}\delta _{il}\). Thus \(\ad (E_{mn})\ad (E_{ij})E_{kl} = E_{ml}\delta _{jk}\delta _{ni} - E_{mj} \delta _{il}\delta _{nk} - E_{in} \delta _{jk}\delta _{lm} + E_{kn}\delta _{il}\delta _{jm}\), so taking trace, we get \(2n\delta _{ni}\delta _{mj} - 2\delta _{mn}\delta _{ij}\). By
linearity, the Killing form is \((a,b) = 2n\tr ab-2\tr a\tr b\). From this we can see that it is nondegenerate on \(\msl _n\), and
null on \(k I\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
                                                                                  

                                                                                  
<!--l. 213--><p class="noindent" ><span class="head">
<a 
 id="x1-3014r10"></a>
<span 
class="cmbx-12">Theorem 2.10.</span>  </span><span 
class="cmti-12">Given a faithful irreducible representation of</span> \(\mg \) <span 
class="cmti-12">into</span> \(V\) <span 
class="cmti-12">either</span> \(\mg \) <span 
class="cmti-12">is semisimple,</span>
<span 
class="cmti-12">or it is</span> \(kI\) <span 
class="cmti-12">summed with something semisimple.</span>
</p>
  <div class="proof">
<!--l. 216--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>If it isn&#x2019;t semisimple, by Lie&#x2019;s theorem, the radical has an nonzero weight
space, which is invariant by Lie&#x2019;s lemma. By irreducibility, it must be all of \(V\). Since
the representation is faithful, the radical must be \(kI\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 220--><p class="noindent" ><span class="head">
<a 
 id="x1-3015r11"></a>
<span 
class="cmbx-12">De&#xFB01;nition 2.11.</span>  </span><span 
class="cmti-12">A  Lie  algebra  is  </span><span 
class="cmbxti-10x-x-120">reductive  </span><span 
class="cmti-12">if  its  adjoint  representation  is</span>
<span 
class="cmti-12">completely reducible.</span>
</p>
  </div>
  <div class="newtheorem">
<!--l. 224--><p class="noindent" ><span class="head">
<a 
 id="x1-3016r12"></a>
<span 
class="cmbx-12">Lemma 2.12.</span>  </span><span 
class="cmti-12">A Lie algebra is reductive i&#xFB00; it is a sum of a semisimple Lie algebra and an</span>
<span 
class="cmti-12">abelian one.</span>
</p>
  <div class="proof">
<!--l. 227--><p class="indent" >  <span class="head">
                                                                                  

                                                                                  
<span 
class="cmti-12">Proof.</span> </span>The irreducible summands of a reductive Lie algebra are ideals, so the Lie
algebra splits into a sum of Lie algebras where the adjoint representation is both
completely reducible and irreducible. If the center of such an algebra is trivial, by
the above theorem, it is semisimple &#x0028;in fact simple&#x0029;. Otherwise, since the center is a
summand of the adjoint representation, it is everything, and the algebra is abelian.
The other direction has already been proven. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 231--><p class="indent" >  We will now see that semisimple Lie algebras are the ones having a semisimple
representation theory. To see it is a necessary condition, observe that the adjoint
representation must be irreducible so it is reductive, and it can&#x2019;t have an abelian part
since abelian Lie algebras aren&#x2019;t semisimple.
</p><!--l. 233--><p class="indent" >  Recall that representations of \(\mg \) are the same as representations of \(U(\mg )\). \(U(\mg )\) is a &#xFB01;ltered
cocommutative Hopf algebra, where the coproduct is \(x \mapsto 1 \otimes x +x\otimes 1\), and the antipode is \(x \mapsto -x\) on \(\mg \subset U(\mg )\). It is the
algebra of di&#xFB00;erential operators on the associated formal group. \(U\) of a free Lie algebra is a
tensor algebra, \(U(\mg \oplus \mh ) = U(\mg ) \otimes _k U(\mh )\), and \(U(k) = k[x]\).
</p><!--l. 236--><p class="indent" >  The argument that representations are semisimple is similar to the argument for
compact Lie group. There, via averaging over a bi-invariant metric, one makes any
representation unitary, after which one can produce orthogonal complements to
subrepresentations. Here the bi-invariant metric becomes the Killing form, and it hard to
average, but we still have an in&#xFB01;nitesmal version of averaging, namely the Laplacian
operator, which here is called the Casimir element.
</p><!--l. 238--><p class="indent" >  Any symmetric invariant form \(B\) on \(\mg \) can be thought of as a map of \(\mg \)-modules \(\mg \otimes \mg \to k\).
Nondegeneracy means the adjoint \(\mg \to \mg ^*\) is an isomorphism. Via this identi&#xFB01;cation,
the identity \(\mg \to \mg \) is adjoint to a map \(k \to \mg \otimes \mg \), the image of \(1\) being the <span 
class="cmbx-12">Casimir element</span>
\(L_B\). Alternatively it is adjoint to the map \(B\). Note that symmetry of the bilinear
form implies that \(L_B\) is invariant under swapping the two terms. We can also view
\(L\) in \(U(\mg )\) via the multiplication map \(\mg \otimes \mg \to U(\mg )\). It is central in \(U(\mg )\) since the map \(k \to \mg \otimes \mg \) is a map of
\(\mg \)-modules.
</p>
  <div class="newtheorem">
<!--l. 240--><p class="noindent" ><span class="head">
<a 
 id="x1-3017r13"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">Lemma 2.13.</span>  </span><span 
class="cmti-12">The category of f.d representations of</span> \(\mg \) <span 
class="cmti-12">is semisimple i&#xFB00;</span> \(\Ext ^1(k,V)=0\) <span 
class="cmti-12">for all irreducible</span> \(V\)<span 
class="cmti-12">,</span>
<span 
class="cmti-12">where</span> \(k\) <span 
class="cmti-12">is the tensor unit.</span>
</p>
  <div class="proof">
<!--l. 243--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>We can identify \(\Hom _{\mg }(V,W)\) with \(\Hom _{\mg }(k,W\otimes V^*)\). \((-)\otimes V^*\) is exact and preserves injectives, so we can derive the
isomorphism to \(\Ext \). Semisimplicity is equivalent to \(\Ext ^1(V,W)=0\). So we only need \(\Ext ^1(k,V) = 0\) for all \(V\), but the
long exact sequence on \(\Ext \) shows it su&#xFB03;ces to prove it for irreducible \(V\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 247--><p class="noindent" ><span class="head">
<a 
 id="x1-3018r14"></a>
<span 
class="cmbx-12">Theorem 2.14 </span>&#x0028;Weyl Complete Reducability&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">For a semisimple</span> \(\mg \)<span 
class="cmti-12">, any &#xFB01;nite-dimensional</span>
<span 
class="cmti-12">representation of</span> \(U(\mg )\) <span 
class="cmti-12">is semisimple.</span>
</p>
  <div class="proof">
<!--l. 250--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>We need to show that a short exact sequence \(0 \to V \to W \to k \to 0\) splits when \(V\) is irreducible.
WLOG \(V\) is faithful by passing to a quotient of \(\mg \). \(L_V\) is \(0\) on \(k\), and \(\tr _{L_V}(V) = \dim \mg \neq 0\). So \(L_V\) is nonzero, and thus
an isomorphism by Schur&#x2019;s Lemma. An element in the kernel of \(L_W\) gives a splitting. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 254--><p class="indent" >  A remark about the proof: we should expect \(k\) to be the only irreducible representation
for which \(L\) acts as \(0\) since every irrep embeds in \(L^2\), where \(L\) is literally the Laplacian, and the
only harmonic functions are constant.
                                                                                  

                                                                                  
</p><!--l. 256--><p class="indent" >  This has an interpretation in terms of derivations. A <span 
class="cmbx-12">derivation</span> \(d:\mg \to M\) is a map such that \(d[a,b] = adb-bda\) It
is the same as a \(1\)-cocycle in the Chevalley-Eilenberg complex &#x0028;i.e the de Rham complex&#x0029; of
\(M\). A \(1\)-boundary is an <span 
class="cmbx-12">inner derivation </span>or a map of the form \(dx = xa, a \in M\). We can write these groups
as \(\Der (\mg ,M)\) and \(\Ider (\mg ,M)\).
</p>
  <div class="newtheorem">
<!--l. 258--><p class="noindent" ><span class="head">
<a 
 id="x1-3019r15"></a>
<span 
class="cmbx-12">Corollary 2.15.</span>  </span><span 
class="cmti-12">Every  derivation  of  a  semisimple  Lie  into  a  &#xFB01;nite-dimensional</span>
<span 
class="cmti-12">module is inner.</span>
</p>
  </div>
<!--l. 262--><p class="indent" >  A special case of this is the Lie algebra of derivations of \(\mg \) into \(\mg \). Here is an alternate proof
of the fact in that case:
</p>
  <div class="newtheorem">
<!--l. 264--><p class="noindent" ><span class="head">
<a 
 id="x1-3020r16"></a>
<span 
class="cmbx-12">Proposition 2.16.</span>  </span><span 
class="cmti-12">If</span> \(\mg \) <span 
class="cmti-12">is semisimple, the map</span> \(\ad : \mg \to \Der (\mg )\) <span 
class="cmti-12">is an isomorphism.</span>
</p>
  <div class="proof">
<!--l. 267--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>The  restriction  of  the  tautological  representation  \(\Der (\mg )\)  to  \(\mg \)  is  the  adjoint
representation. Since \(\kappa \) is nondegenerate, \(\Der (\mg )\) splits as \(\ad \mg \oplus \ad \mg ^{\perp }\). If \(D \in \ad \mg ^{\perp }\) then \(0 = [D,\ad a] = \ad Da\), so \(Da \in Z(\mg ) =0\) showing \(D = 0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 271--><p class="noindent" ><span class="head">
<a 
 id="x1-3021r17"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">De&#xFB01;nition 2.17.</span>  </span><span 
class="cmti-12">An </span><span 
class="cmbxti-10x-x-120">abstract Jordan decomposition </span><span 
class="cmti-12">of</span> \(a\) <span 
class="cmti-12">is a decomposition</span> \(a=a_s+a_n\)
<span 
class="cmti-12">where</span> \([a_s,a_n]=0\) <span 
class="cmti-12">and</span> \(\ad a_s,\ad a_n\) <span 
class="cmti-12">are semisimple and nilpotent.</span>
</p>
  </div>
<!--l. 275--><p class="indent" >  They are unique i&#xFB00; \(Z(\mg )=0\), because that is the kernel of map \(\ad \), and we know Jordan
decompositions to be unique in \(\gl _V\).
</p>
  <div class="newtheorem">
<!--l. 277--><p class="noindent" ><span class="head">
<a 
 id="x1-3022r18"></a>
<span 
class="cmbx-12">Lemma 2.18.</span>  </span><span 
class="cmti-12">Abstract Jordan decompositions exist for reductive Lie algebras.</span>
</p>
  <div class="proof">
<!--l. 280--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>It  su&#xFB03;ces  to  assume  \(\mg \)  semisimple.  \(A=\ad g\)  has  a  Jordan  decomposition  as  an
endomorphism, so it su&#xFB03;ces to show that \(A_s\) is a derivation. By linearity it su&#xFB03;ces to
do check this for elements in a root space \(x,y\), with eigenvalues \(\lambda ,\mu \) for \(A\). Indeed, \(A_s[x,y] = (\mu +\lambda )[x,y] =[\lambda x,y] + [x,\mu y] = [A_sx,y] + [x,A_sy]\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 284--><p class="indent" >  Now we can better understand the Killing forms of a semisimple Lie algebra.
</p>
  <div class="newtheorem">
<!--l. 286--><p class="noindent" ><span class="head">
<a 
 id="x1-3023r19"></a>
<span 
class="cmbx-12">Theorem 2.19.</span>  </span><span 
class="cmti-12">Let</span> \(\kappa \) <span 
class="cmti-12">be the killing form on</span> \(\mg \)<span 
class="cmti-12">, a semisimple Lie algebra, and let</span> \(\mh \) <span 
class="cmti-12">be a</span>
<span 
class="cmti-12">Cartan subalgebra.</span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\kappa (\mg _{\alpha },\mg _{\beta })=0\) <span 
class="cmti-12">unless</span> \(\alpha +\beta =0\)<span 
class="cmti-12">.</span>
                                                                                  

                                                                                  
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\kappa _{\mg _{\alpha }+ \mg _{-\alpha }}\) <span 
class="cmti-12">is nondegenerate.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\mh \) <span 
class="cmti-12">is abelian</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;4&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\mh \) <span 
class="cmti-12">consists of semisimple elements</span></dd></dl>
  <div class="proof">
<!--l. 294--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\((1)\): This is immediate from Theorem <a 
href="#x1-2015r15">1.15<!--tex4ht:ref: weightstheorem --></a> by looking at how \(\ad \) acts on the root
spaces.
</p><!--l. 296--><p class="indent" >  \((2)\): This follows from \((1)\) and the fact that \(\kappa \) is nondegenerate.
</p><!--l. 298--><p class="indent" >  \((3)\): Cartan&#x2019;s criterion shows that \(\kappa (\mh ,[\mh ,\mh ])= 0\), but along with \((2)\) on \(\mg _0=\mh \) this means \([\mh ,\mh ]=0\).
</p><!--l. 300--><p class="indent" >  \((4)\): \(\mh _s \subset \mh \) because of how \(\ad \mh _s\) behaves, but note that by \((3)\), \(\kappa (h,h') = \kappa (h_s,h')\) for \(h,h' \in \mh \). Thus by \((2)\) on \(\mg _0=\mh \), \(h = h_s\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <h3 class="sectionHead"><span class="titlemark">3. </span> <a 
 id="x1-40003"></a>Poincar&#x00E9; Birkho&#xFB00; Witt</h3>
<!--l. 306--><p class="noindent" >We would in general like to understand the structure of \(U(\mg )\).
</p><!--l. 308--><p class="indent" >  To do this, we will use a general tool due to George Bergman for &#xFB01;nding canonical forms
for elements of associative \(k\)-algebras.
</p><!--l. 310--><p class="indent" >  Say that we have a set \(X\), and we consider the tensor algebra \(T_R(X)\) on \(X\) over a commutative
ring \(R\). Say we also have some relations \(\sigma \in S\) of the form \(W_\sigma = f_\sigma \), where \(W\) is a word in \(X\). For any other
words \(A,B\), we can consider \(r_{A\sigma B}\), the \(R\)-linear endomorphism on \(T_R(X)\) replacing \(AW_\sigma B\) with \(Af_\sigma B\). We call
applying this to an element of \(T_R(X)\) a <span 
class="cmbx-12">reduction</span>. If all reductions on an element are
trivial, then that element is <span 
class="cmbx-12">irreducible</span>. The submodule of irreducible elements is
called \(T_R(X)_{irr}\). We say that an element is <span 
class="cmbx-12">reduction &#xFB01;nite </span>if for any in&#xFB01;nite sequence of
reductions, only &#xFB01;nitely many act nontrivially. The reduction &#xFB01;nite elements form an
\(R\)-submodule of \(T_R(X)\) called \(T_R(X)_{fin}\). A sequence of reductions is <span 
class="cmbx-12">&#xFB01;nal </span>if it results in an irreducible
element. An element \(a\) is <span 
class="cmbx-12">reduction unique </span>if it is reduction &#xFB01;nite and any &#xFB01;nal
sequence results in the same irreducible element. The unique result will be denoted
\(r(a)\).
</p>
                                                                                  

                                                                                  
  <div class="newtheorem">
<!--l. 313--><p class="noindent" ><span class="head">
<a 
 id="x1-4001r1"></a>
<span 
class="cmbx-12">Lemma 3.1.</span>  </span><span 
class="cmti-12">The reduction unique elements form a submodule denoted</span> \(T_R(X)_{un}\)<span 
class="cmti-12">, and</span> \(r:T_R(X)_{un} \to T_R(X)_{irr}\) <span 
class="cmti-12">is</span>
\(R\)<span 
class="cmti-12">-linear.</span>
</p>
  <div class="proof">
<!--l. 317--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Suppose \(a,b \in T_R(X)_{un}, k \in R\). \(a+kb\) is reduction &#xFB01;nite, and if we have two reduction sequences of it
to an irreducible, we can consider doing the same sequence on \(a,b\) and extend them
to one that makes each irreducible &#x0028;note that this won&#x2019;t change the result, only the
sequence&#x0029;. Then by uniqueness for \(a,b\) we see that the two reductions are the same, and
that \(r\) is \(R\)-linear. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 321--><p class="noindent" ><span class="head">
<a 
 id="x1-4002r2"></a>
<span 
class="cmbx-12">Lemma 3.2.</span>  </span> <span 
class="cmti-12">Let</span> \(a,b,c \in T_R(X)\) <span 
class="cmti-12">have the property that if</span> \(A,B,C\) <span 
class="cmti-12">are nonzero monomials in</span> \(a,b,c\)<span 
class="cmti-12">, then</span> \(ABC\) <span 
class="cmti-12">is</span>
<span 
class="cmti-12">reduction unique. Then if</span> \(r_\Sigma (b)\) <span 
class="cmti-12">is the result of some &#xFB01;nite reductions on</span> \(b\)<span 
class="cmti-12">, then</span> \(ar_\Sigma (b)c\) <span 
class="cmti-12">is reduction</span>
<span 
class="cmti-12">unique.</span>
</p>
  <div class="proof">
<!--l. 325--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Note in particular that the hypotheses imply that if \(abc\) is reduction unique,
and that if the conclusion holds, \(r(ar_\Sigma (b)c) = r(abc)\). By linearity we only need to show this when \(a,b,c\) are
monomials, and when \(r_\Sigma (b)\) is a single reduction \(r_{d\sigma e}\). But \(ar_{d\sigma e}(b)c = r_{ad\sigma ec}(abc)\), so this follows since \(abc\) is reduction
unique. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
                                                                                  

                                                                                  
</p>
  </div>
  </div>
<!--l. 330--><p class="indent" >  We say that a <span 
class="cmbx-12">overlap ambiguity </span>is a pair \(\sigma ,\sigma ' \in S\) and a triple \(A,B,C\) of nonempty words such that \(AB = W_\sigma , BC = W_\sigma '\)
&#x0028;they overlap&#x0029;. It is <span 
class="cmbx-12">resolvable </span>if there is are sequences of reductions \(r,r'\) such that \(r \circ r_\sigma (ABC) = r' \circ r_{\sigma '}(ABC)\). An
<span 
class="cmbx-12">inclusion ambiguity </span>is the same, except when \(W_\sigma = B,W_\sigma ' = ABC\), and has the same conditions for
resolvability &#x0028;except \(A,C\) can be empty&#x0029;.
</p><!--l. 332--><p class="indent" >  Say that a <span 
class="cmbx-12">compatible partial ordering</span> \(\leq \) on words of \(X\) is one such that \(A\leq B \implies CAD \leq CBD\) and such that
the monomials of the \(f_\sigma \) are smaller than the monomials of \(W_\sigma \). Let \(I\) be the two-sided ideal
generated by the relations in \(S\), and \(I_A\) be the \(R\)-submodule of \(T_R(X)\) generated by \(B\sigma C&lt;A, \sigma \in S\) &#x0028;every monomial
is smaller than \(A\)&#x0029;. An ambiguity is <span 
class="cmbx-12">resolvable relative to</span> \(\leq \) if \(r_\sigma (ABC)-r'_\sigma (ABC) \in I_{ABC}\). Note that this is an easy
condition to check.
</p><!--l. 334--><p class="indent" >  Finally we arrive at this theorem, which can be considered a Diamond Lemma for
rings:
</p>
  <div class="newtheorem">
<!--l. 336--><p class="noindent" ><span class="head">
<a 
 id="x1-4003r3"></a>
<span 
class="cmbx-12">Theorem 3.3.</span>  </span> <span 
class="cmti-12">Suppose we have</span> \(S,X,\leq ,I\) <span 
class="cmti-12">as above where</span> \(\leq \) <span 
class="cmti-12">is compatible with</span> \(S\) <span 
class="cmti-12">and satis&#xFB01;es</span>
<span 
class="cmti-12">the descending chain condition. Then the following are equivalent:</span>
</p><!--l. 340--><p class="indent" >
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">Every ambiguity is resolvable.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">Every ambiguity is resolvable with respect to</span> \(\leq \)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">Every element is reduction unique.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;4&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">The  natural  quotient  identi&#xFB01;es  the  submodule  spanned  by  irreducible</span>
       <span 
class="cmti-12">monomials with</span> \(T_R(X)/I\)<span 
class="cmti-12">, which is</span> \(T_R(X)_{irr}\)<span 
class="cmti-12">.</span></dd></dl>
  <div class="proof">
<!--l. 346--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Clearly \((3) \implies (1) \implies (2)\). If \((3)\) is true, \(r\) de&#xFB01;nes a projection onto \(T_R(X)_{irr}\). The kernel is contained in \(I\)
                                                                                  

                                                                                  
by de&#xFB01;nition of \(r\) and contains \(I\), as for any \(AB\), \(r(A\sigma B) = 0\) by Lemma <a 
href="#x1-4002r2">3.2<!--tex4ht:ref: idealred --></a>. Thus as an \(R\)-module, \(T_R(X) = I \oplus T_R(X)_{irr}\),
giving \((4)\). Conversely if \((4)\) is true, Then since reductions are equal in the quotient, they
must be unique.
</p><!--l. 348--><p class="indent" >  Thus it su&#xFB03;ces to prove \((2) \implies (3)\), and by linearity, we need only show this for a monomial
\(A\). From the descending chain condition, we can assume that any smaller monomial is
reduction unique. Now suppose that we have two reductions of a monomial \(A\).
</p><!--l. 350--><p class="indent" >  If there is no ambiguity, they commute, so we can create two more reductions to
an irreducible where the &#xFB01;rst two steps are the &#xFB01;rst step of these reductions but in
di&#xFB00;erent orders. They will give the same element, and by induction will show that
the two original reductions are also the same.
</p><!--l. 352--><p class="indent" >  If  there  is  ambiguity,  then  since  it  is  resolvable  relative  to  \(\leq \)  by  induction  the
di&#xFB00;erence can be resolved to \(0\), so by linearity the two resolutions must agree. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 356--><p class="noindent" ><span class="head">
<a 
 id="x1-4008r4"></a>
<span 
class="cmbx-12">Theorem 3.4 </span>&#x0028;Poincar&#x00E9;-Birkho&#xFB00;-Witt&#x0029;<span 
class="cmbx-12">.</span>  </span> <span 
class="cmti-12">Let</span> \(\mg \) <span 
class="cmti-12">be a Lie algebra over</span> \(R\) <span 
class="cmti-12">where the</span>
<span 
class="cmti-12">underlying module is free. Choose a well-ordered basis of</span> \(\mg \)<span 
class="cmti-12">,</span> \(x_\alpha , \alpha \in I\)<span 
class="cmti-12">. Then</span> \(x_{a_1}^{e_1}\dots x_{a_n}^{e_n}\) <span 
class="cmti-12">for</span> \(x_{a_1}\) <span 
class="cmti-12">in increasing</span>
<span 
class="cmti-12">order, over all possible</span> \(a_i\) <span 
class="cmti-12">and</span> \(e_i\) <span 
class="cmti-12">form a basis of</span> \(U(\mg )\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 361--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Construct an ordering on monomials in the basis where monomials of smaller
degree are smaller, and if two monomials have the same degree, we compare them
lexicographically using the order on our basis. This is a well-ordering on monomials,
and a su&#xFB03;cient set of relations for \(U(\mg )\) can be written as \(xy = yx +[x,y]\) for \(x&gt;y\) in the basis. The order
is compatible with this, and we can check that every ambiguity is resolvable with
respect to our order. Here, the only nontrivial kind of ambiguity that can occur is an
overlap ambiguity, when we have something of the form \(A(yxz+[x,y]z)B=AxyzB=A(xzy+x[y,z])B\). The di&#xFB00;erence is: \[A(yxz+[x,y]z-(xzy+x[y,z]))B = A(yzx + y[x,z] + z[x,y] + [[x,y],z]\]\[ - (zxy + [x,z]y + [y,z]x + [x,[y,z]]))B= A(zyx + [y,z]x + y[x,z] + z[x,y] + [[x,y],z]\]\[ - (zyx + z[x,y] + y[x,z] + [[x,z],y] + [y,z]x + [x,[y,z]])B\]\[ = A([[x,y],z] - [[x,z],y] - [x,[y,z]])B = 0 \] Where
at the last step, we have used the Jacobi identity. This shows that the ambiguity is
resolvable under the ordering, so that by Theorem <a 
href="#x1-4003r3">3.3<!--tex4ht:ref: diamondlemmaring --></a> we are done. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
                                                                                  

                                                                                  
</p>
  </div>
  </div>
<!--l. 368--><p class="indent" >  Note that as a corollary, any Lie algebra \(\mg \) &#x0028;not necessarily &#xFB01;nite-dimensional&#x0029; is faithfully
represented in \(U(\mg )\).
</p>
  <h3 class="sectionHead"><span class="titlemark">4. </span> <a 
 id="x1-50004"></a>\(\msl _2k\)</h3>
<!--l. 371--><p class="noindent" >The structure theory of semisimple Lie algebras is centered around the behavior of \(\msl _2k\). Before
moving on let&#x2019;s study it more carefully.
</p><!--l. 373--><p class="indent" >  Let&#x2019;s consider a root system for \(\msl _2\).
</p><!--l. 375--><p class="indent" >  It has a basis \(e = \begin{bmatrix} 0 &amp; 1\\0 &amp; 0 \end{bmatrix},f = \begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0 \end{bmatrix},h = \begin{bmatrix} 1 &amp; 0\\ 0 &amp; -1 \end{bmatrix}\), and can be presented via the relations \([e,f]=h, [h,e]=2e,[h,f]=-2f\). \(kh\) is a Cartan subalgebra, and \(e,f\)
generate the root spaces.
</p><!--l. 384--><p class="indent" >  We can try to classify &#xFB01;nite-dimensional irreducible \(\msl _2\)-modules. There is a standard
one, given on a vector space \(V\) of dimension \(2\). \(\Sym ^nV\) is a representation of dimension
\(n+1\).
</p>
  <div class="newtheorem">
<!--l. 385--><p class="noindent" ><span class="head">
<a 
 id="x1-5001r1"></a>
<span 
class="cmbx-12">Proposition 4.1.</span>  </span>\(\Sym ^nV\) <span 
class="cmti-12">is a complete list of f.d irreducible</span> \(\msl _2\)<span 
class="cmti-12">-representations.</span>
</p>
  <div class="proof">
<!--l. 388--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Let \(v\) be a nonzero element of \(V\) in the kernel of \(e\). \(v,fv\) form a basis of \(V\). Note that \(e\)
acts nilpotently with \(1\)-dimensional kernel \(v^{\otimes n}\). Thus any subrepresentation contains that
vector, and since it generates the rest of the space by powers of \(f\), \(\Sym ^nV\) is irreducible.
</p><!--l. 390--><p class="indent" >  Now let \(W\) be an any f.d irreducible representation. It decomposes into eigenspaces
\(W_\lambda \) for \(h\), and \(eW_{\lambda } \subset W_{\lambda +2}, fW_{\lambda } = W_{\lambda -2}\). We see then by irreducibility \(\oplus _n W_{\lambda +2n} = W\), where the nonzero terms occur in a
segment, and are one-dimensional as \([e,f] = h\). Since \(\tr h\) is \(0\), we must have the highest and lowest
weights be opposite in signs, so \(\lambda \) is an integer \(n\). This is enough to see that \(\lambda \) uniquely
characterizes the irrep, so it is \(\Sym ^n V\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
                                                                                  

                                                                                  
</p>
  </div>
  </div>
<!--l. 393--><p class="indent" >  By this theorem, we can understand the isomorphism class of any &#xFB01;nite-dimensional
\(\msl _2\)-module by looking at how \(h\) acts on the kernel of \(e\). Namely, every eigenvalue of \(n\)
corresponds to a copy of \(\Sym ^n V\).
</p>
  <div class="newtheorem">
<!--l. 395--><p class="noindent" ><span class="head">
<a 
 id="x1-5002r2"></a>
<span 
class="cmbx-12">Corollary 4.2.</span>  </span><span 
class="cmti-12">Let</span> \(W\) <span 
class="cmti-12">be a &#xFB01;nite dimensional representation of</span> \(\msl _2\)<span 
class="cmti-12">, and</span> \(v\) <span 
class="cmti-12">a vector such</span>
<span 
class="cmti-12">that</span> \(ev = 0\)<span 
class="cmti-12">. Then</span> \(hv = \lambda v\)<span 
class="cmti-12">,</span> \(\lambda \in \ZZ _{\geq 0}\)<span 
class="cmti-12">.</span> \(\lambda \) <span 
class="cmti-12">is the largest</span> \(k\) <span 
class="cmti-12">such that</span> \(f^k v \neq 0\)<span 
class="cmti-12">. Moreover,</span> \(v,fv,\dots f^\lambda v\) <span 
class="cmti-12">are linearly independent,</span> \(hf^kv=(\lambda -2k)f^kv\) <span 
class="cmti-12">and</span>
\(ef^kv = n(\lambda -n+1)f^{k-1}v\)<span 
class="cmti-12">.</span>
</p>
  </div>
  <div class="newtheorem">
<!--l. 400--><p class="noindent" ><span class="head">
<a 
 id="x1-5003r3"></a>
<span 
class="cmbx-12">Corollary 4.3.</span>  </span> <span 
class="cmti-12">A f.d representation of</span> \(\msl _2\) <span 
class="cmti-12">is irreducible i&#xFB00; it satis&#xFB01;es any of the following</span>
<span 
class="cmti-12">conditions:</span> </p>
          <ul class="itemize1">
       <li class="itemize"><span 
class="cmti-12">The kernel of</span> \(e\) <span 
class="cmti-12">is</span> \(1\)<span 
class="cmti-12">-dimensional.</span>
          </li>
       <li class="itemize"><span 
class="cmti-12">The kernel of</span> \(f\) <span 
class="cmti-12">is</span> \(1\)<span 
class="cmti-12">-dimensional.</span>
          </li>
       <li class="itemize"><span 
class="cmti-12">The eigenspaces of</span> \(h\) <span 
class="cmti-12">are</span> \(1\)<span 
class="cmti-12">-dimensional.</span></li></ul>
  </div>
<!--l. 409--><p class="indent" >  Given a &#xFB01;nite-dimensional \(\msl _2\)-module \(V\), let \(\tau = \exp (e)\exp (f)\exp (-e)\).
</p>
  <div class="newtheorem">
<!--l. 410--><p class="noindent" ><span class="head">
<a 
 id="x1-5004r4"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">Lemma 4.4.</span>  </span>\(\tau \) <span 
class="cmti-12">swaps the</span> \(-n\) <span 
class="cmti-12">and</span> \(n\) \(h\)<span 
class="cmti-12">-eigenspaces of any f.d.</span> \(\msl _2\)<span 
class="cmti-12">-module</span> \(W\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 413--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Since \(W\) is a sum of summands of tensor products of the standard representation,
it su&#xFB03;ces to verify for the standard representation. Here \(\tau \) is \(\begin{bmatrix} 0 &amp; 1 \\ -1 &amp; 0 \end{bmatrix}\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 419--><p class="noindent" ><span class="head">
<a 
 id="x1-5005r5"></a>
<span 
class="cmbx-12">De&#xFB01;nition 4.5.</span>  </span><span 
class="cmti-12">An</span> \(\msl _2\)<span 
class="cmbxti-10x-x-120">-triple </span><span 
class="cmti-12">is a homomorphism</span> \(\msl _2 \to \mg \)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 422--><p class="indent" >  For any semisimple Lie algebra, we will get an \(\msl _2\)-triple for each root, so we will use the
representation theory of \(\msl _2\) to show that the roots form a root system.
</p>
  <h3 class="sectionHead"><span class="titlemark">5. </span> <a 
 id="x1-60005"></a>Root Systems</h3>
<!--l. 426--><p class="noindent" >First we will need to show that we get a root system from a semisimple Lie
algebra. Let \(\mg \) be a &#xFB01;xed semisimple Lie algebra, \(\mh \) a Cartan subalgebra, \(\Delta \) the set of
roots. \(\kappa \) induces a nondegenerate symmetric bilinear form on \(\mh ^*\), and we will use \(\kappa \) to
denote this as well. Let \((-)^*\) be the isomorphism between \(\mg \) and its dual induced by
\(\kappa \).
</p>
  <div class="newtheorem">
<!--l. 428--><p class="noindent" ><span class="head">
<a 
 id="x1-6001r1"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">Lemma 5.1 </span>&#x0028;\(\msl _2\)-triples&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">If</span> \(\alpha \in \Delta \)<span 
class="cmti-12">,</span> \(e \in \mg _{\alpha }\)<span 
class="cmti-12">,</span> \(f \in \mg _{-\alpha }\)<span 
class="cmti-12">, then</span> \([e,f] = \kappa (e,f)\alpha ^*\)<span 
class="cmti-12">. Moreover, if</span> \(\alpha \in \Delta , \kappa (\alpha ,\alpha ) \neq 0\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 432--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\(\kappa (h,[e,f]) = \kappa (\ad h(e),f) = \alpha (h) \kappa (e,f) = \kappa (h,\alpha ^*\kappa (e,f))\), giving the &#xFB01;rst result since \(\kappa \) is nondegenerate on \(\mh \). For the second, choose \(e,f\) so
that \(\kappa (e,f)=1\). If \(\kappa (\alpha ,\alpha ) = \kappa (\alpha ,[e,f]) = \alpha ([e,f])\) is \(0\), then \(\alpha ^*,e,f\) form a subalgebra presented by the relations \([e,f] = \alpha ^*,[\alpha ^*,e] = [\alpha ^*,f]=0\). This is a nilpotent
subalgebra, so by Lie&#x2019;s theorem, \(\alpha ^* = [e,f]\) must act nilpotently on \(\mg \). but it acts semisimply so
\(\ad \alpha ^*=0\), a contradiction. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 436--><p class="indent" >  Thus given \(\alpha \), we can pick \(e_{\alpha },f_{\alpha }\) so that \(\kappa (e_{\alpha },f_{\alpha }) = \frac 2{\kappa (\alpha ,\alpha )}\). Then \([e_\alpha ,f_\alpha ] = h_\alpha = \frac{2\alpha ^*}{\kappa (\alpha ,\alpha )}\). Then \(e_\alpha ,f_\alpha ,h_\alpha \) give an \(\msl _2\)-triple associated with
\(\alpha \).
</p><!--l. 438--><p class="indent" >  \(\msl _2\)-triples associated with \(\alpha \) are unique up to scaling \(f \mapsto \lambda f, e \mapsto \lambda ^{-1}e\). This follows from the next
theorem.
</p><!--l. 441--><p class="indent" >  For convenience, de&#xFB01;ne \(\langle \alpha |\beta \rangle \) as \(2\frac{\kappa (\alpha ,\beta )}{\kappa (\alpha ,\alpha )}\). This notation is nonstandard, but \(|\) is being used to remind
us that it is not symmetric.
</p>
  <div class="newtheorem">
<!--l. 442--><p class="noindent" ><span class="head">
<a 
 id="x1-6002r2"></a>
<span 
class="cmbx-12">Theorem 5.2.</span>  </span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\dim \mg _\alpha = 1, \alpha \in \Delta \)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">If</span> \(\alpha , \beta \in \Delta \)<span 
class="cmti-12">, then</span> \(\beta +r\alpha , r \in k\) <span 
class="cmti-12">is a connected string where</span> \(r\) <span 
class="cmti-12">are integers going from</span> \(-p\) <span 
class="cmti-12">to</span> \(q\) <span 
class="cmti-12">where</span> \(p-q = \langle \alpha |\beta \rangle \)
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">If</span> \(\alpha ,\beta ,\alpha +\beta \in \Delta \)<span 
class="cmti-12">, then</span> \([\mg _\alpha ,\mg _\beta ] =\mg _{\alpha +\beta } \)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;4&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\alpha \in \Delta \implies r\alpha \in \Delta \) <span 
class="cmti-12">i&#xFB00;</span> \(r = \pm 1\)<span 
class="cmti-12">.</span></dd></dl>
  <div class="proof">
                                                                                  

                                                                                  
<!--l. 450--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\((1)\): If \(e,e'\) are nonzero in \(\mg _\alpha \), rescale them and choose an \(f\) in \(\mg _{-\alpha }\), so that \(e,f,[e,f]\) and \(e',f,[e',f]\) extend to
an \(\msl _2\)-triple. But \([e,f] = \frac{2\alpha ^*}{\kappa (\alpha ,\alpha )} = [e',f]\), so the representation theory of \(\msl _2\) tells us \(e = e'\).
</p><!--l. 452--><p class="indent" >  \((2\&amp; 3)\): Consider \(M = \oplus _{r \in k} \mg _{\beta +r\alpha }\) as a representation of an \(\msl _2\)-triple associated to \(\alpha \). \(h_{\alpha }\mg _{\beta +r\alpha } = (\langle \alpha |\beta \rangle +2r) \mg _\beta \) by de&#xFB01;nition of \(h_\alpha \), so \(M\)
is irreducible by \((1)\) and Corollary <a 
href="#x1-5003r3">4.3<!--tex4ht:ref: irreduciblecrit --></a>. The results then follows from the representation
theory of \(\msl _2\).
</p><!--l. 454--><p class="indent" >  \((4)\): This follows from the former observation that \(M\) is an irreducible \(\msl _2\) module for \(\beta =\alpha \) along
with the fact that \([\mg _\alpha ,\mg _\alpha ]=0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 457--><p class="indent" >  Because the &#x0028;nonzero&#x0029; roots are \(1\)-dimensional, and \(\mh \) is abelian, it follows that if \(a,b \in \mh \), then
\(\kappa (a,b) = \sum _{\alpha \in \Delta }\alpha (a)\alpha (b)\).
</p><!--l. 459--><p class="indent" >  \(\kappa \) restricted to the roots is really de&#xFB01;ned over \(\QQ \) and is positive de&#xFB01;nite.
</p>
  <div class="newtheorem">
<!--l. 460--><p class="noindent" ><span class="head">
<a 
 id="x1-6007r3"></a>
<span 
class="cmbx-12">Theorem 5.3.</span>  </span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\Delta \) <span 
class="cmti-12">spans</span> \(\mh ^*\)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\kappa (\alpha ,\beta ) \in \QQ \) <span 
class="cmti-12">for</span> \(\alpha ,\beta \in \Delta \)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\kappa |_{\mh ^*_\QQ }\) <span 
class="cmti-12">is positive de&#xFB01;nite.</span></dd></dl>
  <div class="proof">
<!--l. 467--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\((1)\): If there is some \(h \in \mh \) such that \(\kappa (\alpha ^*,h) = \alpha (h)=0\) for all \(\alpha \in \Delta \), then \(h\) acts trivially on all \(\mg _\alpha \), so must be \(0\).
</p><!--l. 469--><p class="indent" >  \((2\&amp; 3)\): Let \(\alpha ,\beta \in \Delta \). Then the formula for \(\kappa \) shows \(\frac{4}{\kappa (\alpha ,\alpha )} = \sum _{\lambda \in \Delta } \langle \alpha | \lambda \rangle \in \ZZ \) so \(\kappa (\alpha ,\alpha ) \in \QQ \). Since \(\frac{\langle \alpha |\beta \rangle \kappa (\alpha ,\alpha )}{2} = \kappa (\alpha ,\beta )\), \(\kappa (\alpha ,\beta ) \in \QQ \). Finally the formula for \(\kappa (\alpha ,\alpha )\) shows it
is positive, since it is a sum of squares of rational numbers. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
                                                                                  

                                                                                  
</p>
  </div>
  </div>
<!--l. 473--><p class="indent" >  We have shown that \(h^*,\Delta \) is a root system, of which a de&#xFB01;nition will now be given. I think
the right way to do this gives something called root datum, where you don&#x2019;t identify the
vector space with its dual via an inner product.
</p>
  <div class="newtheorem">
<!--l. 475--><p class="noindent" ><span class="head">
<a 
 id="x1-6011r4"></a>
<span 
class="cmbx-12">De&#xFB01;nition 5.4.</span>  </span><span 
class="cmti-12">A </span><span 
class="cmbxti-10x-x-120">root system </span><span 
class="cmti-12">is an vector space</span> \(V\) <span 
class="cmti-12">with a conformal structure &#x0028;i.e. an</span>
<span 
class="cmti-12">inner product up to scaling&#x0029; and a collection of nonzero elements &#x0028;roots&#x0029;</span> \(\Delta \) <span 
class="cmti-12">spanning it, such</span>
<span 
class="cmti-12">that:</span> </p>
          <ul class="itemize1">
       <li class="itemize"><span 
class="cmti-12">If</span> \(\alpha \in \Delta \)<span 
class="cmti-12">,</span> \(n\alpha \in \Delta \) <span 
class="cmti-12">i&#xFB00;</span> \(n = \pm 1\)<span 
class="cmti-12">.</span>
          </li>
       <li class="itemize"><span 
class="cmti-12">If</span> \(\alpha , \beta \in \Delta \)<span 
class="cmti-12">, then</span> \(\beta +n\alpha ,n \in \ZZ \) <span 
class="cmti-12">is in</span> \(\Delta \coprod 0\) <span 
class="cmti-12">for</span> \(n\) <span 
class="cmti-12">in a connected string from</span> \(-p\) <span 
class="cmti-12">to</span> \(q\)<span 
class="cmti-12">, where</span> \(p-q = \frac{2(\alpha ,\beta )}{(\alpha ,\alpha )}\)<span 
class="cmti-12">.</span></li></ul>
  </div>
<!--l. 482--><p class="indent" >  The second condition is called the string condition.
</p><!--l. 484--><p class="indent" >  We denote \(\frac{2(\alpha ,\beta )}{(\alpha ,\alpha )}\) as \(\langle \alpha |\beta \rangle \) like before.
</p><!--l. 486--><p class="indent" >  We would like to determine when a Lie algebra is simple rather than just
semisimple. Let us consider a sum of two semisimple Lie algebras \(\mg ,\mg '\), let \(\mh ,\mh '\) be their
Cartan subalgebras and let \(\Delta ,\Delta '\) be the roots. \(\mh \oplus \mh '\) is a Cartan subalgebra and \(\Delta \coprod \Delta '\) is the
corresponding set of roots. Note that the splitting of \(\mg \oplus \mg '\) can be detected entirely through
the root system. Namely \(\mh ,\mh '\) orthogonally decompose the space, and \(\Delta , \Delta '\) respects the
decomposition. Conversely such a decomposition clearly indicates how to decompose
the Lie algebra. By the axioms of a root system, this is equivalent to &#xFB01;nding
a partition \(\Delta \coprod \Delta '\) where \(a+b \notin \Delta \coprod \Delta ' \coprod 0\) if \(a \in \Delta , b \in \Delta '\). When a nontrivial partition exists, the root system is
<span 
class="cmbx-12">indecomposable</span>.
</p>
  <div class="newtheorem">
<!--l. 488--><p class="noindent" ><span class="head">
<a 
 id="x1-6012r5"></a>
<span 
class="cmbx-12">Lemma 5.5.</span>  </span>\(\mg \) <span 
class="cmti-12">is simple i&#xFB00; its root system is indecomposable.</span>
                                                                                  

                                                                                  
</p>
  </div>
<!--l. 492--><p class="indent" >  We can easily check indecomposability as follows:
</p>
  <div class="newtheorem">
<!--l. 493--><p class="noindent" ><span class="head">
<a 
 id="x1-6013r6"></a>
<span 
class="cmbx-12">Lemma 5.6.</span>  </span> <span 
class="cmti-12">A root system</span> \(\Delta \) <span 
class="cmti-12">is indecomposable i&#xFB00; any two roots can be connected</span>
<span 
class="cmti-12">by a sequence such that for any neighboring pair in the sequence, the sum is in</span> \(\Delta \coprod 0\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 497--><p class="indent" >  The existence of a root system is really equivalent to being semisimple. Now we will
produce many examples of semisimple Lie algebras and hence root systems. To
exhibit a Lie algebra as semisimple, it really su&#xFB03;ces to provide a root space
decomposition.
</p>
  <div class="newtheorem">
<!--l. 499--><p class="noindent" ><span class="head">
<a 
 id="x1-6014r7"></a>
<span 
class="cmbx-12">Theorem 5.7.</span>  </span> <span 
class="cmti-12">If</span> \(\mg \) <span 
class="cmti-12">has a decomposition as</span> \(\mh \oplus \bigoplus _{\alpha \in \Delta }\mg _\alpha \)<span 
class="cmti-12">,</span> \(\Delta \subset \mh ^*\) <span 
class="cmti-12">such that</span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\Delta \) <span 
class="cmti-12">spans</span> \(\mh ^*\)<span 
class="cmti-12">, and</span> \(\mh \) <span 
class="cmti-12">is nilpotent.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\mg _\alpha \) <span 
class="cmti-12">are weight spaces for the action of</span> \(\mh \)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\alpha (a,\mg _{-\alpha })\neq 0\) <span 
class="cmti-12">for</span> \(a \in \mg _\alpha \)<span 
class="cmti-12">.</span></dd></dl>
<!--l. 506--><p class="noindent" ><span 
class="cmti-12">Then</span> \(\mg \) <span 
class="cmti-12">is semisimple, and</span> \(\mh ,\Delta ,\mg _\alpha \) <span 
class="cmti-12">denote the usual things.</span>
</p>
  <div class="proof">
<!--l. 508--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Consider an abelian ideal \(\ma \). It cannot be contained in \(\mh \), as \(\alpha \) of any element in \(\mh \)
                                                                                  

                                                                                  
is nonzero for some \(\alpha \) by \((1)\), so \(\mg _\alpha \) would also be in it. Consider any element \(a \in \ma -\mh \). By acting on
it by elements of \(\mh \) many times, since \(\mh \) is nilpotent and \(\mg _\alpha \) are weight spaces for \(\mh \), we can
assume its component in \(\mh \) is \(0\) and its components in the \(\mg _\alpha \) are restricted to \(\alpha \) supported
on a line. By further acting by an element in \(\mh \) for which \(\alpha \) doesn&#x2019;t vanish, and taking
linear combinations, we can assume \(a\) is supported on \(\mg _\alpha \oplus \mg _{-\alpha }\). Suppose its component in \(\mg _\alpha \) is
\(0\). Then by acting on \(a\) by an element of \(\mg _{-\alpha }\), by \((3)\) we can produce an element \(b \in \ma \) supported
in \(\mh \oplus \mg _{-2\alpha }\) that has \(\alpha \neq 0\), but this doesn&#x2019;t commute with \(a\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 512--><p class="indent" >  Now we can construct the classical simple Lie algebras and their root decompositions.
We will not show they are simple since it easily follows from our criteria.
</p>
  <div class="newtheorem">
<!--l. 514--><p class="noindent" ><span class="head">
<a 
 id="x1-6018r1"></a>
<span 
class="cmbx-12">Example 5.7.1 </span>&#x0028;\(\msl _n\)&#x0029;<span 
class="cmbx-12">.</span>  </span>The diagonal matricies form an abelian subalgebra, with basis \(e_i = E_{i,i}-E_{i+1,i+1}\)
for \(1 \leq i &lt; n\). Anything that commutes with \(e_i\) commutes with all diagonal matricies preserves
their eigenspaces so must be diagonal. \(\ad e_i(E_{jk})\) was computed before, and we see that \(E_{jk},j\neq k\) are
the weight spaces with weight \(e_j^*-e_k^*\). The roots are then \(e_j^*-e_k^*\) for \(j\neq k\) both less than \(n\).
</p>
  </div>
<!--l. 518--><p class="indent" >  Given a bilinear form \(B\) on a vector space \(V\), the set of endomorphisms \(A\) such that \(B(Aa,b)+B(a,Ab)=0\) is a Lie
algebra. When \(B\) is a nondegenerate symmetric bilinear form on a vector space of dimension
\(n\), this is called \(\so _n\), and when it is a nondegenerate alternating biliner form on a vector space
of dimension \(2n\), this is called \(\msp _{2n}\).
</p>
  <div class="newtheorem">
<!--l. 520--><p class="noindent" ><span class="head">
<a 
 id="x1-6019r2"></a>
<span 
class="cmbx-12">Example 5.7.2 </span>&#x0028;\(\so _{n}\)&#x0029;<span 
class="cmbx-12">.</span>  </span>Here \(n\geq 3\). Choose a basis so that \(B\) is the matrix that is \(1\)s on the
antidiagonal. Then \(\so _n\) consists of all matrices that are anti symmetric with respect to
&#xFB02;ipping across the antidiagonal. A Cartan subalgebra consists of all matrices that
                                                                                  

                                                                                  
are diagonal, a basis given by \(e_i = E_{ii}-E_{n+1-i,n+1-i}\) for \(1 \leq i \leq \frac n 2\). The root spaces are given by \(E_{ij}-E_{n+1-i,n+1-j}\), corresponding to
the roots \(e_i^*-e_{j}^*\), where \(e_j^*\) really means \(-e_{n+1-j}^*\) when \(j&gt;\frac n 2\) and \(0\) when \(j=\frac n 2\). When \(n\) is even, these then give \(\pm (e_i^* + e_j^*), e_i^*-e_j^*\)
for \(i\neq j\) at most \(\frac{n}{2}\), and when \(n\) is odd, they give \(\pm (e_i^* + e_j^*),e_i^*-e_j^*, \pm e_i^*\) for \(i \neq j\) at most \(\frac n 2\).
</p>
  </div>
  <div class="newtheorem">
<!--l. 524--><p class="noindent" ><span class="head">
<a 
 id="x1-6020r3"></a>
<span 
class="cmbx-12">Example 5.7.3 </span>&#x0028;\(\msp _{2n}\)&#x0029;<span 
class="cmbx-12">.</span>  </span>Here \(n\geq 1\). We can choose a basis so the bilinear form looks like \(1\) on
the upper half of the antidiagonal and \(-1\) on the other half. We can split any matrix in
\(\msp _{2n}\) into four quadrants like \(\begin{bmatrix} a&amp;b\\c&amp;d \end{bmatrix}\), and if \(a'\) denotes the re&#xFB02;ection across the antidiagonal, the
conditions are that \(a'=-d,b'=b,c'=c\). Again the diagonal matrices form a Cartan subalgebra, with
bases \(e_i = E_{ii}-E_{n+1-i,n+1-i}\). Now there are di&#xFB00;erent kinds of rootspaces. One kind is \(E_{ij}-E_{n+1-i,n+1-j}\) where \(i,j\) is in the
upper left quadrant, which gives \(e_i^*-e_j^*\). Another is \(E_{ij}+E_{n+1-i,n+1-j}\) where \(i,j\) is in the upper left half of either
the top right or bottom left quadrant, giving \(\pm (e_i^* + e_j^*)\). The last kind is \(E_{ij}\) where \(i,j\) lies on the
antidiagonal, giving \(\pm 2e_i^*\).
</p>
  </div>
<!--l. 529--><p class="indent" >  There is another naming scheme related to Dynkin diagrams: \(A_n = \msl _{n+1}, B_n = \so _{2n+1}, C_n = \msp _{2n}, D_n = \so _{2n} (n&gt;1)\).
</p><!--l. 532--><p class="indent" >  The Killing forms are easy to understand up to scalar multiplication:
</p>
  <div class="newtheorem">
<!--l. 533--><p class="noindent" ><span class="head">
<a 
 id="x1-6021r8"></a>
<span 
class="cmbx-12">Lemma 5.8.</span>  </span><span 
class="cmti-12">Any nontrivial invariant bilinear form on a simple Lie algebra is</span>
<span 
class="cmti-12">nondegenerate. Moreover any invariant nondegenerate bilinear form on a simple Lie</span>
<span 
class="cmti-12">algebra is unique up to scalar multiplication. In particular it must be proportional to</span>
\(\kappa \)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 536--><p class="indent" >  <span class="head">
                                                                                  

                                                                                  
<span 
class="cmti-12">Proof.</span> </span>An invariant bilinear form is a map of \(\mg \)-modules \(\mg \otimes \mg \to k\). \(\Hom (\mg \otimes \mg ,k) = \Hom (\mg ,\mg ^*)\) which is one-dimensional
since \(\mg \) is simple. The result follows since \(\kappa \) is an example of a nontrivlal form. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 540--><p class="indent" >  Thus the trace form of the standard representation is proportional to \(\kappa \). Now let&#x2019;s
study root systems in general. There is an analog of the previous lemma for root
systems.
</p>
  <div class="newtheorem">
<!--l. 543--><p class="noindent" ><span class="head">
<a 
 id="x1-6022r9"></a>
<span 
class="cmbx-12">Proposition 5.9.</span>  </span><span 
class="cmti-12">An indecomposable root system has a unique up to scalars</span>
<span 
class="cmti-12">inner product making it a root system. Moreover, if</span> \((\alpha ,\alpha ) \in \QQ \) <span 
class="cmti-12">for some</span> \(\alpha \in \Delta \)<span 
class="cmti-12">, it is true for all</span>
\((\alpha ,\beta )\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 546--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Given \((\alpha ,\alpha )\), the string condition lets us compute \((\alpha ,\beta )\) whenever \(\alpha +\beta \in \Delta \), which then lets us
compute \((\beta ,\beta )\). Continuing this way via Lemma <a 
href="#x1-6013r6">5.6<!--tex4ht:ref: indeccondition --></a>, we can recover the rest of the inner
product showing it is determined by \((\alpha ,\alpha )\) and moreover in \(\QQ \) if \((\alpha ,\alpha )\) is. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 549--><p class="indent" >  Thus we can really choose to work over \(\QQ \) or \(\RR \) and it makes no di&#xFB00;erence. \(\ZZ \Delta \) is a &#xFB01;nitely
generated subgroup of a rational vector space, so is a lattice called the <span 
class="cmbx-12">root</span>
<span 
class="cmbx-12">lattice</span>.
</p><!--l. 551--><p class="indent" >  Let \(E_r\) be the lattice consisting of linear combinations \(a_ie_I\) where either \(a_i \in \ZZ \) or \(a_i\in \ZZ +\frac 1 2\) for all \(i\) and
\(\sum _i a_i \in 2\ZZ \).
</p><!--l. 553--><p class="indent" >  A lattice is <span 
class="cmbx-12">even </span>if \((a,b) \in \ZZ \) for any \(a,b\) in it. The following is straightforward.
</p>
  <div class="newtheorem">
                                                                                  

                                                                                  
<!--l. 555--><p class="noindent" ><span class="head">
<a 
 id="x1-6023r10"></a>
<span 
class="cmbx-12">Lemma 5.10.</span>  </span>\(E_r\) <span 
class="cmti-12">is even i&#xFB00;</span> \(8|r\)<span 
class="cmti-12">.</span>
</p>
  </div>
  <div class="newtheorem">
<!--l. 559--><p class="noindent" ><span class="head">
<a 
 id="x1-6024r11"></a>
<span 
class="cmbx-12">Theorem 5.11.</span>  </span><span 
class="cmti-12">Given an even lattice such that</span> \(\Delta \)<span 
class="cmti-12">, the set of elements in the lattice such</span>
<span 
class="cmti-12">that</span> \((a,a) =2\) <span 
class="cmti-12">span the vector space,</span> \(\Delta \) <span 
class="cmti-12">is a root system.</span>
</p>
  <div class="proof">
<!--l. 562--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>One really only needs to check the string property. Since \(0 \leq (\alpha -\beta ,\alpha -\beta ) = (\alpha ,\alpha )+(\beta ,\beta )-2(\alpha ,\beta )\), we see that \((\alpha ,\beta ) \leq 2\). One
can calculate in each case that the string condition holds. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 566--><p class="noindent" ><span class="head">
<a 
 id="x1-6025r1"></a>
<span 
class="cmbx-12">Example 5.11.1 </span>&#x0028;\(E_8\)&#x0029;<span 
class="cmbx-12">.</span>  </span>The theorem implies \(E_8\) is a root system, which can be checked
is indecomposable. It can be described as the root system consisting of \(\pm (e_i + e_j), \pm e_i \mp e_j\) and things
of the form \(\frac{1}{2}(e_1\pm \dots e_8)\) where there are an even number of minus signs.
</p>
  </div>
  <div class="newtheorem">
<!--l. 570--><p class="noindent" ><span class="head">
<a 
 id="x1-6026r2"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">Example 5.11.2 </span>&#x0028;\(E_7\)&#x0029;<span 
class="cmbx-12">.</span>  </span>We  can  construct  another  called  \(E_7\)  as  a  sub-root  system  as
follows: consider the vectors in \(E_8\) orthogonal to the constant vector with entry \(\frac 1 2\). It is
still even, so a root system. These are of the form \(e_i-e_j, i \neq j\) and things of the form \(\frac{1}{2}(e_1\pm \dots e_8)\) where the
number of minus signs is divisible by four.
</p>
  </div>
  <div class="newtheorem">
<!--l. 574--><p class="noindent" ><span class="head">
<a 
 id="x1-6027r3"></a>
<span 
class="cmbx-12">Example 5.11.3 </span>&#x0028;\(E_6\)&#x0029;<span 
class="cmbx-12">.</span>  </span>Finally, \(E_6\) can be constructed as the root system consisting of
vectors in \(E_7\) that are orthogonal to \(e_7+e_8\). It is still even, so a root system. It contains \(e_i-e_j\) such
that if either of \(\{i,j\}\cap \{7,8\}\) is \(\{7,8\}\) or \(\phi \), as well as things of the form \(\frac{1}{2}(e_1\pm \dots e_8)\) where the number of minus
signs is divisible by four, and \(e_7,e_8\) have opposite signs.
</p>
  </div>
<!--l. 578--><p class="indent" >  There are two more exceptional root systems, which have a di&#xFB00;erent origin.
</p>
  <div class="newtheorem">
<!--l. 580--><p class="noindent" ><span class="head">
<a 
 id="x1-6028r4"></a>
<span 
class="cmbx-12">Example 5.11.4 </span>&#x0028;\(F_4\)&#x0029;<span 
class="cmbx-12">.</span>  </span>Consider  the  vector  space  generated  by  \(e_1,e_2,e_3,e_4\)  and  consider  the
lattice consisting of elements of the form \(\sum _i a_i e_i\) where either \(a_i \in \ZZ \) or all \(a_i \in \ZZ +\frac 1 2\). The elements of the
lattice such that \((x,x) = 1,2\) form an indecomposable root system. More explicitly, the roots are
\(\pm e_i, \pm (e_i + e_j), e_i-e_j, \pm \frac 1 2 (e_1\pm \dots e_4)\).
</p>
  </div>
  <div class="newtheorem">
<!--l. 584--><p class="noindent" ><span class="head">
<a 
 id="x1-6029r5"></a>
<span 
class="cmbx-12">Example 5.11.5 </span>&#x0028;\(G_2\)&#x0029;<span 
class="cmbx-12">.</span>  </span>Here the lattice is the same as that for \(A_2\), namely all elements
\(a_1e_1+a_2e_2+a_3e_3\) such that \(\sum _i a_i = 0\), except we take elements with \((x,x) = 2,6\). This is an indecomposable root system
                                                                                  

                                                                                  
whose elements are \(\pm (e_i + e_j), e_i - e_j, \pm (2e_i-e_j-e_k)\).
</p>
  </div>
  <h3 class="sectionHead"><span class="titlemark">6. </span> <a 
 id="x1-70006"></a>Classi&#xFB01;cation</h3>
<!--l. 590--><p class="noindent" >To classify root systems, we will really classify root systems with a generic linear
functional, and show it doesn&#x2019;t depend on the functional. Suppose that we have a root
system \((V,\Delta )\) and a linear functional \(f\) not vanishing on any root. Then we say a root \(\alpha \) is
<span 
class="cmbx-12">positive </span>if \(f(\alpha )&gt;0\), and negative otherwise. A positive root is <span 
class="cmbx-12">simple </span>if it is not the sum of two
positive roots. A <span 
class="cmbx-12">highest root</span> \(\theta \) is a root such that \(f(\theta )\) is maximal. \(\Delta _+,\Delta _-\) denote the positive and
negative roots, and \(\Pi \) denotes the simple roots. \(\Pi \) is indecomposable if it can&#x2019;t be nontrivially
partitioned into orthogonal sets.
</p>
  <div class="newtheorem">
<!--l. 592--><p class="noindent" ><span class="head">
<a 
 id="x1-7001r1"></a>
<span 
class="cmbx-12">Theorem 6.1 </span>&#x0028;Dynkin&#x0029;<span 
class="cmbx-12">.</span>  </span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">If</span> \(\alpha ,\beta \in \Pi \) <span 
class="cmti-12">are distinct, then</span> \(\alpha -\beta \notin \Delta \) <span 
class="cmti-12">and</span> \((\alpha ,\beta )\leq 0\)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">Every positive root is a nonnegative integral linear combination of simple</span>
       <span 
class="cmti-12">roots.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">If</span> \(\alpha \in \Delta _+-\Pi \)<span 
class="cmti-12">, then for some</span> \(\gamma \in \Pi \)<span 
class="cmti-12">,</span> \(\alpha -\gamma \in \Pi \)<span 
class="cmti-12">, and when this is true,</span> \(\alpha - \gamma \in \Delta _+\)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;4&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\Pi \) <span 
class="cmti-12">is a basis of the lattice generated by</span> \(\Delta \)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;5&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\Delta \) <span 
class="cmti-12">is indecomposable i&#xFB00;</span> \(\Pi \) <span 
class="cmti-12">is.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;6&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">For an indecomposable root system, there is a unique highest root</span> \(\theta \)<span 
class="cmti-12">, and</span> \((\theta ,\alpha )&gt;0,\alpha \in \Delta _+\)<span 
class="cmti-12">.</span>
          </dd></dl>
  <div class="proof">
<!--l. 603--><p class="indent" >  <span class="head">
                                                                                  

                                                                                  
<span 
class="cmti-12">Proof.</span> </span>\((1)\): If it were in \(\Delta \), by possibly taking its negative, we could assume it is in \(\Delta _+\). But
then \(\alpha -\beta + \beta = \beta \) so \(\beta \) isn&#x2019;t simple. The string condition then implies that \((\alpha ,\beta ) \leq 0\).
</p><!--l. 605--><p class="indent" >  \((2)\): Break up a positive root into smaller positive roots until they are all simple.
</p><!--l. 607--><p class="indent" >  \((3)\): \(\alpha = \sum _i c_i\gamma _i\) where \(\gamma _i\) are positive simple roots, and \(c_i&gt;0\). we have that \(\sum _i c_i\langle \alpha |\gamma _i\rangle = \langle \alpha |\alpha \rangle = 2\), so \(\langle \alpha |\gamma _i\rangle \) is positive for some \(\gamma _i\),
so \(\gamma _i-\alpha \in \Delta \). If \(\gamma -\alpha \) is ever in \(\Delta _+\), then since \(\alpha \) is too, \(\gamma \) cannot be simple. Thus \(\alpha -\gamma \in \Delta _+\).
</p><!--l. 609--><p class="indent" >  \((4)\): Since \(\Delta \) spans the lattice, so does \(\Delta _+\), so by \((2)\), \(\Pi \) does too. Suppose there is a relation \(\sum c_i \gamma _i = \sum c'_j \gamma '_j\)
where \(c_i,c'_j\geq 0\), and \(\gamma _i,\gamma _j'\) are a disjoint set of simple roots. Then \((\sum c_i \gamma _i,\sum c'_j \gamma '_j) \leq 0\) by \((1)\) so the coe&#xFB03;cients are \(0\).
</p><!--l. 611--><p class="indent" >  \((5)\):  If  \(\Gamma \)  is  decomposable,  the  string  condition  and  \((2),(3)\)  implies  that  any  element  in
\(\Delta _+\) is  decomposable  into  things  in  exactly  one  of  the  decompositions  of  \(\Gamma \),  showing
\(\Delta \) is  decomposable.  Conversely  if  \(\Delta \)  is  decomposable,  as  noted  earlier  the  string
condition shows the decomposition is orthogonal, implying that that the simple roots
decompose orthogonally too.
</p><!--l. 613--><p class="indent" >  \((6)\): If \(\theta \) is a highest root and \(\alpha \) a positive root, then \(\theta +\alpha \notin \Delta \) because it is larger than \(\theta \). Then
the string condition implies \((\theta ,\alpha )\geq 0\). By \((1),(2)\), the set of \(\gamma \in \Pi \) orthogonal to \(\theta \) and the set of \(\gamma \in \Pi \) in the
decomposition of \(\theta \) are a decomposition of \(\Pi \), so by indecomposability we must have \((\theta ,\gamma )&gt;0\)
for \(\gamma \in \Pi \) and hence for all elements of \(\Delta _+\).
</p><!--l. 615--><p class="indent" >  But if \(\theta _1\neq \theta _2\) are highest roots, \(f(\theta _1-\theta _2)\) = 0 so it cannot be a root and \(f(\theta _1+\theta _2)&gt;f(\theta _1)\) so it isn&#x2019;t a root. the
string condition then says \((\theta _1,\theta _2) = 0\), but this was shown to not be possible. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 619--><p class="noindent" ><span class="head">
<a 
 id="x1-7008r2"></a>
<span 
class="cmbx-12">De&#xFB01;nition 6.2.</span>  </span><span 
class="cmti-12">If</span> \(\gamma _1,\dots ,\gamma _r\) <span 
class="cmti-12">are the simple roots, then the matrix</span> \(A\) <span 
class="cmti-12">with entries</span> \(\langle \gamma _i|\gamma _i\rangle \) <span 
class="cmti-12">is called the</span>
<span 
class="cmbxti-10x-x-120">Cartan matrix</span><span 
class="cmti-12">.</span>
</p>
  </div>
  <div class="newtheorem">
<!--l. 623--><p class="noindent" ><span class="head">
<a 
 id="x1-7009r3"></a>
<span 
class="cmbx-12">Lemma 6.3.</span>  </span> <span 
class="cmti-12">The Cartan matrix</span> \(A\) <span 
class="cmti-12">is an integer matrix with</span> \(2\) <span 
class="cmti-12">on the diagonals,</span>
                                                                                  

                                                                                  
<span 
class="cmti-12">nonpositive numbers on the o&#xFB00;-diagonals, and positive principle values. Moreover</span>
\(A_{ij}=0 \iff A_{ji}=0\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 626--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>The &#xFB01;rst,second, and last claim are clear, the third follows from the previous
theorem, and the fourth follows from Sylvester&#x2019;s criterion because the Cartan matrix
is the inner product matrix except with the rows rescaled. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 630--><p class="noindent" ><span class="head">
<a 
 id="x1-7010r4"></a>
<span 
class="cmbx-12">De&#xFB01;nition 6.4.</span>  </span><span 
class="cmti-12">If</span> \(\gamma _1,\dots ,\gamma _r,\theta \) <span 
class="cmti-12">are the simple roots, then the matrix</span> \(\tilde{A}\) <span 
class="cmti-12">with the same entries for</span>
\(A\) <span 
class="cmti-12">except including</span> \(\theta \) <span 
class="cmti-12">is called the </span><span 
class="cmbxti-10x-x-120">extended Cartan matrix</span><span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 634--><p class="indent" >  \(\tilde{A}\) clearly satis&#xFB01;es the same properties as \(A\) except the determinant is \(0\).
</p>
  <div class="newtheorem">
<!--l. 636--><p class="noindent" ><span class="head">
<a 
 id="x1-7011r5"></a>
<span 
class="cmbx-12">De&#xFB01;nition 6.5.</span>  </span><span 
class="cmti-12">An abstract Cartan matrix is one satisfying the properties of Lemma</span>
<a 
href="#x1-7009r3"><span 
class="cmti-12">6.3</span><!--tex4ht:ref: cartanproperties --></a><span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 640--><p class="indent" >  A Cartan matrix is <span 
class="cmbx-12">indecomposable </span>i&#xFB00; it is not the direct sum of Cartan matrices.
Clearly a root system is indecomposable i&#xFB00; its Cartan matrix is.
</p>
                                                                                  

                                                                                  
  <div class="newtheorem">
<!--l. 642--><p class="noindent" ><span class="head">
<a 
 id="x1-7012r6"></a>
<span 
class="cmbx-12">Lemma 6.6.</span>  </span><span 
class="cmti-12">The only</span> \(2x2\) <span 
class="cmti-12">Cartan matricies &#x0028;up to rearrangement&#x0029; are </span>\[ \begin{bmatrix} 2 &amp; 0 \\ 0 &amp; 2 \end{bmatrix} \begin{bmatrix} 2 &amp; -1 \\ -1 &amp; 2 \end{bmatrix} \begin{bmatrix} 2 &amp; -1 \\ -2 &amp; 2 \end{bmatrix} \begin{bmatrix} 2 &amp; -1 \\ -3 &amp; 2 \end{bmatrix} \]
</p>
  </div>
<!--l. 660--><p class="indent" >  Because of this classi&#xFB01;cation and the fact that every matrix is determined by its graph
of \(2x2\) principal submatrices, the Cartan matrix is completely encoded by a <span 
class="cmbx-12">Dynkin</span>
<span 
class="cmbx-12">diagram</span>, where there is a vertex for every diagonal entry and an edge corresponding to
each \(2x2\) principal submatrix.
</p>
<div class="center" 
>
<!--l. 662--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-1" class="tabular" 
 
><colgroup id="TBL-1-1g"><col 
id="TBL-1-1" /><col 
id="TBL-1-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-1-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-1"  
class="td11">\(\begin{bmatrix} 2 &amp; 0 \\0 &amp; 2 \end{bmatrix}\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-2"  
class="td11"> <img 
src="Lie_Algebras0x.svg" alt=" "  /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-1-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-1"  
class="td11">  \(\begin{bmatrix} 2 &amp; -1 \\-1 &amp; 2 \end{bmatrix}\) </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-2"  
class="td11"> <img 
src="Lie_Algebras1x.svg" alt=" "  /></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-1"  
class="td11">\(\begin{bmatrix} 2 &amp; -1 \\-2 &amp; 2 \end{bmatrix}\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-2"  
class="td11"> <img 
src="Lie_Algebras2x.svg" alt=" "  /> </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-1"  
class="td11">\(\begin{bmatrix} 2 &amp; -1 \\-3 &amp; 2 \end{bmatrix}\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-2"  
class="td11"> <img 
src="Lie_Algebras3x.svg" alt=" "  /> </td></tr></table></div></div>
<!--l. 678--><p class="noindent" >An edge indicates two arrows that are not orthogonal. The double and triple edges indicate
that one root is longer, and they point to the shorter root.
</p><!--l. 680--><p class="indent" >  Extended Cartan matrices gives an <span 
class="cmbx-12">extended Dynkin diagram</span>, where we mark the
highest root as special. In the case of \(A_1\) the extended Cartan matrix consists of all \(2\)s, so it is
exceptional, and we denote it by  <img 
src="Lie_Algebras4x.svg" alt="  "  />  .
</p>
  <div class="newtheorem">
<!--l. 682--><p class="noindent" ><span class="head">
<a 
 id="x1-7013r1"></a>
<span 
class="cmbx-12">Example 6.6.1 </span>&#x0028;Extended Dynkin Diagrams&#x0029;<span 
class="cmbx-12">.</span>  </span>Here is a list of the extended Dynkin
diagrams of the thus-far constructed root systems. We will soon see that this list is
complete. </p>
<div class="center" 
>
<!--l. 684--><p class="noindent" >
                                                                                  

                                                                                  
</p>
<div class="tabular"> <table id="TBL-2" class="tabular" 
 
><colgroup id="TBL-2-1g"><col 
id="TBL-2-1" /><col 
id="TBL-2-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-2-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-1"  
class="td11">\(A_1\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-2"  
class="td11">     <img 
src="Lie_Algebras5x.svg" alt=" "  />      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-1"  
class="td11">\(A_n\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-2"  
class="td11">   <img 
src="Lie_Algebras6x.svg" alt=" "  />        </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-1"  
class="td11">\(B_n\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-2"  
class="td11">  <img 
src="Lie_Algebras7x.svg" alt=" "  />
             </td></tr><tr  
 style="vertical-align:baseline;" id="TBL-2-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-1"  
class="td11">  \(C_n\) </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-2"  
class="td11"> <img 
src="Lie_Algebras8x.svg" alt=" "  /></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-1"  
class="td11">\(D_n\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-2"  
class="td11">   <img 
src="Lie_Algebras9x.svg" alt=" "  />
             </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-6-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-1"  
class="td11">\(E_6\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-6-2"  
class="td11">   <img 
src="Lie_Algebras10x.svg" alt=" "  />        </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-7-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-1"  
class="td11">\(E_7\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-7-2"  
class="td11">   <img 
src="Lie_Algebras11x.svg" alt=" "  />        </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-8-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-1"  
class="td11">\(E_8\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-8-2"  
class="td11"> <img 
src="Lie_Algebras12x.svg" alt=" "  />           </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-9-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-1"  
class="td11">\(F_4\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-9-2"  
class="td11">   <img 
src="Lie_Algebras13x.svg" alt=" "  />        </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-10-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-10-1"  
class="td11">\(G_2\)</td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-10-2"  
class="td11">     <img 
src="Lie_Algebras14x.svg" alt=" "  />       </td></tr></table></div></div>
<!--l. 698--><p class="noindent" >Now let&#x2019;s see why these are as above. We will always choose \(f\) so the \(e_i\) are positive and \(e_i\) is
much larger than \(e_{i+1}\). </p>
          <ul class="itemize1">
       <li class="itemize">\(A_n\):, The roots are \(e_i-e_j\) &#x0028;we drop the \((-)^*\) in the notation&#x0029;. Then the simple roots are \(e_i-e_{i+1}\),
       and the largest root is \(e_1-e_n\).
          </li>
       <li class="itemize">\(B_n\): The roots are \(\pm (e_i +e_j),e_i - e_j, \pm e_i\). Then the simple roots are \(e_n, e_{i}-e_{i+1}\), and the largest root is \(e_1+e_2\).
          </li>
       <li class="itemize">\(C_n\): The roots are \(\pm (e_i+e_j),e_i-e_j, 2e_i\). The simple roots are \(2e_n, e_{i}-e_{i+1}\), and the largest root is \(2e_1\).
          </li>
       <li class="itemize">\(D_n\): The roots are \(\pm (e_i+e_j), e_i-e_j\). The simple roots are \(e_i-e_{i+1}, e_n+e_{n-1}\) and the largest root is \(e_1+e_2\)
          </li>
       <li class="itemize">\(E_8\): The roots are \(\pm (e_i+e_j), e_i - e_j\) and things of the form \(\frac{1}{2}(e_1\pm \dots e_8)\) where there are an even number of
       minus signs. The simple roots are then \(e_i-e_{i+1}\) for \(i&gt;1\), \(e_8+e_7, \frac 1 2 (e_1+e_8-\sum _2^6 e_i)\), and the largest root is \(e_1+e_2\).
          </li>
       <li class="itemize">\(E_7\): The roots are \(e_i-e_j, i \neq j\) and things of the form \(\frac{1}{2}(e_1\pm \dots e_8)\) where the number of minus signs is
       divisible by four. The simple roots are then \(e_i-e_j\) for \(i&gt;1\) and \(\frac 1 2 (\sum _{1,6,7,8} e_i - \sum _{2,3,4,5}e_i)\), and the largest root is
       \(e_1+e_2\).
          </li>
       <li class="itemize">\(E_6\): The roots are \(e_i-e_j\) such that if either of \(\{i,j\}\cap \{7,8\}\) is \(\{7,8\}\) or \(\phi \), as well as things of the form
       \(\frac{1}{2}(e_1\pm \dots e_8)\) where the number of minus signs is divisible by four, \(e_7,e_8\) have opposite signs.
       The simple roots are \(e_i-e_{i+1}\) for \(i \neq 1,7\) and \(\frac 1 2 (\sum _{1,5,6,8}e_i-\sum _{2,3,4,7}e_j)\) and the largest root is \(e_1-e_2\).
          </li>
       <li class="itemize">\(F_4\): The roots are \(\pm e_i, \pm (e_i + e_j), e_i-e_j, \pm \frac 1 2 (e_1\pm \dots e_4)\). The simple roots are \(\frac{1}{2} (e_1-e_2-e_3-e_4), e_4,e_2-e_3,e_3-e_4\), and the largest root is \(e_1+e_2\).
                                                                                  

                                                                                  
          </li>
       <li class="itemize">\(G_2\): The roots are \(\pm (e_i + e_j), e_i - e_j, \pm (2e_i-e_j-e_k)\). The simple roots are \(e_2-e_3, e_1-2e_2+e_3\), and the largest root is \(2e_1-e_2-e_3\).</li></ul>
  </div>
  <div class="newtheorem">
<!--l. 712--><p class="noindent" ><span class="head">
<a 
 id="x1-7014r7"></a>
<span 
class="cmbx-12">Theorem 6.7.</span>  </span><span 
class="cmti-12">The examples contain a complete list of indecomposable Cartan</span>
<span 
class="cmti-12">matrices.</span>
</p>
  <div class="proof">
<!--l. 715--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Every subdiagram of a Dynkin diagram is a Dynkin diagram. Moreover, any
extended Dynkin diagram is not a Dynkin diagram. Finally, for any multiple edge
on a vertex of degree \(1\) on a Dynkin diagram, reversing an isolated set of multiple
edges preserves being a Dynkin diagram since it preserves determinants of principle
submatrices.  Reducing  an  edge&#x2019;s  multiplicity  preserves  being  a  Dynkin  diagram
since it increases the determinant of the principal submatrices. These observations
essentially prove the theorem. Namely, the extended Dynkin diagrams constructed
obstruct any other Dynkin diagrams from existing via these observations.
</p><!--l. 717--><p class="indent" >  To actually work this out, \(A_n\) obstructs cycles from existing, so all Dynkin diagrams
are trees.  \(G_2\) obstructs triple edges from existing anywhere else, \(F_4\) obstructs double
edges from appearing not on a leaf. \(C_n\) obstructs double edges from appearing multiple
times elsewhere, \(B_n\) obstructs branching when there is a double edge. \(D_n\) obstructs double
branching, and \(E_6,E_7,E_8\) obstruct branches from getting too long. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 721--><p class="indent" >  Observe that the list is a bit redundant. Namely, \(A_1=B_1=C_1\), \(D_2 = A_1 \oplus A_1\), \(B_2 = C_2\), \(D_3 = A_3\), but the rest are not redundant.
Sometimes these are called <span 
class="cmbx-12">exceptional isomorphisms</span>.
</p><!--l. 723--><p class="indent" >  We will now show that this classi&#xFB01;cation also classi&#xFB01;es simple Lie algebras and
indecomposable root systems as well. First we will show nothing depends on \(f\), and that we
can recover the root system from the Cartan matrix.
                                                                                  

                                                                                  
</p><!--l. 725--><p class="indent" >  There is another way of thinking about root systems. Namely, re&#xFB02;ection across the
orthogonal plane to \(a\) is given by the equation \(r_a(v) = v-\langle a|v\rangle a\). One then sees from the string
condition that \(\Delta \) is closed under re&#xFB02;ection by any element in it &#x0028;this condition is
actually equivalent to it by checking what happens in dimension \(2\)&#x0029;. For the root
system of a Lie algebra, one can see the re&#xFB02;ection arising from the action of
the element \(\tau \) of the \(\msl _2\)-triple associated to the root. The group generated by \(r_\alpha , \alpha \in \Delta \) is
called the <span 
class="cmbx-12">Weyl group </span>and denoted \(W(\Delta )\). It is &#xFB01;nite since it acts faithfully on \(\Delta \).
The fact that there are so many symmetries already suggests \(f\) doesn&#x2019;t really do
much.
</p><!--l. 727--><p class="indent" >  If \(\gamma _1,\dots ,\gamma _r\) are the simple roots, let \(s_i = r_{\gamma _i}\); these are called simple re&#xFB02;ections. De&#xFB01;ne the <span 
class="cmbx-12">height </span>of a
positive root \(\alpha \) to be \(\hgt (\alpha ) = \sum _i c_i\) where \(\alpha = \sum _i c_i \gamma _i\).
</p>
  <div class="newtheorem">
<!--l. 729--><p class="noindent" ><span class="head">
<a 
 id="x1-7015r8"></a>
<span 
class="cmbx-12">Theorem 6.8.</span>  </span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(s_i\) <span 
class="cmti-12">preserves</span> \(\Delta _+-\gamma _i\)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">If</span> \(\alpha \in \Delta _+-\Pi \)<span 
class="cmti-12">, there is an</span> \(i\) <span 
class="cmti-12">so that</span> \(\hgt (s_i(\alpha )) &lt; \hgt (\alpha )\)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">There is a sequence of simple re&#xFB02;ections taking any positive root to an element</span>
       <span 
class="cmti-12">of</span> \(\Pi \) <span 
class="cmti-12">such that at every step it is still positive.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;4&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(W\) <span 
class="cmti-12">is generated by simple re&#xFB02;ections.</span></dd></dl>
  <div class="proof">
<!--l. 737--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\((1)\): Such an element looks like \(\sum _jc_j \gamma _j\) where \(c_j &gt; 0\) for some \(j \neq i\). \(\gamma _j\) are linearly independent and
everything is either a strictly positive or negative linear combination of them, so the
result follows.
</p><!--l. 739--><p class="indent" >  \((2)\): \((\alpha ,\alpha )&gt;0\), and \(\alpha \) is a positive sum of \(\gamma _i\)s so \((\alpha ,\gamma _i)&gt;0\) for some \(i\). Then \(s_i(\alpha )\) has smaller height.
</p><!--l. 741--><p class="indent" >  \((3)\): Follows immediately from \((2)\).
</p><!--l. 743--><p class="indent" >  \((4)\): By \((3)\) we can get between from element of \(\Delta \) and an element \(\gamma _i\) of \(\Pi \) via simple re&#xFB02;ections.
                                                                                  

                                                                                  
Now conjugating \(s_i\) by this composite of simple re&#xFB02;ections gives the re&#xFB02;ection by that
element. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 747--><p class="indent" >  We can consider \(V-\cup _{\alpha \in \Delta }T_\alpha \) where \(T_\alpha \) is the plane perpendicular to \(\alpha \). The components of this
are called the <span 
class="cmbx-12">Weyl chambers</span>. The Weyl group acts on these chambers since
\(r_\alpha (T_\beta ) = T_{r_\alpha (\beta )}\).
</p>
  <div class="newtheorem">
<!--l. 749--><p class="noindent" ><span class="head">
<a 
 id="x1-7020r9"></a>
<span 
class="cmbx-12">Lemma 6.9.</span>  </span>\(x\) <span 
class="cmti-12">such that</span> \((x,\gamma )&gt;0\) <span 
class="cmti-12">for any</span> \(\gamma \in \Delta \) <span 
class="cmti-12">form a chamber.</span>
</p>
  <div class="proof">
<!--l. 752--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Since anything is a positive or negative learn combination of \(\Pi \), the set described
doesn&#x2019;t contain anything orthogonal to anything in \(\Delta \). Moreover its boundary clearly
consists of things that do. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 756--><p class="indent" >  A word in the \(s_i\) is <span 
class="cmbx-12">reduced </span>if it isn&#x2019;t equivalent to a shorter word in \(W\). The length of a
reduced work representing \(w \in W\) is called its <span 
class="cmbx-12">length</span>, denoted \(l\).
</p>
  <div class="newtheorem">
<!--l. 757--><p class="noindent" ><span class="head">
<a 
 id="x1-7021r10"></a>
<span 
class="cmbx-12">Lemma 6.10 </span>&#x0028;Exchange Lemma&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Suppose that</span> \(s_{i_1}\dots s_{i_{t-1}}(\gamma _{i_t}) \in \Delta _-\)<span 
class="cmti-12">. Then</span> \(s_{i_1}\dots s_{i_t}\) <span 
class="cmti-12">isn&#x2019;t reduced. In fact, it is equal</span>
<span 
class="cmti-12">to</span> \(s_{i_1}\dots s_{i_{m-1}}s_{i_{m+1}}\dots s_{i_{t-1}}\) <span 
class="cmti-12">for some</span> \(m\)<span 
class="cmti-12">.</span>
                                                                                  

                                                                                  
</p>
  <div class="proof">
<!--l. 760--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>The sequence \(\beta _k = s_{i_k}\dots s_{i_{t-1}}(\gamma _{i_t})\) at some point switches from negative to positive, which can
only happen by the previous theorem if \(\beta _{m+1}\) is \(\gamma _{i_m}\). But then \(w=s_{i_{m+1}}\dots s_{i_{t-1}}\) satis&#xFB01;es \(ws_{i_t}w^{-1} = s_{i_m}\) which gives the result
after multiplying by \(w\) on the right. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 764--><p class="noindent" ><span class="head">
<a 
 id="x1-7022r11"></a>
<span 
class="cmbx-12">Theorem 6.11.</span>  </span>\(W\) <span 
class="cmti-12">acts simply and transitively on chambers, and on possible sets of simple</span>
<span 
class="cmti-12">roots.</span>
</p>
  <div class="proof">
<!--l. 767--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>To see it acts transitively on chambers, make a generic path between two
chambers and everytime you cross a wall, do a re&#xFB02;ection. By realizing the re&#xFB02;ections
on \(f\) and on \(\Pi \), we see that the chambers correspond to sets of simple roots for various
choices of \(f\). To see that the action is simple, suppose that \(w\in W\) &#xFB01;xes \(\Pi \). If \(w = s_{i_1}\dots s_{i_{t}}\), then the exchange
lemma shows it isn&#x2019;t reduced. Thus \(w\) must be trivial. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 771--><p class="noindent" ><span class="head">
<a 
 id="x1-7023r12"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">Corollary 6.12.</span>  </span><span 
class="cmti-12">The Cartan matrix is not dependent on</span> \(f\) <span 
class="cmti-12">and one can recover the root</span>
<span 
class="cmti-12">system from the Cartan matrix. In fact there is a bijection between indecomposable Cartan</span>
<span 
class="cmti-12">matrices and root systems.</span>
</p>
  <div class="proof">
<!--l. 774--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>The Cartan matrix essentially encodes the inner product on \(\Pi \) which form
a basis for the vector space. Thus we can recover these vectors, but by using the
re&#xFB02;ections by these vectors, we can recover everything. To see this always gives a
root system, note that &#xFB01;niteness follows from everything lying on a lattice and being
bounded. Most of the conditions are easy, and since it is closed under re&#xFB02;ections of
the generators and generated by them, it is closed under re&#xFB02;ections of all elements.
<span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 778--><p class="noindent" ><span class="head">
<a 
 id="x1-7024r1"></a>
<span 
class="cmbx-12">Example 6.12.1.</span>  </span>\(A_n\) has Weyl group \(S_{n+1}\) coming from the permutations of the \(e_i\).
</p>
  </div>
<!--l. 782--><p class="indent" >  Recall \(\mg \) semisimple is \(\mh \oplus \bigoplus _{\alpha \in \Delta }\mg _{\alpha } = \mg \oplus \mn _+ \oplus \mn _- \). where \(\mn _+,\mn _-\) are the nilpotent subalgebra of positive/negative root
spaces. We would like to &#xFB01;nd a description in terms of the Cartan matrix \(A_{ij}\). Let \(\gamma _1\dots \gamma _r\) be the
simple roots, and let \(e_i,f_i,h_i\) be \(\msl _2\)-triples corresponding to \(\gamma _i\). Note that they generate the algebra,
are linearly independent, and satisfy the following relations called the <span 
class="cmbx-12">Chevalley</span>
<span 
class="cmbx-12">relations</span>:
</p><!--l. 785--><p class="indent" >
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   &#x0028;1&#x0029; </dt><dd 
class="enumerate-enumitem">\([h_i,h_j]=0\)
                                                                                  

                                                                                  
          </dd><dt class="enumerate-enumitem">
   &#x0028;2&#x0029; </dt><dd 
class="enumerate-enumitem">\([h_i,e_j]=\langle \gamma _i|\gamma _j\rangle e_i\)
          </dd><dt class="enumerate-enumitem">
   &#x0028;3&#x0029; </dt><dd 
class="enumerate-enumitem">\([h_i,f_j]= -\langle \gamma _i|\gamma _j\rangle f_i\)
          </dd><dt class="enumerate-enumitem">
   &#x0028;4&#x0029; </dt><dd 
class="enumerate-enumitem">\([e_i,f_j]= \delta _{ij}h_i\)</dd></dl>
<!--l. 791--><p class="indent" >  Note that these relations come from entries in the Cartan matrix: namely \(\langle \gamma _i|\gamma _j\rangle \)
is \(A_{ij}\). Let \(\tilde{\mg }\) denote the free Lie algebra presented by these relations. Let \(\tilde{\mn }_+,\tilde{\mn }_-\) denote
the subalgebras generated by \(e_i\) and \(f_i\) respectively. When the Cartan matrix was
constructed from a Lie algebra, there is a natural surjective map to \(\tilde{\mg } \to \mg \). Note that the
construction is symmetric in the \(f_i,e_i\): we can swap the two and replace \(h_i\) with its negative
and the same relations hold. This means we have to prove half as many things
about the construction. We will still use \(\gamma _i \in \Pi \) to denote the weights of the span of \(\ad (h_i)\) on
\(e_i\).
</p><!--l. 793--><p class="indent" >  Consider the \(T(V)\) the tensor algebra on the vector space \(V\) generated by \(v_1,\dots , v_r\). This should be
thought of as the universal enveloping algebra of \(\tilde{\mg }/(\tilde{\mn }_+\oplus \mh )\). Of course this doesn&#x2019;t make sense since
the quotient isn&#x2019;t by an ideal, but it is the quotient as an algebra and can probably be
thought of as the invariant di&#xFB00;erential operators on the quotient formal group. We can
produce an action of \(\tilde{\mg }\) on \(T(V)\) as follows: \(h_k\) sends \(v_{i_1}\dots v_{i_s}\) to \(-(\sum _1^sA_{k,i_j}\rangle ) v_{i_1}\dots v_{i_s}\), \(f_k\) sends \(v_{i_1}\dots v_{i_s}\) to \(v_k v_{i_1}\dots v_{i_s}\), and \(e_k\) sends \(v_{i_1}\dots v_{i_s}\) to \(\sum _1^s (\delta _{k,i_j}v_{i_1}\dots \hat{v_{i_j}}\dots v_{i_s})\). A
straightforward calculation shows that this satis&#xFB01;es the Chevalley relations, so is indeed an
action.
</p><!--l. 795--><p class="indent" >  For the next lemma, it will be convenient to introduce notation. \(e(s),f(s)\) denote an iterated
bracket of \(s\) of the \(e_i,f_i\) respectively, and \(\Sigma \) to denote a linear combination. \(f(0)\) or \(e(0)\) will mean the
\(h_i\).
</p>
  <div class="newtheorem">
<!--l. 796--><p class="noindent" ><span class="head">
<a 
 id="x1-7029r13"></a>
<span 
class="cmbx-12">Lemma 6.13.</span>  </span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\tilde{\mg } = \tilde{\mn }_+\oplus \tilde{\mn }_-\oplus{\mh }\)
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\mn _+,\mn _-\) <span 
class="cmti-12">are free on the</span> \(e_i,f_i\) <span 
class="cmti-12">and</span> \(\tilde{\mn }_+ = \oplus _{\alpha \in \QQ _+} \mg _\alpha , \tilde{\mn }_- = \oplus _{\alpha \in \QQ _+} \mg _{-\alpha }\) <span 
class="cmti-12">where</span> \(\QQ _+\) <span 
class="cmti-12">is</span> \(\ZZ _{\geq 0} \Pi -0\) <span 
class="cmti-12">and</span> \(\alpha \) <span 
class="cmti-12">is the weights of the</span> \(\mh \) <span 
class="cmti-12">action.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">If</span> \(I\) <span 
class="cmti-12">is an ideal in</span> \(\tilde{\mg }\) <span 
class="cmti-12">then</span> \(I = \mh \cap I \oplus \bigoplus _\alpha \mg _\alpha \cap I\)<span 
class="cmti-12">.</span>
          </dd><dt class="enumerate-enumitem">
                                                                                  

                                                                                  
   <span 
class="cmti-12">&#x0028;4&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">Maximal ideals in</span> \(\tilde{\mg }\) <span 
class="cmti-12">correspond to components of the Dynkin diagram.</span></dd></dl>
  <div class="proof">
<!--l. 804--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\((1)\): The action on \(T(V)\) gives a Lie algebra homomorphism \(\tilde{\mg } \to T(V)\). First note that the \(h_i\)
are linearly independent since the Cartan matrix is nonsingular. The Jacobi identity
&#x0028;equivalent to the fact that \(\ad \) is a derivation&#x0029; \([h,e(s)]=[h,[e(1),e(s-1)]] = [[h,e(1)],e(s)]+[e(1),[h,e(s-1)]]\) shows via induction on \(s\) that for an
iterated bracket of \(e_{i_1},\dots , e_{i_s}\) that \(\ad h_k\) has eigenvalue \(\sum _1^sA_{k,i_j}\), and by symmetry the same is true for \(f_i\)
with the opposite eigenvalue.
</p><!--l. 806--><p class="indent" >  Next we can see inductively that \([f(s),e(s')]\) is a linear combination of \([f(s-s')]\) when \(s\geq s'\geq 0\) via \([f(s),e(s')] = [f(s),[e(s'-1),e(1)]] = [[f(s),e(s'-1)],e(1)]+[e(s'-1),[f(s),e(1)]]\) reducing to
\(s'=1\) and \([f(s),e(1)] = [[f(s-1),f(1)],e(1)] = [[f(s-1),e(1)],f(1)]+ [f(s-1),[f(1),e(1)]]\) reducing to \(s=1\), where it follows from relation \((4)\). The same statement holds when \(e,f\)
are switched.
</p><!--l. 808--><p class="indent" >  Thus  \(\tilde{\mn }_+ + \tilde{\mn }_- + \mh \)  is  a  subalgebra,  but  it  isn&#x2019;t  clear  that  the  sum  is  direct.  However,  by
nondegeneracy we can &#xFB01;nd \(h \in \mh \) such that its eigenvalue on \(e(s)\) is positive, and hence on \(f(s)\) is
negative. Moreover \([\mh ,\mh ]=0\) so the eigenspace decomposition of \(h\) separates these subalgebras.
</p><!--l. 810--><p class="indent" >  \((2)\): There is a commutative square </p>
<div class="center" 
>
<!--l. 811--><p class="noindent" >
</p><!--l. 815--><p class="noindent" >                <img 
src="Lie_Algebras15x.svg" alt="F &#x0028;fi&#x0029;            &#x02DC;&#x1D52B; &#x2212;


End &#x0028;T &#x0028;fi&#x0029;&#x0029;       End &#x0028;T &#x0028;V &#x0029;&#x0029; "  />
</p></div>
<!--l. 817--><p class="noindent" >where the left vertical map is the canonical action on the universal enveloping algebra.
Since the left arrow is injective and the bottom arrow is an isomorphism, the top
arrow is injective. But it is also clearly surjective, so it is an isomorphism. Thus \( \tilde{\mn }_+ \)
is free and by symmetry \( \tilde{\mn }_- \) is too. The second statement was already proven in
\((1)\).
</p><!--l. 819--><p class="indent" >  \((3)\): Given an element \(x \in I\), keep acting by the elements of \(\mh \). Since \(\mh \) acts semisimply, some
linear combination of the \(\ad (\mh )^i x\) will be the projection onto the various eigenspaces of
\(x\).
</p><!--l. 821--><p class="indent" >  \((4)\): Consider any proper ideal of \(\tilde{\mg }\). By \((3)\) if its intersection with \(\mh \) wasn&#x2019;t \(0\), it would have to
contain all nonzero weight spaces of its intersection in \(\mh \), which would contain atleast one \(f_i,e_i\).
Thus it would contain \([e_i,f_i]=h_i\), for which the eigenvalue doesn&#x2019;t vanish for all neighbors of \(\gamma _i\).
                                                                                  

                                                                                  
Continuing this way since it is indecomposable, it would have to contain the whole
component. Thus the union of all ideals containing the part of \(\mh \) orthogonal to some
component of a Dynkin diagram is a maximal ideal, and moreover all maximal ideals must
be contained in one of these. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 825--><p class="indent" >  If the Cartan matrix is indecomposable, there is a unique maximal ideal, and if we
already know that the Cartan matrix comes from a simple Lie algebra, the quotient has to
be that simple Lie algebra. The only information this really gives us is knowing the
quotient is &#xFB01;nite-dimensional. However we will now prove that we should apriori expect
the quotient to be &#xFB01;nite dimensional.
</p>
  <div class="newtheorem">
<!--l. 827--><p class="noindent" ><span class="head">
<a 
 id="x1-7034r14"></a>
<span 
class="cmbx-12">Theorem 6.14.</span>  </span><span 
class="cmti-12">Consider the intersection of all the maximal ideals of</span> \(\tilde{\mg }\)<span 
class="cmti-12">. The quotient by</span>
<span 
class="cmti-12">this is a semisimple Lie algebra, whose Cartan subalgebra and root system are exactly the</span>
<span 
class="cmti-12">ones used to construct it.</span>
</p>
  <div class="proof">
<!--l. 830--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>We can make a reduction to the case of an indecomposable Cartan matrix by
observing that a splitting of the Cartan matrix splits everything involved \(\mh ,\tilde{\mg },\tilde{\mn _+},\tilde{\mn _-}\). In this
case when it is simple, if we can &#xFB01;nd a proper ideal with quotient &#xFB01;nite dimensions
\(&gt;1\), then the quotient is simple, and \(\mh \) is clearly self normalizing with \(\mg _{\alpha }\) are its weight
spaces, so we would be done. The quotient contains cannot be \(1\)-dimensional since if
an ideal contains any of the \(e_i,f_i,h_i\), it must contain everything.
</p><!--l. 832--><p class="indent" >  To prove &#xFB01;nite-dimensionality, we &#xFB01;rst prove that when \(i\neq j\) and \(k\) is arbitrary, \(\ad e_k (\ad f_i)^{1-A_{ij}}(f_j)=0\). If \(k\neq i\),
this is equal to \( (\ad f_i)^{1-A_{ij}}\ad e_k(f_j) = (\ad f_i)^{1-A_{ij}}\delta _{jk} h_j = (\ad f_i)^{-A_{ij}}A_{ij}f_i = 0\). If \(k = i\), \(e_i,f_i\) are part of an \(\msl _2\)-triple, so it follows from representation theory
of \(\msl _2\) that \(\ad e_i (\ad f_i)^{t}(f_j)= t(A_{ik}-t+1)(\ad f_i)^{t-1}(f_j) = 0\) by our choice of \(t\).
</p><!--l. 834--><p class="indent" >  Now let \(J_+,J_-\) be the ideals of \(\tilde{\mn }_+,\tilde{\mn }_-\) generated by \((\ad f_i)^{1-A_{ij}}(f_j)\) and \((\ad e_i)^{1-A_{ij}}(e_j)\). By what was just shown, these are
also ideals of \(\tilde{\mg }\). Let \(J\) be their sum. I claim \(\tilde{\mg }/J\) is &#xFB01;nite dimensional. Note that \(\ad e_i,\ad f_i\) act locally
                                                                                  

                                                                                  
nilpotently on this, since they do on generators and \(\ad \) is a derivation. Now we still
have for each \(i\) the \(\msl _2\)-triple associated to \(e_i,f_i,h_i\). Then \(\tilde{\mg }/J\) is a sum of &#xFB01;nite-dimensional modules
for these \(\msl _2\)-triples since the \(e_i,f_i\) act locally nilpotently.
</p><!--l. 836--><p class="indent" >  Thus we can consider the action of \(\tau _i\) from the representation theory of \(\msl _2\) which is
an involution swapping positive and negative eigenspaces, implementing the Weyl
group re&#xFB02;ection of the corresponding simple root on \(\ZZ \Pi \). We know that \(\tilde{\mg }_{k\gamma _i}\) is \(1\)-dimensional
for \(k = \pm 1\) and \(0\)-dimensional for \(|k|&gt;1\) so the same is true for anything connected to these by the
Weyl group action. In particular all the roots of the corresponding root space have
\(1\)-dimensional eigenspaces. Now consider \(\alpha \) in \(\QQ _+\coprod -\QQ _+\) that is not a multiple of a root. then the
plane orthogonal to \(\alpha \) isn&#x2019;t contained in any of the boundaries of the Weyl chambers,
and we can &#xFB01;nd \(\mu \in \ZZ \Pi \) orthogonal to it on the interior of a Weyl chamber. Then acting by
an element of the Weyl group \(w\) we can move \(\mu \) to the Weyl chamber corresponding to
\(\Pi \). Then \(w(\mu )\) is a sum of positive multiples of the \(\gamma _i\) and since it is orthogonal to \(w(\alpha )\), \(w(\alpha )\) must
contain both positive and negative terms in its decomposition as \(\sum _i c_i \gamma _i\). But then \(0=\tilde{\mg }_{w(\alpha )} \cong \tilde{\mg }_{\alpha }\). Thus
the quotient is &#xFB01;nite-dimensional, and in fact we have proven \(J\) is the maximal ideal.
<span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <h3 class="sectionHead"><span class="titlemark">7. </span> <a 
 id="x1-80007"></a>Homological Methods</h3>
<!--l. 842--><p class="noindent" >Lets expand on homological methods, which were &#xFB01;rst mentioned in the proof of
Weyl&#x2019;s theorem that a semisimple Lie algebra has semisimple &#xFB01;nite dimensional
representations.
</p><!--l. 844--><p class="indent" >  Usually \(\Ext \) and \(\Tor \) are the main tools of studying representations of algebras but
for a Hopf algebra, we can do with a bit less. First observe that the antipode
makes left and right modules canonically equivalent, so we can drop the lefts and
rights.
</p>
  <div class="newtheorem">
<!--l. 846--><p class="noindent" ><span class="head">
<a 
 id="x1-8001r1"></a>
<span 
class="cmbx-12">De&#xFB01;nition 7.1.</span>  </span>\(H_*(\mg ,M)\) <span 
class="cmti-12">is</span> \(\Tor _*^{U(\mg )}(k,M)\)<span 
class="cmti-12">,</span> \(H^*(\mg ,M)\) <span 
class="cmti-12">is</span> \(\Ext ^*_{U(\mg )}(k,M)\)<span 
class="cmti-12">.</span>
</p>
                                                                                  

                                                                                  
  </div>
<!--l. 849--><p class="indent" >  In otherwords, \(H_*\), the homology, is the left derived functors of the coinvariants and \(H^*\),
cohomology, is the right derived functors of invariants. The \(\mg \) will be dropped if
unambiguous. The homology, cohomology should be thought of as sheaf cohomology on
the associated Lie group &#x0028;the sheaf being trivial for the module \(k\)&#x0029;. When the module is \(k\)
itself, we can also refer to it as cohomology and homology of the Lie algebra. \(M\) should
correspond to a right invariant trivial vector bundle such that di&#xFB00;erentiating the \(\Ad \)
action gives the actiono of \(\mg \) on the &#xFB01;bre. Indeed this construction coincides with
the construction of \(\ad \). The reason these are well equipped to replace \(\Ext \) and \(\Tor \) is the
following:
</p>
  <div class="newtheorem">
<!--l. 850--><p class="noindent" ><span class="head">
<a 
 id="x1-8002r2"></a>
<span 
class="cmbx-12">Proposition 7.2.</span>  </span>\(\Ext ^*(M,N) = H^*(\Hom (M,N))\)<span 
class="cmti-12">,</span> \(\Tor ^*(M,N) = H_*(\Hom (M,N)))\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 853--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\(\Hom _{\mg }(M,N) \cong \Hom _{\mg }(k,\Hom (M,N))\). Take right derived functors in \(N\). On the right hand side, \(\Hom (M,-)\) is exact and sends
injectives to injectives by the tensor hom adjunction since tensor products are exact,
so the edge homomorphism in the Grothendieck spectral sequence is an isomorphism.
</p><!--l. 855--><p class="indent" >  The same argument works for \(\Tor \) since \(M\otimes _{\mg } N \cong k \otimes _{\mg } (M \otimes N)\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 859--><p class="indent" >  Since \(U(\mg ) \otimes _k U(\mg ')\) = \(U(\mg \oplus \mg ')\) we get Kunneth isomorphisms: \[\bigoplus _{p+q=n} H_p(\mg ,k)\otimes H_p(\mg ',k) = H_n(\mg \oplus \mg ',k)\]\[\bigoplus _{p+q=n} H^p(\mg ,k)\otimes H^p(\mg ',k) =H^n(\mg \oplus \mg ',k)\]
</p><!--l. 862--><p class="indent" >  Using the diagonal \(\mg \to \mg \oplus \mg \) we get a coalgebra structure and an algebra structure on the
homology and cohomology of \(\mg \).
</p><!--l. 864--><p class="indent" >  \(H_1,H^1\) are easy to interpret. Let \(J\) denote the augementation ideal of \(U(\mg )\).
</p>
  <div class="newtheorem">
<!--l. 866--><p class="noindent" ><span class="head">
<a 
 id="x1-8003r3"></a>
                                                                                  

                                                                                  
<span 
class="cmbx-12">Lemma 7.3.</span>  </span>\(H_1(k) = \mg /[\mg ,\mg ]\)
</p>
  <div class="proof">
<!--l. 869--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>\(0 \to J \to U(\mg ) \to k \to 0\), so taking the long exact sequence in homology, we get \(H_1(k) = H_0(J) = \mg /[\mg ,\mg ]\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 873--><p class="noindent" ><span class="head">
<a 
 id="x1-8004r4"></a>
<span 
class="cmbx-12">Lemma 7.4.</span>  </span>\(H^1(M) = \Der (M)/\Ider (M)\)
</p>
  <div class="proof">
<!--l. 876--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Again look at the long exact sequence for \(0 \to J \to U(\mg ) \to k \to 0\) after taking \(\Hom \) into \(M\). We get \(0 \to \Hom (k,M) \to \Hom (U(\mg ),M) \to \Hom (J,M) \to H^1(M) \to 0\). \(\Hom (J,M)\) is the
derivations, and the image of \(\Hom (U(\mg )),M\) is the inner derivations. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 880--><p class="indent" >  If \(M\) is trivial, then \(\Ider (M)\) is trivial, and \(\Der (M)\) is \(\Hom _{\Lie }(\mg ,M)\). Suppose we have a short exact sequence \(0 \to \mh \to \mg \to \mg /\mh \to 0\). The
forgerful functor from \(\mg /\mh \) modules to \(\mg \) modules has left adjoint \(\mh \)-coinvariants and right
adjoint \(\mh \)-invariants. Taking \(\mg \)-invariants is the composite of taking \(\mh \)-invariants and
then taking \(\mg /\mh \)-invariants, and similarly for coinvariants so we get Grothendieck
spectral sequences: \[E_2^{p,q} = H^p(\mg /\mh ,H^q(\mh ,M)) \Rightarrow H^{p+q}(\mg , M) \] \[E_{p,q}^2 = H_p(\mg /\mh ,H_q(\mh ,M)) \Rightarrow H_{p+q}(\mg , M) \] These are also called the <span 
class="cmbx-12">Hochschild-Serre spectral</span>
<span 
class="cmbx-12">sequences</span>.
</p><!--l. 885--><p class="indent" >  \(H^2(M)\) has a simple interpretation: it is extensions of \(\mg \) by the abelian Lie algebra
\(M\).
                                                                                  

                                                                                  
</p>
  <div class="newtheorem">
<!--l. 886--><p class="noindent" ><span class="head">
<a 
 id="x1-8005r5"></a>
<span 
class="cmbx-12">Theorem 7.5.</span>  </span>\(\Ext (\mg ,M) = H^2(\mg ,M)\)<span 
class="cmti-12">.</span>
</p>
  </div>
<!--l. 889--><p class="indent" >  Given an extension \(0 \to M \to \me \to \mg \to 0\), we can look at low dimenisonal exact sequence of the spectral
sequence in cohomology: \[0 \to H^1(\mg ,M) \to H^1(\me ,M) \to H^1(M,M)^{\mg } \to H^2(\mg ,M) \to H^2(\me ,M)\] The image of the identity in \(H^1(M,M)^{\mg } = \Hom _{\mg }(M,M)\) is the class corresponding to the
extension. This gives a map \(\Ext (\mg ,M) \xrightarrow{d^2} H^2(\mg ,M)\). To go in the other direction, we can use a presentation of
\(\mg \).
</p>
  <div class="newtheorem">
<!--l. 893--><p class="noindent" ><span class="head">
<a 
 id="x1-8006r6"></a>
<span 
class="cmbx-12">Lemma 7.6.</span>  </span><span 
class="cmti-12">For a free Lie algebra on the set</span> \(X\)<span 
class="cmti-12">,</span> \(J\) <span 
class="cmti-12">is a free module on the set</span> \(X\)<span 
class="cmti-12">. Thus</span> \(H^i(M),H_i(M) = 0\) <span 
class="cmti-12">for</span>
\(i&gt;1\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 896--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>This is because it is the augmentation ideal of a tensor algebra. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 900--><p class="indent" >  Now consider a presentation \(0 \to \ma \to \mff \to \mg \to 0\), where \(\mff \) is free, and mod out by the ideal generated by \([\ma ,\ma ]\) so
that it is an extension of \(\mg \) by \(\mg _{ab}\) which is abelian. This is actually the unversal extension in
that \(\Hom (\ma _{ab}, M) = H^2(\mg ,M)\) classi&#xFB01;es extensions by \(M\).
</p><!--l. 902--><p class="indent" >  Given any extension \(\me \), we can form the diagram below since \(\mff \) is free and \(M\) is abelian:
</p>
<div class="center" 
>
                                                                                  

                                                                                  
<!--l. 903--><p class="noindent" >
</p><!--l. 908--><p class="noindent" >                      <img 
src="Lie_Algebras16x.svg" alt="0        &#x1D51E;           &#x1D523;          &#x1D524;        0


0        &#x1D51E;           &#x1D523;&#x2215;&#x005B;&#x1D51E;, &#x1D51E;&#x005D;    &#x1D524;        0
          ab


0        M           &#x1D522;          &#x1D524;        0 "  />
</p></div>
<!--l. 911--><p class="indent" >  Now the map producing the class in \(H^2\) corresponding to \(\me \) factors as \[\Hom _{\mg }(M,M) \to \Hom _{\mg }(\ma _{ab}, M) = H^1(\ma _{ab},M)^{\mg } \xrightarrow{d^2} H^2(\mg ,M)\]
</p><!--l. 914--><p class="indent" >  By naturality the extension class in \(H^2(\mg ,\ma _{ab})\) gets sent to the corresponding class in \(H^2(\mg ,M)\). Since \(H^2(\mff ,M)\)
vanishes, the restriction of any class in \(H^2(\mg ,M)\) to \(\mff \) vanishes. From the low-dimensional exact
sequence, this means that there is an element of \(H^1(\ma ,M)^\mg = \Hom _{\mg }(\ma _{ab},M)\) lifting \(H^2(\mg ,M)\). One can then from the semidirect
product \(M\ltimes \mff \) over \(\ma \) to get an extension of \(\mg \) by \(M\) realizing the class.
</p><!--l. 917--><p class="indent" >  It su&#xFB03;ces to show that the cohomology class determines the extension. But suppose
there were two extensions \(\me _1,\me _2\) coming from the same class. They are classi&#xFB01;ed by some maps \(\phi _1,\phi _2 \in H^1(\ma _{ab},M)^{\mg }\).
By assumption their image via \(d^2\) is the same, so there is some element in \(H^1(\mff /[a,a],M)=\Der (\mff ,M)\) whose image is \(\phi _1-\phi _2\).
WLOG, the map \(\mff \to \me _1,\me _2\) is surjective, and it is then easy to see that \(\phi _2+(\phi _1-\phi _2)\) descends to an isomorphism
of extensions from \(\me _1\) to \(\me _2\).
</p>
  <div class="newtheorem">
<!--l. 919--><p class="noindent" ><span class="head">
<a 
 id="x1-8007r7"></a>
<span 
class="cmbx-12">Corollary 7.7.</span>  </span><span 
class="cmti-12">If</span> \(H^2(\mg ,M)\) <span 
class="cmti-12">vanishes for all</span> \(M\)<span 
class="cmti-12">, then</span> \(\mg \) <span 
class="cmti-12">is free.</span>
</p>
  <div class="proof">
<!--l. 922--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Choose a presentation \(\mg =\mff /\ma \) that is minimal in the sense that \(\ma \subset [\mff ,\mff ]\). Mod out by \([\mff ,\ma ]\) to see
that \(\mff /[\mff ,\ma ] = \mg \oplus \ma /[\mff ,\ma ]\) since extensions by abelian things are trivial. But \(f\) is minimal, so taking the
commutator of that equation, we see \(\ma /[\mff ,\ma ]=0\), but any subalgebra of a free algebra satisfying
that is trivial. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
                                                                                  

                                                                                  
  </div>
  </div>
<!--l. 926--><p class="indent" >  There is a canonical and e&#xFB03;cient complex called the Chevalley-Eilenberg complex that
computes Lie algebra homology and cohomology. It is a free resolution of \(k\), and is
essentially the de Rham complex.
</p><!--l. 928--><p class="indent" >  Consider the chain complex where \(V_n(\mg ) = U\mg \otimes _k \Lambda ^n\mg \), and \(d(g \otimes w_1 \dots \wedge w_n)= \sum _{i}(-1)^{i+1}ux_i \otimes w_1 \dots \wedge \hat{w_i} \dots \wedge w_n\) \(+ \sum _{i &lt;j}(-1)^{i+j}u\otimes [w_i,w_j]\otimes w_1 \dots \wedge \hat{w_i} \dots \wedge \hat{w_j} \dots \wedge w_n\). There is an obvious augmentation
\(V_*(\mg ) \to k\).
</p>
  <div class="newtheorem">
<!--l. 930--><p class="noindent" ><span class="head">
<a 
 id="x1-8008r8"></a>
<span 
class="cmbx-12">Lemma 7.8.</span>  </span>\(V_*(\mg )\) <span 
class="cmti-12">is a free resolution of</span> \(k\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 933--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>There is a &#xFB01;ltration on \(V_*\) coming from the tensor products of the &#xFB01;ltrations on
\(U(\mg ),\Lambda ^*(\mg )\). The associated graded by PBW is \(k[\mg ]\otimes _k\Lambda ^*(\mg )\), and di&#xFB00;erential is the Koszul di&#xFB00;erential. Thus
the spectral sequence for the &#xFB01;ltration degenerates at \(E^1\) to the expected cohomology.
  <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 938--><p class="noindent" ><span class="head">
<a 
 id="x1-8009r9"></a>
<span 
class="cmbx-12">Corollary 7.9.</span>  </span><span 
class="cmti-12">For an</span> \(\mg \)<span 
class="cmti-12">-module</span> \(M\)<span 
class="cmti-12">, </span>\[H_*(M) = H_*(M\otimes \Lambda ^*(\mg )), H^*(M) = H^*(\Hom (\Lambda ^*(\mg ),M)\]
</p>
  </div>
<!--l. 943--><p class="indent" >  This complex can give explicit proofs of the interpretations of \(H^1,H^2\).
</p>
                                                                                  

                                                                                  
  <div class="newtheorem">
<!--l. 945--><p class="noindent" ><span class="head">
<a 
 id="x1-8010r10"></a>
<span 
class="cmbx-12">Corollary 7.10.</span>  </span><span 
class="cmti-12">If</span> \(\mg \) <span 
class="cmti-12">has dimension</span> \(n\)<span 
class="cmti-12">, its cohomological dimension is</span> \(n\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 948--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>The Chevalley-Eilenberg complex shows it is at most \(n\). But it also shows that
\(H^n(\Lambda ^n\mg )= k \neq 0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 952--><p class="indent" >  The Chevalley-Eilenberg complex for the Lie algebra of a Lie group can be used to show
that cohomology and homology of the Lie algebra agree with homology and
cohomology of a compact connected Lie group &#x0028;over \(k\)&#x0029;. Namely, one can choose a
bi-invariant metric, and use Hodge theory to show the harmonic forms are invariant
and correspond to the cohomology of the Chevalley-Eilenberg complex. Using
this we can see why we should expect \(H^3(\msl _2)=k\), since \(\msl _2\CC \) is the complexi&#xFB01;cation of the lie
algebra of \(\su (2)\), and \(\SU (2)\) is a \(3\)-sphere. Indeed, the Chevalley-Eilenberg complex veri&#xFB01;es
this.
</p><!--l. 954--><p class="indent" >  We already showed \(H^1(\mg ,M)\) vanishes for a semisimple Lie algebra, but the same is true for \(H^2\).
First we can upgrade Weyl&#x2019;s theorem.
</p>
  <div class="newtheorem">
<!--l. 956--><p class="noindent" ><span class="head">
<a 
 id="x1-8011r11"></a>
<span 
class="cmbx-12">Proposition 7.11.</span>  </span><span 
class="cmti-12">Let</span> \(M\) <span 
class="cmti-12">be a &#xFB01;nite-dimensional nontrivial irreducible</span> \(\mg \) <span 
class="cmti-12">module in</span>
<span 
class="cmti-12">characteristic</span> \(0\)<span 
class="cmti-12">. Then</span> \(H^i(\mg ,M) = H_i(\mg ,M)=0\) <span 
class="cmti-12">for any</span> \(I\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 959--><p class="indent" >  <span class="head">
                                                                                  

                                                                                  
<span 
class="cmti-12">Proof.</span> </span>Over \(\bar{k}\), \(L\), the Casimir element, acts by a scalar on \(M\) and by \(0\) on \(k\), hence it acts on
the homology and cohomology, and the two actions coming from \(M\) and \(k\) coincide since
\(L\) is central. Thus a nonzero scalar is equal to zero, so the cohomology and homology
vanish. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 963--><p class="indent" >  Thus all the interesting &#x0028;&#xFB01;nite-dimensional&#x0029; cohomological information is in the trivial
sheaf.
</p>
  <div class="newtheorem">
<!--l. 965--><p class="noindent" ><span class="head">
<a 
 id="x1-8012r12"></a>
<span 
class="cmbx-12">Theorem 7.12 </span>&#x0028;Second Whitehead Lemma&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">If</span> \(\mg \) <span 
class="cmti-12">is semisimple over characteristic</span> \(0\) <span 
class="cmti-12">and</span> \(M\) <span 
class="cmti-12">is</span>
<span 
class="cmti-12">&#xFB01;nite-dimensional, then</span> \(H^2(\mg ,M)=0\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 968--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>By the previous proposition, it su&#xFB03;ces to show \(H^2(\mg )\) vanishes, which is equivalent
to any saying any extension \(k \to \me \to \mg \) splits. To see that is true, simply observe that the \([\me ,\me ]\) gives
a splitting since \(k\) commutes with everything and \([\mg ,\mg ]= \mg \). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 972--><p class="indent" >  This is analogous to &#x0028;and partially proves&#x0029; a fact in Lie groups, that \(\pi _2\) vanishes for any
Lie group. Perhaps one complete the proof for compact Lie groups by proving that \(H_2\) is the
kernel of the universal central extension, so there can&#x2019;t be any torsion as it would give a
nontrivial cover.
</p>
                                                                                  

                                                                                  
  <div class="newtheorem">
<!--l. 974--><p class="noindent" ><span class="head">
<a 
 id="x1-8013r13"></a>
<span 
class="cmbx-12">Corollary 7.13 </span>&#x0028;Levi Decomposition&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">In characteristic</span> \(0\)<span 
class="cmti-12">, any Lie group splits as a</span>
<span 
class="cmti-12">semidirect product</span> \(\ma \ltimes \mg \) <span 
class="cmti-12">where</span> \(\ma \) <span 
class="cmti-12">is solvable and</span> \(\mg \) <span 
class="cmti-12">is semisimple.</span>
</p>
  <div class="proof">
<!--l. 977--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Note that \(\ma \) is really the radical, so we want to show that \(\rad (\mg ) \to \mg \to \mg /\rad (\mg )\) splits. We can do
this by induction on the length of the derived series. Mod out by \([\rad (\mg ),\rad (\mg )]\) to get an extension
by an abelian Lie algebra, for which there is a splitting by the second Whitehead
lemma. The preimage of this splitting is an ideal \(\mh \) such that there is an extension \([\ma ,\ma ] \to \mh \to \mg \),
at which point we can induct. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 981--><p class="noindent" ><span class="head">
<a 
 id="x1-8014r14"></a>
<span 
class="cmbx-12">Lemma 7.14 </span>&#x0028;Hopf&#x0029;<span 
class="cmbx-12">.</span>  </span><span 
class="cmti-12">Let</span> \(\mff /\ma \) <span 
class="cmti-12">be a presentation of</span> \(\mg \)<span 
class="cmti-12">. Then</span> \(H_2(\mg ) = \frac{\ma \cap [\mff ,\mff ]}{[\mff ,\ma ]}\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 984--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Consider the low term exact sequence from the homology spectral sequence
for \(0 \to \ma \to \mff \to \mg \to 0\) and the trivial module: \[0 \to H_2(\mg ,k) \to \ma /[\ma ,\ma ]_\mg \to \mff /[\mff ,\mff ] \to \mg /[\mg ,\mg ] \to 0\] The second term is \(\ma /[\mff ,\ma ]\), giving the result. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
                                                                                  

                                                                                  
  </div>
  <div class="newtheorem">
<!--l. 990--><p class="noindent" ><span class="head">
<a 
 id="x1-8015r15"></a>
<span 
class="cmbx-12">Lemma 7.15.</span>  </span> <span 
class="cmti-12">If</span> \(\me ,\me '\) <span 
class="cmti-12">are central extensions of</span> \(\mg \)<span 
class="cmti-12">, and</span> \(\me \) <span 
class="cmti-12">is perfect there is at most one</span>
<span 
class="cmti-12">homomorphism of extensions</span> \(\me \to \me '\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 993--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Any two homomorphisms di&#xFB00;er by something in the kernel of \(\me \), and \(\me '\) is perfect
and the kernel is central, it has to be \(0\). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <div class="newtheorem">
<!--l. 997--><p class="noindent" ><span class="head">
<a 
 id="x1-8016r16"></a>
<span 
class="cmbx-12">Theorem 7.16.</span>  </span>\(\mg \) <span 
class="cmti-12">has a universal central extension i&#xFB00;</span> \(\mg \) <span 
class="cmti-12">is perfect, and it is a central</span>
<span 
class="cmti-12">extension by</span> \(H_2(\mg ,k)\)<span 
class="cmti-12">.</span>
</p>
  <div class="proof">
<!--l. 1001--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Suppose \(\mg \) has a universal central extension \(\me \), it must have a unique map to the
trivial central extension, which implies that \(\mg \) has to be perfect. Conversely let \(\mg \) be
perfect. Choose a presentation \(\mg = \mff /\ma \), for \(\mff \) free. Then \(\mh = [\mff ,\mff ]/[\mff ,\ma ]\) will be shown to be the universal
central extension. By the previous lemma, it is an extension by \(H_2(\mg )\). Moreover, one can
see it is perfect. Since \(\mg \) is perfect, any \(x \in \mff \) decomposes as \(x'+r\) where \(x' \in \mff , r \in \ma \). Then choosing such a
decomposition for \(x =x'+r,y =x'+r\) Then \([x,y] = [x',y']\) modulo \([\mff ,\ma ]\). This gives uniqueness of a map to any extension.
                                                                                  

                                                                                  
</p><!--l. 1004--><p class="indent" >  Now let \(\me \) be any other central extension. There is a map from \(\mff \) to \(\me \) lifting the
projection to \(\mg \), and since \(\me \) is central, it induces a map from \(\mh \). <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
<!--l. 1008--><p class="indent" >  Here is a recognition criterion for universal central extensions.
</p>
  <div class="newtheorem">
<!--l. 1009--><p class="noindent" ><span class="head">
<a 
 id="x1-8017r17"></a>
<span 
class="cmbx-12">Lemma 7.17.</span>  </span><span 
class="cmti-12">TFAE for a central extension</span> \(\me \to \mg \)<span 
class="cmti-12">:</span>
          </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;1&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(\me \) <span 
class="cmti-12">is a universal central extension.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;2&#x0029;</span> </dt><dd 
class="enumerate-enumitem"><span 
class="cmti-12">Any central extension of</span> \(\me \) <span 
class="cmti-12">splits in a unique way.</span>
          </dd><dt class="enumerate-enumitem">
   <span 
class="cmti-12">&#x0028;3&#x0029;</span> </dt><dd 
class="enumerate-enumitem">\(H_1(\me )=H_2(\me ) = 0\)<span 
class="cmti-12">.</span>
          </dd></dl>
<!--l. 1017--><p class="noindent" ><span 
class="cmti-12">Moreover the universal central extension is idempotent.</span>
</p>
  <div class="proof">
<!--l. 1019--><p class="indent" >  <span class="head">
<span 
class="cmti-12">Proof.</span> </span>Consider \(\me '\), the universal central extension of the universal central extension,
and let \(x\) be in its kernel to \(\mg \). Since \(\me '\) is perfect, for any \(a\), there is some \(a',a''\) so that \([x,a] = [x,[a',a']]\). But
by the Jacobi identity this is zero since \(\me ',\me \) are central extensions. Thus \(\me '\) is a central
extension so it splits, and must be \(\me \).
</p><!--l. 1022--><p class="indent" >  \((1) \implies (2)\): Any central extension \(\me '\) of \(\me \) splits. \(\me '\) is thus also a central extension of \(\mg \) and since \(\me \)
is perfect, this splitting is unique by Lemma <a 
href="#x1-8015r15">7.15<!--tex4ht:ref: uniquemapcentextn --></a>.
</p><!--l. 1024--><p class="indent" >  \((2) \implies (3)\): Since the a trivial \(k\) extension splits in a unique way, we see \(H_1(\me )=0\). Moreover since any
extension splits, the universal central extension splits, so it must be trivial, showing
\(H_2(\me )=0\).
</p><!--l. 1026--><p class="indent" >  \((3) \implies (1)\): Given any central extension of \(\mg \), we can pull it back to a central extension of \(\me \) which
                                                                                  

                                                                                  
splits, giving a map to the central extension. Uniqueness follows from perfectness. <span class="qed"><span 
class="msam-10x-x-120">&#x25A1;</span></span>
</p>
  </div>
  </div>
  <h3 class="sectionHead"><span class="titlemark">8. </span> <a 
 id="x1-90008"></a>To add</h3>
<!--l. 1031--><p class="noindent" >A&#xFB03;ne Kac-Moody algebras Representation theory/Character formulas More on Cartan
subalgebras Malcev theorem Ado&#x2019;s theorem
</p>
   
</body> 
</html>
                                                                                  

                                                                                  
                                                                                  


